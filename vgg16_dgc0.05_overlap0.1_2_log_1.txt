Sun Apr 10 10:45:57 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   27C    P0    25W / 250W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  On   | 00000000:50:00.0 Off |                    0 |
| N/A   29C    P0    25W / 250W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/gs/software/cuda/10.1
[1,0]<stdout>:==> loading configs from ['configs/imagenet/vgg16_bn.py', 'configs/methods/wm0.py', 'configs/methods/fp16.py', 'configs/methods/int32.py']
[1,0]<stdout>:[train.save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:[seed] = 42
[1,0]<stdout>:[data]
[1,0]<stdout>:  [num_threads_per_worker] = 4
[1,0]<stdout>:[train]
[1,0]<stdout>:  [dgc] = True
[1,0]<stdout>:  [compression]
[1,0]<stdout>:    [func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:    [compress_ratio] = 0.05
[1,0]<stdout>:    [sample_ratio] = 0.01
[1,0]<stdout>:    [strided_sample] = True
[1,0]<stdout>:    [compress_upper_bound] = 1.3
[1,0]<stdout>:    [compress_lower_bound] = 0.8
[1,0]<stdout>:    [max_adaptation_iters] = 10
[1,0]<stdout>:    [resample] = True
[1,0]<stdout>:    [memory]
[1,0]<stdout>:      [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:      [momentum] = 0.9
[1,0]<stdout>:    [warmup_epochs] = 0
[1,0]<stdout>:    [fp16_values] = True
[1,0]<stdout>:    [int32_indices] = True
[1,0]<stdout>:  [criterion]
[1,0]<stdout>:    [func] = <class 'torch.nn.modules.loss.CrossEntropyLoss'>
[1,0]<stdout>:  [optimizer]
[1,0]<stdout>:    [func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:    [momentum] = 0.9
[1,0]<stdout>:    [lr] = 0.0125
[1,0]<stdout>:    [weight_decay] = 5e-05
[1,0]<stdout>:  [schedule_lr_per_epoch] = True
[1,0]<stdout>:  [warmup_lr_epochs] = 5
[1,0]<stdout>:  [metric] = acc/test_top1
[1,0]<stdout>:  [meters]
[1,0]<stdout>:    [acc/{}_top1]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 1
[1,0]<stdout>:    [acc/{}_top5]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 5
[1,0]<stdout>:  [optimize_bn_separately] = False
[1,0]<stdout>:  [num_epochs] = 5
[1,0]<stdout>:  [batch_size] = 64
[1,0]<stdout>:  [scheduler]
[1,0]<stdout>:    [func] = <class 'torch.optim.lr_scheduler.MultiStepLR'>
[1,0]<stdout>:    [milestones] = [25, 55, 75]
[1,0]<stdout>:    [gamma] = 0.1
[1,0]<stdout>:  [topk] = False
[1,0]<stdout>:  [fp16] = False
[1,0]<stdout>:  [powersgd] = False
[1,0]<stdout>:  [sign] = False
[1,0]<stdout>:  [efsign] = False
[1,0]<stdout>:  [natural] = False
[1,0]<stdout>:  [onebit] = False
[1,0]<stdout>:  [qsgd] = False
[1,0]<stdout>:  [randomk] = False
[1,0]<stdout>:  [signum] = False
[1,0]<stdout>:  [terngrad] = False
[1,0]<stdout>:  [num_batches_per_step] = 1
[1,0]<stdout>:  [save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:  [checkpoint_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/e{epoch}-r0.pth
[1,0]<stdout>:  [latest_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/latest-r0.pth
[1,0]<stdout>:  [best_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/best-r0.pth
[1,0]<stdout>:[dataset]
[1,0]<stdout>:  [func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:  [root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [image_size] = 224
[1,0]<stdout>:[model]
[1,0]<stdout>:  [func] = <function vgg16_bn at 0x7f43ef0fdf70>
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [init_weights] = True
[1,0]<stdout>:[device] = cuda[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:==> creating model "[func] = <function vgg16_bn at 0x7f43ef0fdf70>
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[init_weights] = True"
[1,0]<stdout>:
[1,0]<stdout>:==> creating dataset "[func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:[root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[image_size] = 224"
[1,0]<stdout>:
[1,0]<stdout>:==> loading dataset "{'num_workers': 4, 'pin_memory': True, 'multiprocessing_context': 'forkserver'}""
[1,0]<stdout>:
[1,0]<stdout>:==> creating optimizer "[func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:[momentum] = 0.9
[1,0]<stdout>:[lr] = 0.025
[1,0]<stdout>:[weight_decay] = 5e-05"
[1,0]<stdout>:
[1,0]<stdout>:==> creating compression "[func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:[compress_ratio] = 0.05
[1,0]<stdout>:[sample_ratio] = 0.01
[1,0]<stdout>:[strided_sample] = True
[1,0]<stdout>:[compress_upper_bound] = 1.3
[1,0]<stdout>:[compress_lower_bound] = 0.8
[1,0]<stdout>:[max_adaptation_iters] = 10
[1,0]<stdout>:[resample] = True
[1,0]<stdout>:[memory]
[1,0]<stdout>:  [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:  [momentum] = 0.9
[1,0]<stdout>:[warmup_epochs] = 0
[1,0]<stdout>:[fp16_values] = True
[1,0]<stdout>:[int32_indices] = True"
[1,0]<stdout>:
[1,0]<stdout>:==> initializing dgc compression
[1,0]<stdout>:=> initializing dgc sgd memory
[1,1]<stdout>:<generator object Module.named_parameters at 0x7f97ba6d2cf0>
[1,0]<stdout>:<generator object Module.named_parameters at 0x7f43ee43d2e0>
[1,0]<stdout>:=> initializing dgc compressor
[1,0]<stdout>:   features.0.weight        : transmit 87 / 1728 elements of shape [64, 3, 3, 3]
[1,0]<stdout>:                              threshold 3 / 42 samples at stride 41
[1,0]<stdout>:   features.3.weight        : transmit 1844 / 36864 elements of shape [64, 64, 3, 3]
[1,0]<stdout>:                              threshold 19 / 380 samples at stride 97
[1,0]<stdout>:   features.7.weight        : transmit 3687 / 73728 elements of shape [128, 64, 3, 3]
[1,0]<stdout>:                              threshold 38 / 760 samples at stride 97
[1,0]<stdout>:   features.10.weight       : transmit 7373 / 147456 elements of shape [128, 128, 3, 3]
[1,0]<stdout>:                              threshold 76 / 1520 samples at stride 97
[1,0]<stdout>:   features.14.weight       : transmit 14746 / 294912 elements of shape [256, 128, 3, 3]
[1,0]<stdout>:                              threshold 152 / 3040 samples at stride 97
[1,0]<stdout>:   features.17.weight       : transmit 29492 / 589824 elements of shape [256, 256, 3, 3]
[1,0]<stdout>:                              threshold 304 / 6080 samples at stride 97
[1,0]<stdout>:   features.20.weight       : transmit 29492 / 589824 elements of shape [256, 256, 3, 3]
[1,0]<stdout>:                              threshold 304 / 6080 samples at stride 97
[1,0]<stdout>:   features.24.weight       : transmit 58983 / 1179648 elements of shape [512, 256, 3, 3]
[1,0]<stdout>:                              threshold 609 / 12161 samples at stride 97
[1,0]<stdout>:   features.27.weight       : transmit 117965 / 2359296 elements of shape [512, 512, 3, 3]
[1,0]<stdout>:                              threshold 1217 / 24322 samples at stride 97
[1,0]<stdout>:   features.30.weight       : transmit 117965 / 2359296 elements of shape [512, 512, 3, 3]
[1,0]<stdout>:                              threshold 1217 / 24322 samples at stride 97
[1,0]<stdout>:   features.34.weight       : transmit 117965 / 2359296 elements of shape [512, 512, 3, 3]
[1,0]<stdout>:                              threshold 1217 / 24322 samples at stride 97
[1,0]<stdout>:   features.37.weight       : transmit 117965 / 2359296 elements of shape [512, 512, 3, 3]
[1,0]<stdout>:                              threshold 1217 / 24322 samples at stride 97
[1,0]<stdout>:   features.40.weight       : transmit 117965 / 2359296 elements of shape [512, 512, 3, 3]
[1,0]<stdout>:                              threshold 1217 / 24322 samples at stride 97
[1,0]<stdout>:   classifier.0.weight      : transmit 5138023 / 102760448 elements of shape [4096, 25088]
[1,0]<stdout>:                              threshold 52970 / 1059386 samples at stride 97
[1,0]<stdout>:   classifier.3.weight      : transmit 838861 / 16777216 elements of shape [4096, 4096]
[1,0]<stdout>:                              threshold 8648 / 172960 samples at stride 97
[1,0]<stdout>:   classifier.6.weight      : transmit 204800 / 4096000 elements of shape [1000, 4096]
[1,0]<stdout>:                              threshold 2112 / 42226 samples at stride 97
[1,0]<stdout>:
[1,0]<stdout>:==> train from scratch
[1,0]<stdout>:
[1,0]<stdout>:==> broadcasting paramters and optimizer state
[1,0]<stdout>:   features.8.weight        : transmit 6 / 116 elements of shape torch.Size([116])
[1,0]<stdout>:                              threshold 6 / 116 samples at stride 1
[1,0]<stdout>:   features.8.bias          : transmit 6 / 116 elements of shape torch.Size([116])
[1,0]<stdout>:                              threshold 6 / 116 samples at stride 1
[1,1]<stderr>:Traceback (most recent call last):
[1,1]<stderr>:  File "./train.py", line 523, in <module>
[1,1]<stderr>:    main()
[1,1]<stderr>:  File "./train.py", line 230, in main
[1,1]<stderr>:    hvd.broadcast_optimizer_state(optimizer, root_rank=0)
[1,1]<stderr>:  File "/gs/home/lwang20/anaconda3/env/lib/python3.8/site-packages/horovod/torch/functions.py", line 98, in broadcast_optimizer_state
[1,1]<stderr>:    optimizer.step()
[1,1]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 325, in step
[1,1]<stderr>:    self.synchronize()
[1,1]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 221, in synchronize
[1,1]<stderr>:    handle, ctx = self._allreduce_grad_async(p)
[1,1]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 145, in _allreduce_grad_async
[1,1]<stderr>:    tensors_compressed, ctx = self._compression.compress(tensor_to_compress, name)
[1,1]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/compression.py", line 180, in compress
[1,1]<stderr>:    tensor_compensated = self.memory.compensate(
[1,1]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/memory.py", line 66, in compensate
[1,1]<stderr>:    mmt.add_(grad)
[1,1]<stderr>:RuntimeError: The size of tensor a (3) must match the size of tensor b (73728) at non-singleton dimension 3
[1,0]<stderr>:Traceback (most recent call last):
[1,0]<stderr>:  File "./train.py", line 523, in <module>
[1,0]<stderr>:    main()
[1,0]<stderr>:  File "./train.py", line 230, in main
[1,0]<stderr>:    hvd.broadcast_optimizer_state(optimizer, root_rank=0)
[1,0]<stderr>:  File "/gs/home/lwang20/anaconda3/env/lib/python3.8/site-packages/horovod/torch/functions.py", line 98, in broadcast_optimizer_state
[1,0]<stderr>:    optimizer.step()
[1,0]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 325, in step
[1,0]<stderr>:    self.synchronize()
[1,0]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 221, in synchronize
[1,0]<stderr>:    handle, ctx = self._allreduce_grad_async(p)
[1,0]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/horovod/optimizer.py", line 145, in _allreduce_grad_async
[1,0]<stderr>:    tensors_compressed, ctx = self._compression.compress(tensor_to_compress, name)
[1,0]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/compression.py", line 180, in compress
[1,0]<stderr>:    tensor_compensated = self.memory.compensate(
[1,0]<stderr>:  File "/gs/home/lwang20/jzb_horovod_test/compression/src/memory.py", line 66, in compensate
[1,0]<stderr>:    mmt.add_(grad)
[1,0]<stderr>:RuntimeError: The size of tensor a (3) must match the size of tensor b (73728) at non-singleton dimension 3
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[43361,1],1]
  Exit code:    1
--------------------------------------------------------------------------

real	0m25.282s
user	0m11.587s
sys	0m2.851s
