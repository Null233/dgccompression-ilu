Mon Apr 11 14:50:20 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:38:00.0 Off |                    0 |
| N/A   25C    P0    22W / 250W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  On   | 00000000:50:00.0 Off |                    0 |
| N/A   27C    P0    23W / 250W |      0MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/gs/software/cuda/10.1
[1,1]<stdout>:`bottleneck` is a tool that can be used as an initial step for debugging
[1,1]<stdout>:bottlenecks in your program.
[1,1]<stdout>:
[1,1]<stdout>:It summarizes runs of your script with the Python profiler and PyTorch's
[1,1]<stdout>:autograd profiler. Because your script will be profiled, please ensure that it
[1,1]<stdout>:exits in a finite amount of time.
[1,1]<stdout>:
[1,1]<stdout>:For more complicated uses of the profilers, please see
[1,1]<stdout>:https://docs.python.org/3/library/profile.html and
[1,1]<stdout>:https://pytorch.org/docs/master/autograd.html#profiler for more information.
[1,1]<stdout>:Running environment analysis...
[1,0]<stdout>:`bottleneck` is a tool that can be used as an initial step for debugging
[1,0]<stdout>:bottlenecks in your program.
[1,0]<stdout>:
[1,0]<stdout>:It summarizes runs of your script with the Python profiler and PyTorch's
[1,0]<stdout>:autograd profiler. Because your script will be profiled, please ensure that it
[1,0]<stdout>:exits in a finite amount of time.
[1,0]<stdout>:
[1,0]<stdout>:For more complicated uses of the profilers, please see
[1,0]<stdout>:https://docs.python.org/3/library/profile.html and
[1,0]<stdout>:https://pytorch.org/docs/master/autograd.html#profiler for more information.
[1,0]<stdout>:Running environment analysis...
[1,0]<stdout>:Running your script with cProfile
[1,1]<stdout>:Running your script with cProfile
[1,0]<stdout>:==> loading configs from ['configs/imagenet/vgg16_bn.py', 'configs/methods/wm0.py', 'configs/methods/fp16.py', 'configs/methods/int32.py']
[1,0]<stdout>:[train.save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:[seed] = 42
[1,0]<stdout>:[data]
[1,0]<stdout>:  [num_threads_per_worker] = 4
[1,0]<stdout>:[train]
[1,0]<stdout>:  [dgc] = False
[1,0]<stdout>:  [compression]
[1,0]<stdout>:    [func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:    [compress_ratio] = 0.05
[1,0]<stdout>:    [sample_ratio] = 0.01
[1,0]<stdout>:    [strided_sample] = True
[1,0]<stdout>:    [compress_upper_bound] = 1.3
[1,0]<stdout>:    [compress_lower_bound] = 0.8
[1,0]<stdout>:    [max_adaptation_iters] = 10
[1,0]<stdout>:    [resample] = True
[1,0]<stdout>:    [memory]
[1,0]<stdout>:      [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:      [momentum] = 0.9
[1,0]<stdout>:    [warmup_epochs] = 0
[1,0]<stdout>:    [fp16_values] = True
[1,0]<stdout>:    [int32_indices] = True
[1,0]<stdout>:  [criterion]
[1,0]<stdout>:    [func] = <class 'torch.nn.modules.loss.CrossEntropyLoss'>
[1,0]<stdout>:  [optimizer]
[1,0]<stdout>:    [func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:    [momentum] = 0.9
[1,0]<stdout>:    [lr] = 0.0125
[1,0]<stdout>:    [weight_decay] = 5e-05
[1,0]<stdout>:  [schedule_lr_per_epoch] = True
[1,0]<stdout>:  [warmup_lr_epochs] = 5
[1,0]<stdout>:  [metric] = acc/test_top1
[1,0]<stdout>:  [meters]
[1,0]<stdout>:    [acc/{}_top1]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 1
[1,0]<stdout>:    [acc/{}_top5]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 5
[1,0]<stdout>:  [optimize_bn_separately] = False
[1,0]<stdout>:  [num_epochs] = 1
[1,0]<stdout>:  [batch_size] = 64
[1,0]<stdout>:  [scheduler]
[1,0]<stdout>:    [func] = <class 'torch.optim.lr_scheduler.MultiStepLR'>
[1,0]<stdout>:    [milestones] = [25, 55, 75]
[1,0]<stdout>:    [gamma] = 0.1
[1,0]<stdout>:  [topk] = False
[1,0]<stdout>:  [fp16] = False
[1,0]<stdout>:  [powersgd] = False
[1,0]<stdout>:  [sign] = False
[1,0]<stdout>:  [efsign] = False
[1,0]<stdout>:  [natural] = False
[1,0]<stdout>:  [onebit] = False
[1,0]<stdout>:  [qsgd] = False
[1,0]<stdout>:  [randomk] = False
[1,0]<stdout>:  [signum] = False
[1,0]<stdout>:  [terngrad] = False
[1,0]<stdout>:  [num_batches_per_step] = 1
[1,0]<stdout>:  [save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:  [checkpoint_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/e{epoch}-r0.pth
[1,0]<stdout>:  [latest_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/latest-r0.pth
[1,0]<stdout>:  [best_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/best-r0.pth
[1,0]<stdout>:[dataset]
[1,0]<stdout>:  [func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:  [root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [image_size] = 224
[1,0]<stdout>:[model]
[1,0]<stdout>:  [func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [init_weights] = True
[1,0]<stdout>:[device] = cuda
[1,0]<stdout>:
[1,0]<stdout>:==> creating model "[func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[init_weights] = True"
[1,0]<stdout>:
[1,0]<stdout>:==> creating dataset "[func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:[root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[image_size] = 224"
[1,0]<stdout>:
[1,0]<stdout>:==> loading dataset "{'num_workers': 4, 'pin_memory': True, 'multiprocessing_context': 'forkserver'}""
[1,0]<stdout>:
[1,0]<stdout>:==> creating optimizer "[func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:[momentum] = 0.9
[1,0]<stdout>:[lr] = 0.025
[1,0]<stdout>:[weight_decay] = 5e-05"
[1,0]<stdout>:
[1,0]<stdout>:==> creating compression "[func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:[compress_ratio] = 0.05
[1,0]<stdout>:[sample_ratio] = 0.01
[1,0]<stdout>:[strided_sample] = True
[1,0]<stdout>:[compress_upper_bound] = 1.3
[1,0]<stdout>:[compress_lower_bound] = 0.8
[1,0]<stdout>:[max_adaptation_iters] = 10
[1,0]<stdout>:[resample] = True
[1,0]<stdout>:[memory]
[1,0]<stdout>:  [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:  [momentum] = 0.9
[1,0]<stdout>:[warmup_epochs] = 0
[1,0]<stdout>:[fp16_values] = True
[1,0]<stdout>:[int32_indices] = True"
[1,0]<stdout>:Use hvd.none compression...
[1,1]<stdout>:Use hvd.none compression...
[1,0]<stdout>:
[1,0]<stdout>:==> train from scratch
[1,0]<stdout>:
[1,0]<stdout>:==> broadcasting paramters and optimizer state
[1,0]<stdout>:before evaluate
[1,1]<stdout>:before evaluate
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stderr>:test:   1%|▏         | 1/79 [00:06<07:48,  6.01s/it][1,0]<stderr>:test:   1%|▏         | 1/79 [00:06<07:52,  6.06s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:07<01:28,  1.20s/it][1,1]<stderr>:test:   8%|▊         | 6/79 [00:07<01:09,  1.05it/s][1,0]<stderr>:test:   6%|▋         | 5/79 [00:07<01:32,  1.25s/it][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:10<01:01,  1.13it/s][1,1]<stderr>:test:  13%|█▎        | 10/79 [00:10<00:51,  1.33it/s][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:10<01:09,  1.00it/s][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:13<00:59,  1.11it/s][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:13<00:56,  1.16it/s][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:15<00:47,  1.31it/s][1,1]<stderr>:test:  24%|██▍       | 19/79 [00:16<00:36,  1.62it/s][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:16<00:48,  1.27it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:18<00:43,  1.34it/s][1,1]<stderr>:test:  29%|██▉       | 23/79 [00:18<00:31,  1.77it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:18<00:43,  1.33it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:21<00:40,  1.33it/s][1,1]<stderr>:test:  34%|███▍      | 27/79 [00:21<00:30,  1.72it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:21<00:38,  1.41it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:23<00:34,  1.45it/s][1,1]<stderr>:test:  39%|███▉      | 31/79 [00:23<00:25,  1.90it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:24<00:35,  1.41it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:26<00:36,  1.26it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:27<00:32,  1.43it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:28<00:27,  1.50it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:29<00:27,  1.51it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:30<00:24,  1.58it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:31<00:24,  1.57it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:33<00:21,  1.55it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:33<00:20,  1.64it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:35<00:18,  1.58it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:36<00:19,  1.56it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:39<00:17,  1.45it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:39<00:16,  1.54it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [00:41<00:14,  1.54it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:41<00:13,  1.64it/s][1,0]<stderr>:test:  75%|███████▍  | 59/79 [00:41<00:10,  1.92it/s][1,1]<stderr>:test:  77%|███████▋  | 61/79 [00:43<00:10,  1.66it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [00:44<00:11,  1.53it/s][1,1]<stderr>:test:  82%|████████▏ | 65/79 [00:46<00:08,  1.62it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [00:46<00:08,  1.64it/s][1,0]<stderr>:test:  85%|████████▍ | 67/79 [00:46<00:05,  2.01it/s][1,1]<stderr>:test:  87%|████████▋ | 69/79 [00:48<00:06,  1.66it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [00:48<00:06,  1.62it/s][1,0]<stderr>:test:  90%|████████▉ | 71/79 [00:48<00:04,  1.88it/s][1,1]<stderr>:test:  92%|█████████▏| 73/79 [00:50<00:03,  1.65it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [00:51<00:04,  1.49it/s][1,0]<stderr>:test:  95%|█████████▍| 75/79 [00:51<00:02,  1.84it/s][1,1]<stderr>:test:  97%|█████████▋| 77/79 [00:53<00:01,  1.60it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [00:54<00:01,  1.32it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s][1,0]<stdout>:after evaluate
[1,0]<stdout>:[acc/test_top1] = 0.060000
[1,1]<stdout>:after evaluate
[1,0]<stdout>:[acc/test_top5] = 0.560000
[1,1]<stderr>:
[1,0]<stdout>:
[1,0]<stdout>:==> training epoch 0/1
[1,0]<stderr>:
[1,0]<stderr>:train:   0% 0/255 [00:00<?, ?it/s][1,0]<stderr>:train:   0% 1/255 [00:18<1:16:20, 18.03s/it][1,0]<stderr>:train:   1% 2/255 [00:19<36:08,  8.57s/it]  [1,0]<stderr>:train:   1% 3/255 [00:21<23:13,  5.53s/it][1,0]<stderr>:train:   2% 4/255 [00:23<17:09,  4.10s/it][1,0]<stderr>:train:   2% 5/255 [00:25<13:43,  3.29s/it][1,0]<stderr>:train:   2% 6/255 [00:27<11:35,  2.79s/it][1,0]<stderr>:train:   3% 7/255 [00:29<10:16,  2.49s/it][1,0]<stderr>:train:   3% 8/255 [00:31<09:24,  2.28s/it][1,0]<stderr>:train:   4% 9/255 [00:33<08:49,  2.15s/it][1,0]<stderr>:train:   4% 10/255 [00:34<08:26,  2.07s/it][1,0]<stderr>:train:   4% 11/255 [00:36<08:09,  2.00s/it][1,0]<stderr>:train:   5% 12/255 [00:38<07:46,  1.92s/it][1,0]<stderr>:train:   5% 13/255 [00:40<07:30,  1.86s/it][1,0]<stderr>:train:   5% 14/255 [00:41<07:19,  1.82s/it][1,0]<stderr>:train:   6% 15/255 [00:43<07:21,  1.84s/it][1,0]<stderr>:train:   6% 16/255 [00:45<07:21,  1.85s/it][1,0]<stderr>:train:   7% 17/255 [00:47<07:11,  1.81s/it][1,0]<stderr>:train:   7% 18/255 [00:49<07:02,  1.78s/it][1,0]<stderr>:train:   7% 19/255 [00:51<07:08,  1.81s/it][1,0]<stderr>:train:   8% 20/255 [00:52<07:11,  1.84s/it][1,0]<stderr>:train:   8% 21/255 [00:54<07:11,  1.85s/it][1,0]<stderr>:train:   9% 22/255 [00:56<07:00,  1.81s/it][1,0]<stderr>:train:   9% 23/255 [00:58<07:05,  1.83s/it][1,0]<stderr>:train:   9% 24/255 [01:00<07:04,  1.84s/it][1,0]<stderr>:train:  10% 25/255 [01:02<07:06,  1.85s/it][1,0]<stderr>:train:  10% 26/255 [01:04<07:07,  1.87s/it][1,0]<stderr>:train:  11% 27/255 [01:05<07:06,  1.87s/it][1,0]<stderr>:train:  11% 28/255 [01:07<07:05,  1.87s/it][1,0]<stderr>:train:  11% 29/255 [01:09<07:03,  1.87s/it][1,0]<stderr>:train:  12% 30/255 [01:11<06:52,  1.83s/it][1,0]<stderr>:train:  12% 31/255 [01:13<06:53,  1.85s/it][1,0]<stderr>:train:  13% 32/255 [01:15<06:52,  1.85s/it][1,0]<stderr>:train:  13% 33/255 [01:17<06:52,  1.86s/it][1,0]<stderr>:train:  13% 34/255 [01:18<06:51,  1.86s/it][1,0]<stderr>:train:  14% 35/255 [01:20<06:40,  1.82s/it][1,0]<stderr>:train:  14% 36/255 [01:22<06:42,  1.84s/it][1,0]<stderr>:train:  15% 37/255 [01:24<06:41,  1.84s/it][1,0]<stderr>:train:  15% 38/255 [01:26<06:41,  1.85s/it][1,0]<stderr>:train:  15% 39/255 [01:28<06:41,  1.86s/it][1,0]<stderr>:train:  16% 40/255 [01:29<06:40,  1.86s/it][1,0]<stderr>:train:  16% 41/255 [01:31<06:38,  1.86s/it][1,0]<stderr>:train:  16% 42/255 [01:33<06:36,  1.86s/it][1,0]<stderr>:train:  17% 43/255 [01:35<06:34,  1.86s/it][1,0]<stderr>:train:  17% 44/255 [01:37<06:32,  1.86s/it][1,0]<stderr>:train:  18% 45/255 [01:39<06:32,  1.87s/it][1,0]<stderr>:train:  18% 46/255 [01:41<06:30,  1.87s/it][1,0]<stderr>:train:  18% 47/255 [01:43<06:27,  1.87s/it][1,0]<stderr>:train:  19% 48/255 [01:44<06:28,  1.87s/it][1,0]<stderr>:train:  19% 49/255 [01:46<06:26,  1.88s/it][1,0]<stderr>:train:  20% 50/255 [01:48<06:16,  1.83s/it][1,0]<stderr>:train:  20% 51/255 [01:50<06:20,  1.87s/it][1,0]<stderr>:train:  20% 52/255 [01:52<06:18,  1.86s/it][1,0]<stderr>:train:  21% 53/255 [01:54<06:09,  1.83s/it][1,0]<stderr>:train:  21% 54/255 [01:55<06:11,  1.85s/it][1,0]<stderr>:train:  22% 55/255 [01:57<06:10,  1.85s/it][1,0]<stderr>:train:  22% 56/255 [01:59<06:08,  1.85s/it][1,0]<stderr>:train:  22% 57/255 [02:01<06:09,  1.87s/it][1,0]<stderr>:train:  23% 58/255 [02:03<06:07,  1.87s/it][1,0]<stderr>:train:  23% 59/255 [02:05<05:57,  1.83s/it][1,0]<stderr>:train:  24% 60/255 [02:06<05:53,  1.81s/it][1,0]<stderr>:train:  24% 61/255 [02:08<05:48,  1.80s/it][1,0]<stderr>:train:  24% 62/255 [02:10<05:50,  1.82s/it][1,0]<stderr>:train:  25% 63/255 [02:12<05:50,  1.83s/it][1,0]<stderr>:train:  25% 64/255 [02:14<05:51,  1.84s/it][1,0]<stderr>:train:  25% 65/255 [02:16<05:53,  1.86s/it][1,0]<stderr>:train:  26% 66/255 [02:17<05:44,  1.82s/it][1,0]<stderr>:train:  26% 67/255 [02:19<05:43,  1.83s/it][1,0]<stderr>:train:  27% 68/255 [02:21<05:36,  1.80s/it][1,0]<stderr>:train:  27% 69/255 [02:23<05:35,  1.81s/it][1,0]<stderr>:train:  27% 70/255 [02:25<05:38,  1.83s/it][1,0]<stderr>:train:  28% 71/255 [02:26<05:31,  1.80s/it][1,0]<stderr>:train:  28% 72/255 [02:28<05:25,  1.78s/it][1,0]<stderr>:train:  29% 73/255 [02:30<05:24,  1.78s/it][1,0]<stderr>:train:  29% 74/255 [02:32<05:28,  1.82s/it][1,0]<stderr>:train:  29% 75/255 [02:34<05:31,  1.84s/it][1,0]<stderr>:train:  30% 76/255 [02:36<05:32,  1.86s/it][1,0]<stderr>:train:  30% 77/255 [02:38<05:31,  1.86s/it][1,0]<stderr>:train:  31% 78/255 [02:39<05:22,  1.82s/it][1,0]<stderr>:train:  31% 79/255 [02:41<05:23,  1.84s/it][1,0]<stderr>:train:  31% 80/255 [02:43<05:21,  1.83s/it][1,0]<stderr>:train:  32% 81/255 [02:45<05:14,  1.81s/it][1,0]<stderr>:train:  32% 82/255 [02:47<05:17,  1.83s/it][1,0]<stderr>:train:  33% 83/255 [02:48<05:16,  1.84s/it][1,0]<stderr>:train:  33% 84/255 [02:50<05:15,  1.85s/it][1,0]<stderr>:train:  33% 85/255 [02:52<05:12,  1.84s/it][1,0]<stderr>:train:  34% 86/255 [02:54<05:07,  1.82s/it][1,0]<stderr>:train:  34% 87/255 [02:56<05:08,  1.84s/it][1,0]<stderr>:train:  35% 88/255 [02:58<05:07,  1.84s/it][1,0]<stderr>:train:  35% 89/255 [03:00<05:07,  1.86s/it][1,0]<stderr>:train:  35% 90/255 [03:01<04:59,  1.82s/it][1,0]<stderr>:train:  36% 91/255 [03:03<05:04,  1.86s/it][1,0]<stderr>:train:  36% 92/255 [03:05<05:04,  1.87s/it][1,0]<stderr>:train:  36% 93/255 [03:07<05:03,  1.87s/it][1,0]<stderr>:train:  37% 94/255 [03:09<04:54,  1.83s/it][1,0]<stderr>:train:  37% 95/255 [03:11<04:54,  1.84s/it][1,0]<stderr>:train:  38% 96/255 [03:12<04:54,  1.85s/it][1,0]<stderr>:train:  38% 97/255 [03:14<04:47,  1.82s/it][1,0]<stderr>:train:  38% 98/255 [03:16<04:48,  1.84s/it][1,0]<stderr>:train:  39% 99/255 [03:18<04:43,  1.82s/it][1,0]<stderr>:train:  39% 100/255 [03:20<04:45,  1.84s/it][1,0]<stderr>:train:  40% 101/255 [03:22<04:45,  1.85s/it][1,0]<stderr>:train:  40% 102/255 [03:23<04:37,  1.82s/it][1,0]<stderr>:train:  40% 103/255 [03:25<04:32,  1.79s/it][1,0]<stderr>:train:  41% 104/255 [03:27<04:33,  1.81s/it][1,0]<stderr>:train:  41% 105/255 [03:29<04:33,  1.82s/it][1,0]<stderr>:train:  42% 106/255 [03:31<04:31,  1.83s/it][1,0]<stderr>:train:  42% 107/255 [03:32<04:26,  1.80s/it][1,0]<stderr>:train:  42% 108/255 [03:34<04:29,  1.83s/it][1,0]<stderr>:train:  43% 109/255 [03:36<04:29,  1.84s/it][1,0]<stderr>:train:  43% 110/255 [03:38<04:23,  1.82s/it][1,0]<stderr>:train:  44% 111/255 [03:40<04:18,  1.80s/it][1,0]<stderr>:train:  44% 112/255 [03:42<04:20,  1.82s/it][1,0]<stderr>:train:  44% 113/255 [03:43<04:22,  1.85s/it][1,0]<stderr>:train:  45% 114/255 [03:45<04:23,  1.87s/it][1,0]<stderr>:train:  45% 115/255 [03:47<04:22,  1.88s/it][1,0]<stderr>:train:  45% 116/255 [03:49<04:20,  1.87s/it][1,0]<stderr>:train:  46% 117/255 [03:51<04:19,  1.88s/it][1,0]<stderr>:train:  46% 118/255 [03:53<04:19,  1.89s/it][1,0]<stderr>:train:  47% 119/255 [03:55<04:15,  1.88s/it][1,0]<stderr>:train:  47% 120/255 [03:57<04:06,  1.83s/it][1,0]<stderr>:train:  47% 121/255 [03:58<04:09,  1.86s/it][1,0]<stderr>:train:  48% 122/255 [04:00<04:02,  1.83s/it][1,0]<stderr>:train:  48% 123/255 [04:02<03:57,  1.80s/it][1,0]<stderr>:train:  49% 124/255 [04:04<03:54,  1.79s/it][1,0]<stderr>:train:  49% 125/255 [04:06<03:56,  1.82s/it][1,0]<stderr>:train:  49% 126/255 [04:07<03:57,  1.84s/it][1,0]<stderr>:train:  50% 127/255 [04:09<03:56,  1.85s/it][1,0]<stderr>:train:  50% 128/255 [04:11<03:55,  1.86s/it][1,0]<stderr>:train:  51% 129/255 [04:13<03:53,  1.85s/it][1,0]<stderr>:train:  51% 130/255 [04:15<03:53,  1.87s/it][1,0]<stderr>:train:  51% 131/255 [04:17<03:52,  1.87s/it][1,0]<stderr>:train:  52% 132/255 [04:19<03:50,  1.87s/it][1,0]<stderr>:train:  52% 133/255 [04:21<03:45,  1.84s/it][1,0]<stderr>:train:  53% 134/255 [04:22<03:41,  1.83s/it][1,0]<stderr>:train:  53% 135/255 [04:24<03:36,  1.80s/it][1,0]<stderr>:train:  53% 136/255 [04:26<03:33,  1.79s/it][1,0]<stderr>:train:  54% 137/255 [04:28<03:34,  1.82s/it][1,0]<stderr>:train:  54% 138/255 [04:29<03:31,  1.80s/it][1,0]<stderr>:train:  55% 139/255 [04:31<03:31,  1.82s/it][1,0]<stderr>:train:  55% 140/255 [04:33<03:32,  1.84s/it][1,0]<stderr>:train:  55% 141/255 [04:35<03:31,  1.86s/it][1,0]<stderr>:train:  56% 142/255 [04:37<03:26,  1.83s/it][1,0]<stderr>:train:  56% 143/255 [04:39<03:23,  1.82s/it][1,0]<stderr>:train:  56% 144/255 [04:40<03:19,  1.80s/it][1,0]<stderr>:train:  57% 145/255 [04:42<03:15,  1.78s/it][1,0]<stderr>:train:  57% 146/255 [04:44<03:12,  1.76s/it][1,0]<stderr>:train:  58% 147/255 [04:46<03:15,  1.81s/it][1,0]<stderr>:train:  58% 148/255 [04:48<03:16,  1.84s/it][1,0]<stderr>:train:  58% 149/255 [04:50<03:17,  1.86s/it][1,0]<stderr>:train:  59% 150/255 [04:51<03:10,  1.82s/it][1,0]<stderr>:train:  59% 151/255 [04:53<03:13,  1.86s/it][1,0]<stderr>:train:  60% 152/255 [04:55<03:12,  1.87s/it][1,0]<stderr>:train:  60% 153/255 [04:57<03:12,  1.89s/it][1,0]<stderr>:train:  60% 154/255 [04:59<03:11,  1.89s/it][1,0]<stderr>:train:  61% 155/255 [05:01<03:08,  1.89s/it][1,0]<stderr>:train:  61% 156/255 [05:03<03:07,  1.89s/it][1,0]<stderr>:train:  62% 157/255 [05:05<03:01,  1.85s/it][1,0]<stderr>:train:  62% 158/255 [05:06<03:00,  1.86s/it][1,0]<stderr>:train:  62% 159/255 [05:08<02:59,  1.87s/it][1,0]<stderr>:train:  63% 160/255 [05:10<02:59,  1.89s/it][1,0]<stderr>:train:  63% 161/255 [05:12<02:57,  1.89s/it][1,0]<stderr>:train:  64% 162/255 [05:14<02:56,  1.89s/it][1,0]<stderr>:train:  64% 163/255 [05:16<02:54,  1.90s/it][1,0]<stderr>:train:  64% 164/255 [05:18<02:52,  1.90s/it][1,0]<stderr>:train:  65% 165/255 [05:20<02:46,  1.85s/it][1,0]<stderr>:train:  65% 166/255 [05:21<02:41,  1.82s/it][1,0]<stderr>:train:  65% 167/255 [05:23<02:39,  1.81s/it][1,0]<stderr>:train:  66% 168/255 [05:25<02:40,  1.84s/it][1,0]<stderr>:train:  66% 169/255 [05:27<02:40,  1.86s/it][1,0]<stderr>:train:  67% 170/255 [05:29<02:38,  1.87s/it][1,0]<stderr>:train:  67% 171/255 [05:31<02:37,  1.88s/it][1,0]<stderr>:train:  67% 172/255 [05:33<02:36,  1.88s/it][1,0]<stderr>:train:  68% 173/255 [05:34<02:30,  1.83s/it][1,0]<stderr>:train:  68% 174/255 [05:36<02:25,  1.80s/it][1,0]<stderr>:train:  69% 175/255 [05:38<02:22,  1.79s/it][1,0]<stderr>:train:  69% 176/255 [05:40<02:24,  1.83s/it][1,0]<stderr>:train:  69% 177/255 [05:42<02:24,  1.85s/it][1,0]<stderr>:train:  70% 178/255 [05:44<02:23,  1.86s/it][1,0]<stderr>:train:  70% 179/255 [05:45<02:22,  1.88s/it][1,0]<stderr>:train:  71% 180/255 [05:47<02:21,  1.88s/it][1,0]<stderr>:train:  71% 181/255 [05:49<02:17,  1.85s/it][1,0]<stderr>:train:  71% 182/255 [05:51<02:12,  1.82s/it][1,0]<stderr>:train:  72% 183/255 [05:53<02:12,  1.84s/it][1,0]<stderr>:train:  72% 184/255 [05:55<02:11,  1.85s/it][1,0]<stderr>:train:  73% 185/255 [05:56<02:07,  1.82s/it][1,0]<stderr>:train:  73% 186/255 [05:58<02:03,  1.79s/it][1,0]<stderr>:train:  73% 187/255 [06:00<02:00,  1.77s/it][1,0]<stderr>:train:  74% 188/255 [06:02<02:00,  1.80s/it][1,0]<stderr>:train:  74% 189/255 [06:04<02:01,  1.83s/it][1,0]<stderr>:train:  75% 190/255 [06:05<01:57,  1.81s/it][1,0]<stderr>:train:  75% 191/255 [06:07<01:57,  1.84s/it][1,0]<stderr>:train:  75% 192/255 [06:09<01:57,  1.86s/it][1,0]<stderr>:train:  76% 193/255 [06:11<01:56,  1.88s/it][1,0]<stderr>:train:  76% 194/255 [06:13<01:54,  1.88s/it][1,0]<stderr>:train:  76% 195/255 [06:15<01:53,  1.89s/it][1,0]<stderr>:train:  77% 196/255 [06:17<01:51,  1.89s/it][1,0]<stderr>:train:  77% 197/255 [06:19<01:49,  1.89s/it][1,0]<stderr>:train:  78% 198/255 [06:20<01:45,  1.85s/it][1,0]<stderr>:train:  78% 199/255 [06:22<01:44,  1.86s/it][1,0]<stderr>:train:  78% 200/255 [06:24<01:43,  1.88s/it][1,0]<stderr>:train:  79% 201/255 [06:26<01:39,  1.83s/it][1,0]<stderr>:train:  79% 202/255 [06:28<01:37,  1.84s/it][1,0]<stderr>:train:  80% 203/255 [06:30<01:36,  1.86s/it][1,0]<stderr>:train:  80% 204/255 [06:32<01:35,  1.87s/it][1,0]<stderr>:train:  80% 205/255 [06:33<01:31,  1.84s/it][1,0]<stderr>:train:  81% 206/255 [06:35<01:28,  1.80s/it][1,0]<stderr>:train:  81% 207/255 [06:37<01:27,  1.83s/it][1,0]<stderr>:train:  82% 208/255 [06:39<01:27,  1.85s/it][1,0]<stderr>:train:  82% 209/255 [06:41<01:25,  1.87s/it][1,0]<stderr>:train:  82% 210/255 [06:43<01:22,  1.83s/it][1,0]<stderr>:train:  83% 211/255 [06:44<01:21,  1.84s/it][1,0]<stderr>:train:  83% 212/255 [06:46<01:19,  1.86s/it][1,0]<stderr>:train:  84% 213/255 [06:48<01:18,  1.87s/it][1,0]<stderr>:train:  84% 214/255 [06:50<01:16,  1.88s/it][1,0]<stderr>:train:  84% 215/255 [06:52<01:13,  1.84s/it][1,0]<stderr>:train:  85% 216/255 [06:54<01:12,  1.85s/it][1,0]<stderr>:train:  85% 217/255 [06:56<01:11,  1.87s/it][1,0]<stderr>:train:  85% 218/255 [06:58<01:09,  1.88s/it][1,0]<stderr>:train:  86% 219/255 [06:59<01:07,  1.87s/it][1,0]<stderr>:train:  86% 220/255 [07:01<01:05,  1.87s/it][1,0]<stderr>:train:  87% 221/255 [07:03<01:04,  1.88s/it][1,0]<stderr>:train:  87% 222/255 [07:05<01:00,  1.84s/it][1,0]<stderr>:train:  87% 223/255 [07:07<00:58,  1.82s/it][1,0]<stderr>:train:  88% 224/255 [07:09<00:56,  1.83s/it][1,0]<stderr>:train:  88% 225/255 [07:11<00:55,  1.86s/it][1,0]<stderr>:train:  89% 226/255 [07:12<00:53,  1.84s/it][1,0]<stderr>:train:  89% 227/255 [07:14<00:50,  1.82s/it][1,0]<stderr>:train:  89% 228/255 [07:16<00:49,  1.84s/it][1,0]<stderr>:train:  90% 229/255 [07:18<00:48,  1.85s/it][1,0]<stderr>:train:  90% 230/255 [07:20<00:46,  1.87s/it][1,0]<stderr>:train:  91% 231/255 [07:22<00:44,  1.87s/it][1,0]<stderr>:train:  91% 232/255 [07:23<00:42,  1.84s/it][1,0]<stderr>:train:  91% 233/255 [07:25<00:39,  1.81s/it][1,0]<stderr>:train:  92% 234/255 [07:27<00:39,  1.86s/it][1,0]<stderr>:train:  92% 235/255 [07:29<00:37,  1.88s/it][1,0]<stderr>:train:  93% 236/255 [07:31<00:35,  1.88s/it][1,0]<stderr>:train:  93% 237/255 [07:33<00:33,  1.89s/it][1,0]<stderr>:train:  93% 238/255 [07:35<00:31,  1.84s/it][1,0]<stderr>:train:  94% 239/255 [07:37<00:29,  1.87s/it][1,0]<stderr>:train:  94% 240/255 [07:38<00:28,  1.88s/it][1,0]<stderr>:train:  95% 241/255 [07:40<00:26,  1.88s/it][1,0]<stderr>:train:  95% 242/255 [07:42<00:24,  1.85s/it][1,0]<stderr>:train:  95% 243/255 [07:44<00:22,  1.86s/it][1,0]<stderr>:train:  96% 244/255 [07:46<00:20,  1.83s/it][1,0]<stderr>:train:  96% 245/255 [07:48<00:18,  1.83s/it][1,0]<stderr>:train:  96% 246/255 [07:49<00:16,  1.85s/it][1,0]<stderr>:train:  97% 247/255 [07:51<00:14,  1.87s/it][1,0]<stderr>:train:  97% 248/255 [07:53<00:13,  1.87s/it][1,0]<stderr>:train:  98% 249/255 [07:55<00:11,  1.88s/it][1,0]<stderr>:train:  98% 250/255 [07:57<00:09,  1.88s/it][1,0]<stderr>:train:  98% 251/255 [07:59<00:07,  1.83s/it][1,0]<stderr>:train:  99% 252/255 [08:00<00:05,  1.80s/it][1,0]<stderr>:train:  99% 253/255 [08:02<00:03,  1.79s/it][1,0]<stderr>:train: 100% 254/255 [08:04<00:01,  1.77s/it][1,0]<stderr>:train: 100% 255/255 [08:05<00:00,  1.56s/it][1,0]<stderr>:train: 100% 255/255 [08:05<00:00,  1.90s/it][1,1]<stdout>:         886344 function calls (872517 primitive calls) in 486.736 seconds
[1,1]<stdout>:
[1,1]<stdout>:   Ordered by: internal time
[1,1]<stdout>:
[1,1]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,1]<stdout>:    15045  185.672    0.012  185.672    0.012 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,1]<stdout>:      255  182.071    0.714  182.071    0.714 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,1]<stdout>:      511   97.657    0.191   97.657    0.191 {method 'item' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        4   13.285    3.321   13.285    3.321 {method 'write' of '_io.BufferedWriter' objects}
[1,1]<stdout>:      809    3.903    0.005    3.903    0.005 {method 'acquire' of '_thread.lock' objects}
[1,1]<stdout>:    15045    1.007    0.000  186.681    0.012 mpi_ops.py:928(synchronize)
[1,1]<stdout>:    29580    0.457    0.000    0.457    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.360    0.000    0.360    0.000 {built-in method conv2d}
[1,1]<stdout>:    15045    0.315    0.000    0.315    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.206    0.000    0.206    0.000 {built-in method batch_norm}
[1,1]<stdout>:    14790    0.159    0.000    0.159    0.000 {method 'set_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    14790    0.137    0.000    0.137    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.131    0.000    0.421    0.000 batchnorm.py:99(forward)
[1,1]<stdout>:      510    0.113    0.000    0.113    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:14280/510    0.099    0.000    1.312    0.003 module.py:710(_call_impl)
[1,1]<stdout>:      255    0.097    0.000  185.900    0.729 optimizer.py:232(synchronize)
[1,1]<stdout>:        1    0.079    0.079  486.736  486.736 train.py:338(train)
[1,1]<stdout>:      765    0.078    0.000    0.078    0.000 {built-in method addmm}
[1,1]<stdout>:     3825    0.077    0.000    0.077    0.000 {built-in method relu_}
[1,1]<stdout>:    88740    0.077    0.000    0.087    0.000 tensor.py:725(grad)
[1,1]<stdout>:        8    0.060    0.007    0.060    0.008 {method 'dump' of '_pickle.Pickler' objects}
[1,1]<stdout>:      255    0.057    0.000    0.856    0.003 sgd.py:75(step)
[1,1]<stdout>:     1275    0.055    0.000    0.055    0.000 {built-in method max_pool2d}
[1,1]<stdout>:      255    0.028    0.000    0.215    0.001 optimizer.py:166(zero_grad)
[1,1]<stdout>:    29070    0.025    0.000    0.025    0.000 module.py:758(__getattr__)
[1,1]<stdout>:      510    0.025    0.000    1.233    0.002 container.py:115(forward)
[1,1]<stdout>:     3370    0.024    0.000    0.028    0.000 module.py:774(__setattr__)
[1,1]<stdout>:       14    0.021    0.001    0.021    0.001 {method 'poll' of 'select.poll' objects}
[1,1]<stdout>:     3315    0.019    0.000    0.245    0.000 functional.py:1998(batch_norm)
[1,1]<stdout>:      510    0.017    0.000    0.017    0.000 {built-in method dropout}
[1,1]<stdout>:      765    0.015    0.000    0.015    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:   159020    0.014    0.000    0.014    0.000 {built-in method builtins.isinstance}
[1,1]<stdout>:    14790    0.013    0.000    0.013    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    14280    0.013    0.000    0.013    0.000 {built-in method torch._C._get_tracing_state}
[1,1]<stdout>:    44370    0.012    0.000    0.020    0.000 tensor.py:458(__hash__)
[1,1]<stdout>:     3315    0.012    0.000    0.373    0.000 conv.py:410(_conv_forward)
[1,1]<stdout>:      255    0.012    0.000    0.012    0.000 {built-in method torch._C._nn.nll_loss}
[1,1]<stdout>:    90530    0.012    0.000    0.012    0.000 {built-in method builtins.hasattr}
[1,1]<stdout>:      255    0.011    0.000    0.011    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,1]<stdout>:     3315    0.011    0.000    0.388    0.000 conv.py:418(forward)
[1,1]<stdout>:      256    0.010    0.000    0.020    0.000 sampler.py:206(__iter__)
[1,1]<stdout>:      255    0.010    0.000    0.010    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.009    0.000    0.010    0.000 functional.py:1980(_verify_batch_size)
[1,1]<stdout>:      255    0.009    0.000    1.127    0.004 {built-in method apply}
[1,1]<stdout>:    57630    0.008    0.000    0.008    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,1]<stdout>:51523/51520    0.008    0.000    0.008    0.000 {built-in method builtins.len}
[1,1]<stdout>:    44399    0.008    0.000    0.008    0.000 {built-in method builtins.id}
[1,1]<stdout>:      255    0.007    0.000    0.007    0.000 {built-in method ones_like}
[1,1]<stdout>:     3825    0.007    0.000    0.085    0.000 functional.py:1106(relu)
[1,1]<stdout>:      255    0.007    0.000  182.092    0.714 tensor.py:155(backward)
[1,1]<stdout>:      255    0.006    0.000    0.006    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,1]<stdout>:     1275    0.006    0.000    0.068    0.000 pooling.py:156(forward)
[1,1]<stdout>:     3825    0.006    0.000    0.091    0.000 activation.py:101(forward)
[1,1]<stdout>:      765    0.006    0.000    0.104    0.000 functional.py:1655(linear)
[1,1]<stdout>:     4080    0.006    0.000    0.006    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.005    0.000    1.270    0.005 vgg.py:42(forward)
[1,1]<stdout>:      255    0.005    0.000    0.005    0.000 {built-in method tensor}
[1,1]<stdout>:      255    0.005    0.000  186.769    0.732 optimizer.py:337(step)
[1,1]<stdout>:      255    0.005    0.000  186.774    0.732 lr_scheduler.py:62(wrapper)
[1,1]<stdout>:      255    0.005    0.000    0.005    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      510    0.004    0.000    0.023    0.000 functional.py:950(dropout)
[1,1]<stdout>:        8    0.004    0.001    0.065    0.008 reduction.py:58(dump)
[1,1]<stdout>:      256    0.004    0.000    3.968    0.015 dataloader.py:945(_next_data)
[1,1]<stdout>:      255    0.004    0.000  182.085    0.714 __init__.py:57(backward)
[1,1]<stdout>:      255    0.004    0.000    0.004    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        6    0.003    0.001    0.003    0.001 {built-in method _thread.start_new_thread}
[1,1]<stdout>:      255    0.003    0.000    0.003    0.000 {built-in method flatten}
[1,1]<stdout>:      255    0.003    0.000    0.011    0.000 __init__.py:25(_make_grads)
[1,1]<stdout>:      255    0.003    0.000    3.907    0.015 queue.py:153(get)
[1,1]<stdout>:      255    0.003    0.000    1.119    0.004 mpi_ops.py:191(forward)
[1,1]<stdout>:     1275    0.003    0.000    0.062    0.000 _jit_internal.py:237(fn)
[1,1]<stdout>:     1275    0.003    0.000    0.059    0.000 functional.py:564(_max_pool2d)
[1,1]<stdout>:      255    0.003    0.000    0.006    0.000 train.py:409(adjust_learning_rate)
[1,1]<stdout>:      255    0.003    0.000    0.019    0.000 mpi_ops.py:105(_allreduce_async)
[1,1]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,1]<stdout>:      255    0.003    0.000    0.864    0.003 grad_mode.py:12(decorate_context)
[1,1]<stdout>:        1    0.003    0.003    0.003    0.003 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.003    0.000    1.131    0.004 mpi_ops.py:209(allreduce)
[1,1]<stdout>:      765    0.003    0.000    0.108    0.000 linear.py:90(forward)
[1,1]<stdout>:      256    0.003    0.000    0.003    0.000 basics.py:183(size)
[1,1]<stdout>:     3315    0.003    0.000    0.004    0.000 batchnorm.py:275(_check_input_dim)
[1,1]<stdout>:      521    0.003    0.000    0.005    0.000 threading.py:341(notify)
[1,1]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,1]<stdout>:    15047    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,1]<stdout>:      255    0.003    0.000    0.015    0.000 functional.py:2158(nll_loss)
[1,1]<stdout>:      255    0.003    0.000    3.914    0.015 dataloader.py:912(_get_data)
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:65(__enter__)
[1,1]<stdout>:      256    0.002    0.000   17.342    0.068 std.py:1159(__iter__)
[1,1]<stdout>:      263    0.002    0.000    0.033    0.000 dataloader.py:991(_try_put_index)
[1,1]<stdout>:      260    0.002    0.000    0.010    0.000 queues.py:80(put)
[1,1]<stdout>:      255    0.002    0.000    0.217    0.001 optimizer.py:353(zero_grad)
[1,1]<stdout>:      255    0.002    0.000    0.031    0.000 loss.py:946(forward)
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 utils.py:29(_list_with_default)
[1,1]<stdout>:     3315    0.002    0.000    0.004    0.000 __init__.py:31(__get__)
[1,1]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,1]<stdout>:      255    0.002    0.000    0.026    0.000 mpi_ops.py:152(allreduce_async)
[1,1]<stdout>:      255    0.002    0.000    0.028    0.000 functional.py:2370(cross_entropy)
[1,1]<stdout>:      268    0.002    0.000    0.002    0.000 {method 'release' of '_thread.lock' objects}
[1,1]<stdout>:     4335    0.002    0.000    0.002    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      510    0.002    0.000    0.025    0.000 dropout.py:57(forward)
[1,1]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,1]<stdout>:      255    0.002    0.000    0.016    0.000 functional.py:909(adaptive_avg_pool2d)
[1,1]<stdout>:      255    0.002    0.000    3.909    0.015 dataloader.py:766(_try_get_data)
[1,1]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,1]<stdout>:     2040    0.002    0.000    0.003    0.000 {built-in method builtins.any}
[1,1]<stdout>:        1    0.002    0.002    0.002    0.002 {built-in method randperm}
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,1]<stdout>:      255    0.001    0.000    0.018    0.000 pooling.py:1110(forward)
[1,1]<stdout>:     3315    0.001    0.000    0.001    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,1]<stdout>:      765    0.001    0.000    0.004    0.000 _overrides.py:779(has_torch_function)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}
[1,1]<stdout>:      510    0.001    0.000    0.002    0.000 container.py:107(__iter__)
[1,1]<stdout>:      255    0.001    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,1]<stdout>:      256    0.001    0.000    3.969    0.016 dataloader.py:362(__next__)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 grad_mode.py:149(__init__)
[1,1]<stdout>:       20    0.001    0.000    0.003    0.000 synchronize.py:50(__init__)
[1,1]<stdout>:       88    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,1]<stdout>:      255    0.001    0.000    0.005    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,1]<stdout>:      527    0.001    0.000    0.002    0.000 threading.py:246(__enter__)
[1,1]<stdout>:     2295    0.001    0.000    0.002    0.000 _overrides.py:792(<genexpr>)
[1,1]<stdout>:      255    0.001    0.000    0.026    0.000 dataloader.py:1010(_process_data)
[1,1]<stdout>:      510    0.001    0.000    0.001    0.000 _VF.py:13(__getattr__)
[1,1]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}
[1,1]<stdout>:      255    0.001    0.000    0.007    0.000 mpi_ops.py:92(_check_function)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,1]<stdout>:      875    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,1]<stdout>:      269    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}
[1,1]<stdout>:      256    0.001    0.000    0.002    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,1]<stdout>:      601    0.001    0.000    0.022    0.000 {built-in method builtins.next}
[1,1]<stdout>:      255    0.001    0.000    0.011    0.000 functional.py:1567(log_softmax)
[1,1]<stdout>:        1    0.001    0.001    0.005    0.005 distributed.py:68(__iter__)
[1,1]<stdout>:      266    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 queue.py:216(_get)
[1,1]<stdout>:      527    0.000    0.000    0.001    0.000 threading.py:249(__exit__)
[1,1]<stdout>:      512    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
[1,1]<stdout>:        4    0.000    0.000   13.351    3.338 popen_forkserver.py:41(_launch)
[1,1]<stdout>:      529    0.000    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,1]<stdout>:      263    0.000    0.000    0.021    0.000 dataloader.py:356(_next_index)
[1,1]<stdout>:        1    0.000    0.000   13.369   13.369 dataloader.py:690(__init__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,1]<stdout>:      257    0.000    0.000    0.000    0.000 queue.py:208(_qsize)
[1,1]<stdout>:       34    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,1]<stdout>:      295    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,1]<stdout>:       14    0.000    0.000    0.022    0.002 connection.py:917(wait)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,1]<stdout>:      160    0.000    0.000    0.001    0.000 random.py:285(choice)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,1]<stdout>:        1    0.000    0.000  486.736  486.736 {built-in method builtins.exec}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,1]<stdout>:        5    0.000    0.000    0.003    0.001 queues.py:158(_start_thread)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,1]<stdout>:      527    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,1]<stdout>:       15    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,1]<stdout>:       40    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,1]<stdout>:        5    0.000    0.000    0.004    0.001 queues.py:36(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.004    0.001 context.py:100(Queue)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,1]<stdout>:      273    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:761(__init__)
[1,1]<stdout>:      269    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,1]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,1]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,1]<stdout>:        4    0.000    0.000   13.352    3.338 process.py:110(start)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,1]<stdout>:       48    0.000    0.000    0.000    0.000 resource_tracker.py:70(ensure_running)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    0.000    0.000  486.736  486.736 <string>:1(<module>)
[1,1]<stdout>:       29    0.000    0.000    0.002    0.000 util.py:205(__call__)
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,1]<stdout>:        4    0.000    0.000    0.001    0.000 forkserver.py:76(connect_to_new_process)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,1]<stdout>:        8    0.000    0.000    3.902    0.488 threading.py:270(wait)
[1,1]<stdout>:      273    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,1]<stdout>:        4    0.000    0.000   13.351    3.338 popen_fork.py:15(__init__)
[1,1]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,1]<stdout>:       14    0.000    0.000    0.021    0.001 selectors.py:402(select)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,1]<stdout>:       11    0.000    0.000    0.002    0.000 context.py:65(Lock)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,1]<stdout>:        2    0.000    0.000    0.023    0.012 dataloader.py:1040(_shutdown_workers)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,1]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,1]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method posix.close}
[1,1]<stdout>:     55/1    0.000    0.000    0.000    0.000 module.py:1253(train)
[1,1]<stdout>:        6    0.000    0.000    0.006    0.001 threading.py:834(start)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,1]<stdout>:        6    0.000    0.000    0.002    0.000 threading.py:540(wait)
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,1]<stdout>:       11    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,1]<stdout>:       48    0.000    0.000    0.000    0.000 resource_tracker.py:134(_check_alive)
[1,1]<stdout>:        4    0.000    0.000   13.352    3.338 context.py:288(_Popen)
[1,1]<stdout>:      272    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,1]<stdout>:        4    0.000    0.000    0.021    0.005 popen_fork.py:40(wait)
[1,1]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 reduction.py:145(sendfds)
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,1]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,1]<stdout>:      104    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,1]<stdout>:        4    0.000    0.000    0.021    0.005 process.py:142(join)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,1]<stdout>:       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:128(is_initialized)
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e8bf7bc9a0}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,1]<stdout>:       50    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,1]<stdout>:        4    0.000    0.000    0.001    0.000 process.py:61(_cleanup)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,1]<stdout>:       70    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,1]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 resource_tracker.py:145(register)
[1,1]<stdout>:        1    0.000    0.000   13.369   13.369 dataloader.py:287(__iter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,1]<stdout>:        4    0.000    0.000   13.351    3.338 popen_forkserver.py:33(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:134(close)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7fe279c02c10}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:200(_finalize_close)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:149(unregister)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:846(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:382(current_device)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,1]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,1]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,1]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:161(_lazy_init)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:104(acquire)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,1]<stdout>:       29    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,1]<stdout>:       18    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:90(Event)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:108(release)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,1]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,1]<stdout>:        1    0.000    0.000    0.001    0.001 threading.py:979(join)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:75(Condition)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,1]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:this epoch's train spend:486.7454719543457s
[1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stdout>:         932540 function calls (918713 primitive calls) in 485.579 seconds
[1,0]<stdout>:
[1,0]<stdout>:   Ordered by: internal time
[1,0]<stdout>:
[1,0]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,0]<stdout>:    15045  182.665    0.012  182.665    0.012 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,0]<stdout>:      255  181.343    0.711  181.343    0.711 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,0]<stdout>:      511  101.047    0.198  101.047    0.198 {method 'item' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        4   12.112    3.028   12.112    3.028 {method 'write' of '_io.BufferedWriter' objects}
[1,0]<stdout>:     1072    3.840    0.004    3.840    0.004 {method 'acquire' of '_thread.lock' objects}
[1,0]<stdout>:    15045    1.101    0.000  183.769    0.012 mpi_ops.py:928(synchronize)
[1,0]<stdout>:     3315    0.405    0.000    0.405    0.000 {built-in method conv2d}
[1,0]<stdout>:    29580    0.398    0.000    0.398    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    15045    0.321    0.000    0.321    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315    0.207    0.000    0.207    0.000 {built-in method batch_norm}
[1,0]<stdout>:    14790    0.157    0.000    0.157    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    14790    0.146    0.000    0.146    0.000 {method 'set_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      510    0.130    0.000    0.130    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315    0.125    0.000    0.423    0.000 batchnorm.py:99(forward)
[1,0]<stdout>:14280/510    0.107    0.000    1.360    0.003 module.py:710(_call_impl)
[1,0]<stdout>:      255    0.103    0.000  183.189    0.718 optimizer.py:232(synchronize)
[1,0]<stdout>:      267    0.100    0.000    0.100    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,0]<stdout>:        1    0.094    0.094  485.578  485.578 train.py:338(train)
[1,0]<stdout>:     3825    0.091    0.000    0.091    0.000 {built-in method relu_}
[1,0]<stdout>:    88740    0.083    0.000    0.094    0.000 tensor.py:725(grad)
[1,0]<stdout>:        8    0.070    0.009    0.071    0.009 {method 'dump' of '_pickle.Pickler' objects}
[1,0]<stdout>:      765    0.063    0.000    0.063    0.000 {built-in method addmm}
[1,0]<stdout>:      255    0.058    0.000    0.804    0.003 sgd.py:75(step)
[1,0]<stdout>:     1275    0.053    0.000    0.053    0.000 {built-in method max_pool2d}
[1,0]<stdout>:      255    0.032    0.000    0.247    0.001 optimizer.py:166(zero_grad)
[1,0]<stdout>:      510    0.026    0.000    1.280    0.003 container.py:115(forward)
[1,0]<stdout>:     3370    0.025    0.000    0.029    0.000 module.py:774(__setattr__)
[1,0]<stdout>:    29070    0.024    0.000    0.024    0.000 module.py:758(__getattr__)
[1,0]<stdout>:       14    0.023    0.002    0.023    0.002 {method 'poll' of 'select.poll' objects}
[1,0]<stdout>:     3315    0.021    0.000    0.249    0.000 functional.py:1998(batch_norm)
[1,0]<stdout>:      510    0.021    0.000    0.021    0.000 {built-in method dropout}
[1,0]<stdout>:    14790    0.017    0.000    0.017    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.016    0.000    0.056    0.000 summary.py:137(scalar)
[1,0]<stdout>:   160553    0.016    0.000    0.016    0.000 {built-in method builtins.isinstance}
[1,0]<stdout>:    14280    0.013    0.000    0.013    0.000 {built-in method torch._C._get_tracing_state}
[1,0]<stdout>:    44370    0.013    0.000    0.021    0.000 tensor.py:458(__hash__)
[1,0]<stdout>:      255    0.012    0.000    0.012    0.000 {built-in method torch._C._nn.nll_loss}
[1,0]<stdout>:     3315    0.012    0.000    0.419    0.000 conv.py:410(_conv_forward)
[1,0]<stdout>:    91045    0.012    0.000    0.012    0.000 {built-in method builtins.hasattr}
[1,0]<stdout>:      257    0.012    0.000    0.022    0.000 std.py:355(format_meter)
[1,0]<stdout>:      256    0.011    0.000    0.020    0.000 sampler.py:206(__iter__)
[1,0]<stdout>:     3315    0.010    0.000    0.011    0.000 functional.py:1980(_verify_batch_size)
[1,0]<stdout>:      255    0.010    0.000    0.923    0.004 {built-in method apply}
[1,0]<stdout>:      255    0.009    0.000    0.009    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315    0.009    0.000    0.432    0.000 conv.py:418(forward)
[1,0]<stdout>:      255    0.009    0.000    0.027    0.000 x2num.py:11(check_nan)
[1,0]<stdout>:    57630    0.009    0.000    0.009    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,0]<stdout>:      255    0.008    0.000    0.008    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,0]<stdout>:    44399    0.008    0.000    0.008    0.000 {built-in method builtins.id}
[1,0]<stdout>:     3825    0.008    0.000    0.099    0.000 functional.py:1106(relu)
[1,0]<stdout>:      255    0.008    0.000    0.008    0.000 {method 'reduce' of 'numpy.ufunc' objects}
[1,0]<stdout>:      255    0.007    0.000    0.007    0.000 {built-in method ones_like}
[1,0]<stdout>:      765    0.007    0.000    0.082    0.000 functional.py:1655(linear)
[1,0]<stdout>:51524/51521    0.007    0.000    0.007    0.000 {built-in method builtins.len}
[1,0]<stdout>:      255    0.007    0.000    0.165    0.001 std.py:1197(update)
[1,0]<stdout>:      765    0.007    0.000    0.007    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        8    0.007    0.001    0.077    0.010 reduction.py:58(dump)
[1,0]<stdout>:     3825    0.006    0.000    0.106    0.000 activation.py:101(forward)
[1,0]<stdout>:      255    0.006    0.000  181.364    0.711 tensor.py:155(backward)
[1,0]<stdout>:      255    0.006    0.000  184.008    0.722 optimizer.py:337(step)
[1,0]<stdout>:      515    0.006    0.000    0.023    0.000 queues.py:80(put)
[1,0]<stdout>:      255    0.006    0.000    0.006    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,0]<stdout>:    11449    0.006    0.000    0.008    0.000 utils.py:330(<genexpr>)
[1,0]<stdout>:      255    0.006    0.000    0.006    0.000 {built-in method tensor}
[1,0]<stdout>:     4080    0.006    0.000    0.006    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      256    0.006    0.000   16.287    0.064 std.py:1159(__iter__)
[1,0]<stdout>:      255    0.005    0.000  184.014    0.722 lr_scheduler.py:62(wrapper)
[1,0]<stdout>:     1275    0.005    0.000    0.065    0.000 pooling.py:156(forward)
[1,0]<stdout>:      255    0.005    0.000    1.314    0.005 vgg.py:42(forward)
[1,0]<stdout>:     1575    0.005    0.000    0.005    0.000 {method 'format' of 'str' objects}
[1,0]<stdout>:      255    0.005    0.000    0.005    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.004    0.000    0.022    0.000 writer.py:131(add_summary)
[1,0]<stdout>:      510    0.004    0.000    0.027    0.000 functional.py:950(dropout)
[1,0]<stdout>:      256    0.004    0.000    3.905    0.015 dataloader.py:945(_next_data)
[1,0]<stdout>:      776    0.004    0.000    0.009    0.000 threading.py:341(notify)
[1,0]<stdout>:      255    0.004    0.000  181.358    0.711 __init__.py:57(backward)
[1,0]<stdout>:      255    0.004    0.000    0.037    0.000 x2num.py:18(make_np)
[1,0]<stdout>:      255    0.004    0.000    0.084    0.000 writer.py:401(add_scalar)
[1,0]<stdout>:     1530    0.004    0.000    0.004    0.000 std.py:233(__call__)
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {built-in method numpy.array}
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {built-in method flatten}
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      256    0.004    0.000    0.004    0.000 {built-in method now}
[1,0]<stdout>:      524    0.004    0.000    0.004    0.000 {method 'release' of '_thread.lock' objects}
[1,0]<stdout>:      255    0.003    0.000    0.017    0.000 writer.py:115(add_event)
[1,0]<stdout>:      255    0.003    0.000    0.813    0.003 grad_mode.py:12(decorate_context)
[1,0]<stdout>:      255    0.003    0.000    3.849    0.015 dataloader.py:912(_get_data)
[1,0]<stdout>:      257    0.003    0.000    0.004    0.000 std.py:1445(format_dict)
[1,0]<stdout>:      255    0.003    0.000    0.914    0.004 mpi_ops.py:191(forward)
[1,0]<stdout>:     1275    0.003    0.000    0.060    0.000 _jit_internal.py:237(fn)
[1,0]<stdout>:     1275    0.003    0.000    0.057    0.000 functional.py:564(_max_pool2d)
[1,0]<stdout>:      511    0.003    0.000    0.003    0.000 basics.py:183(size)
[1,0]<stdout>:      255    0.003    0.000    0.011    0.000 __init__.py:25(_make_grads)
[1,0]<stdout>:     3315    0.003    0.000    0.005    0.000 batchnorm.py:275(_check_input_dim)
[1,0]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,0]<stdout>:    15051    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,0]<stdout>:      256    0.003    0.000    0.155    0.001 std.py:1324(refresh)
[1,0]<stdout>:        1    0.003    0.003    0.003    0.003 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      765    0.003    0.000    0.086    0.000 linear.py:90(forward)
[1,0]<stdout>:      255    0.003    0.000    0.926    0.004 mpi_ops.py:209(allreduce)
[1,0]<stdout>:      255    0.003    0.000    0.014    0.000 fromnumeric.py:2123(sum)
[1,0]<stdout>:      263    0.003    0.000    0.032    0.000 dataloader.py:991(_try_put_index)
[1,0]<stdout>:      255    0.003    0.000    3.841    0.015 queue.py:153(get)
[1,0]<stdout>:     3315    0.003    0.000    0.004    0.000 __init__.py:31(__get__)
[1,0]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,0]<stdout>:      255    0.003    0.000    0.005    0.000 train.py:409(adjust_learning_rate)
[1,0]<stdout>:      255    0.003    0.000    0.019    0.000 mpi_ops.py:105(_allreduce_async)
[1,0]<stdout>:      255    0.003    0.000    0.016    0.000 functional.py:2158(nll_loss)
[1,0]<stdout>:      255    0.003    0.000    0.250    0.001 optimizer.py:353(zero_grad)
[1,0]<stdout>:      255    0.002    0.000    0.011    0.000 fromnumeric.py:69(_wrapreduction)
[1,0]<stdout>:    11192    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
[1,0]<stdout>:      257    0.002    0.000    0.118    0.000 std.py:348(print_status)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 utils.py:29(_list_with_default)
[1,0]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,0]<stdout>:      257    0.002    0.000    0.148    0.001 std.py:1463(display)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:65(__enter__)
[1,0]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,0]<stdout>:      257    0.002    0.000    0.028    0.000 std.py:1149(__str__)
[1,0]<stdout>:      255    0.002    0.000    0.027    0.000 mpi_ops.py:152(allreduce_async)
[1,0]<stdout>:      255    0.002    0.000    0.002    0.000 numeric.py:1858(isscalar)
[1,0]<stdout>:      255    0.002    0.000    0.014    0.000 functional.py:909(adaptive_avg_pool2d)
[1,0]<stdout>:      255    0.002    0.000    0.031    0.000 loss.py:946(forward)
[1,0]<stdout>:     4335    0.002    0.000    0.002    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.002    0.000    0.018    0.000 <__array_function__ internals>:2(sum)
[1,0]<stdout>:      512    0.002    0.000    0.002    0.000 {method 'sub' of 're.Pattern' objects}
[1,0]<stdout>:      255    0.002    0.000    0.014    0.000 event_file_writer.py:132(add_event)
[1,0]<stdout>:      255    0.002    0.000    3.843    0.015 dataloader.py:766(_try_get_data)
[1,0]<stdout>:      255    0.002    0.000    0.029    0.000 functional.py:2370(cross_entropy)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,0]<stdout>:      257    0.002    0.000    0.010    0.000 {built-in method builtins.sum}
[1,0]<stdout>:      260    0.002    0.000    0.002    0.000 std.py:104(acquire)
[1,0]<stdout>:      255    0.002    0.000    0.016    0.000 pooling.py:1110(forward)
[1,0]<stdout>:      255    0.002    0.000    0.002    0.000 {built-in method builtins.sorted}
[1,0]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,0]<stdout>:     2040    0.002    0.000    0.003    0.000 {built-in method builtins.any}
[1,0]<stdout>:      255    0.002    0.000    0.002    0.000 writer.py:318(_check_caffe2_blob)
[1,0]<stdout>:        1    0.002    0.002    0.002    0.002 {built-in method randperm}
[1,0]<stdout>:      765    0.002    0.000    0.004    0.000 _overrides.py:779(has_torch_function)
[1,0]<stdout>:      260    0.002    0.000    0.002    0.000 std.py:108(release)
[1,0]<stdout>:     3315    0.001    0.000    0.001    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,0]<stdout>:      510    0.001    0.000    0.028    0.000 dropout.py:57(forward)
[1,0]<stdout>:       20    0.001    0.000    0.004    0.000 synchronize.py:50(__init__)
[1,0]<stdout>:      255    0.001    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,0]<stdout>:      513    0.001    0.000    0.004    0.000 std.py:288(format_interval)
[1,0]<stdout>:      257    0.001    0.000    0.102    0.000 std.py:342(fp_write)
[1,0]<stdout>:      255    0.001    0.000    0.015    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}
[1,0]<stdout>:      783    0.001    0.000    0.002    0.000 threading.py:246(__enter__)
[1,0]<stdout>:      510    0.001    0.000    0.002    0.000 container.py:107(__iter__)
[1,0]<stdout>:      256    0.001    0.000    3.906    0.015 dataloader.py:362(__next__)
[1,0]<stdout>:      255    0.001    0.000    0.003    0.000 summary.py:28(_clean_tag)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 grad_mode.py:149(__init__)
[1,0]<stdout>:      779    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:      255    0.001    0.000    0.005    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,0]<stdout>:      783    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}
[1,0]<stdout>:      255    0.001    0.000    0.025    0.000 dataloader.py:1010(_process_data)
[1,0]<stdout>:     2295    0.001    0.000    0.002    0.000 _overrides.py:792(<genexpr>)
[1,0]<stdout>:      257    0.001    0.000    0.012    0.000 utils.py:333(disp_len)
[1,0]<stdout>:        7    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 writer.py:333(_get_file_writer)
[1,0]<stdout>:       80    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,0]<stdout>:      510    0.001    0.000    0.002    0.000 _VF.py:13(__getattr__)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 queue.py:216(_get)
[1,0]<stdout>:      269    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}
[1,0]<stdout>:      257    0.001    0.000    0.011    0.000 utils.py:329(_text_width)
[1,0]<stdout>:      255    0.001    0.000    0.007    0.000 mpi_ops.py:92(_check_function)
[1,0]<stdout>:      881    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,0]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,0]<stdout>:      255    0.001    0.000    0.010    0.000 functional.py:1567(log_softmax)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,0]<stdout>:        4    0.001    0.000    0.001    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,0]<stdout>:      786    0.001    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,0]<stdout>:      783    0.001    0.000    0.001    0.000 threading.py:249(__exit__)
[1,0]<stdout>:        7    0.001    0.000    0.001    0.000 threading.py:761(__init__)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 fromnumeric.py:70(<dictcomp>)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 {method 'replace' of 'str' objects}
[1,0]<stdout>:       21    0.001    0.000    0.001    0.000 {built-in method posix.close}
[1,0]<stdout>:        1    0.001    0.001    0.005    0.005 distributed.py:68(__iter__)
[1,0]<stdout>:      603    0.001    0.000    0.021    0.000 {built-in method builtins.next}
[1,0]<stdout>:      512    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
[1,0]<stdout>:        1    0.000    0.000  485.579  485.579 {built-in method builtins.exec}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
[1,0]<stdout>:      516    0.000    0.000    0.101    0.000 utils.py:143(inner)
[1,0]<stdout>:      257    0.000    0.000    0.000    0.000 {built-in method builtins.max}
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
[1,0]<stdout>:      256    0.000    0.000    0.002    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,0]<stdout>:       36    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,0]<stdout>:     1026    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,0]<stdout>:     1277    0.000    0.000    0.000    0.000 {built-in method time.time}
[1,0]<stdout>:        6    0.000    0.000    0.005    0.001 queues.py:158(_start_thread)
[1,0]<stdout>:      263    0.000    0.000    0.020    0.000 dataloader.py:356(_next_index)
[1,0]<stdout>:     55/1    0.000    0.000    0.001    0.001 module.py:1253(train)
[1,0]<stdout>:        4    0.000    0.000   12.192    3.048 popen_forkserver.py:41(_launch)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,0]<stdout>:        1    0.000    0.000   12.208   12.208 dataloader.py:690(__init__)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,0]<stdout>:      258    0.000    0.000    0.000    0.000 queue.py:208(_qsize)
[1,0]<stdout>:      765    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,0]<stdout>:      160    0.000    0.000    0.001    0.000 random.py:285(choice)
[1,0]<stdout>:      293    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,0]<stdout>:      513    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,0]<stdout>:      783    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,0]<stdout>:      530    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 fromnumeric.py:2118(_sum_dispatcher)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,0]<stdout>:        1    0.000    0.000  485.578  485.578 <string>:1(<module>)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
[1,0]<stdout>:       36    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,0]<stdout>:       14    0.000    0.000    0.024    0.002 connection.py:917(wait)
[1,0]<stdout>:      271    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      261    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:       25    0.000    0.000    0.002    0.000 util.py:205(__call__)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,0]<stdout>:        5    0.000    0.000    0.004    0.001 queues.py:36(__init__)
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,0]<stdout>:       10    0.000    0.000    3.838    0.384 threading.py:270(wait)
[1,0]<stdout>:       44    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,0]<stdout>:      274    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,0]<stdout>:       80    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,0]<stdout>:        4    0.000    0.000    0.002    0.000 forkserver.py:76(connect_to_new_process)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,0]<stdout>:        5    0.000    0.000    0.004    0.001 context.py:100(Queue)
[1,0]<stdout>:       11    0.000    0.000    0.003    0.000 context.py:65(Lock)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 std.py:846(__init__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,0]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,0]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,0]<stdout>:        7    0.000    0.000    0.004    0.001 threading.py:834(start)
[1,0]<stdout>:        4    0.000    0.000   12.193    3.048 process.py:110(start)
[1,0]<stdout>:       16    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,0]<stdout>:        2    0.000    0.000    0.027    0.014 dataloader.py:1040(_shutdown_workers)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,0]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,0]<stdout>:      256    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,0]<stdout>:       44    0.000    0.000    0.001    0.000 resource_tracker.py:134(_check_alive)
[1,0]<stdout>:       80    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,0]<stdout>:       14    0.000    0.000    0.023    0.002 selectors.py:402(select)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,0]<stdout>:        7    0.000    0.000    0.003    0.000 threading.py:540(wait)
[1,0]<stdout>:        4    0.000    0.000   12.192    3.048 popen_fork.py:15(__init__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 reduction.py:145(sendfds)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,0]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,0]<stdout>:       21    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,0]<stdout>:      102    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        4    0.000    0.000    0.023    0.006 popen_fork.py:40(wait)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,0]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:145(register)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,0]<stdout>:        4    0.000    0.000   12.192    3.048 context.py:288(_Popen)
[1,0]<stdout>:       53    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,0]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ee8110b9a0}
[1,0]<stdout>:       72    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_linux)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,0]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,0]<stdout>:        4    0.000    0.000    0.023    0.006 process.py:142(join)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,0]<stdout>:       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:61(_cleanup)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 context.py:80(Semaphore)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:583(_decr_instances)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7f4bc715bc10}
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:200(_finalize_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:134(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,0]<stdout>:        4    0.000    0.000   12.192    3.048 popen_forkserver.py:33(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:128(is_initialized)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,0]<stdout>:       24    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:296(<listcomp>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:670(__getitem__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,0]<stdout>:       16    0.000    0.000    0.001    0.000 resource_tracker.py:149(unregister)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,0]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,0]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:329(status_printer)
[1,0]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:382(current_device)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:161(_lazy_init)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 context.py:75(Condition)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 context.py:90(Event)
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,0]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 synchronize.py:212(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,0]<stdout>:        1    0.000    0.000   12.208   12.208 dataloader.py:287(__iter__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:748(encode)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 synchronize.py:125(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 threading.py:979(join)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 synchronize.py:323(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:171(__eq__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:215(_supports_unicode)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:201(_is_utf)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 std.py:228(__init__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1285(fp_write)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:88(__getattr__)
[1,0]<stdout>:        6    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:231(_screen_shape_wrapper)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1300(<lambda>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:this epoch's train spend:485.59961318969727s
[1,0]<stderr>:
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stderr>:test:   1%|▏         | 1/79 [00:22<29:18, 22.55s/it][1,0]<stderr>:test:   3%|▎         | 2/79 [00:22<11:59,  9.35s/it][1,1]<stderr>:test:   1%|▏         | 1/79 [00:22<29:47, 22.92s/it][1,0]<stderr>:test:   5%|▌         | 4/79 [00:22<04:27,  3.57s/it][1,1]<stderr>:test:   4%|▍         | 3/79 [00:23<07:39,  6.05s/it][1,0]<stderr>:test:   6%|▋         | 5/79 [00:24<03:39,  2.97s/it][1,0]<stderr>:test:   8%|▊         | 6/79 [00:24<02:34,  2.12s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:24<04:07,  3.34s/it][1,0]<stderr>:test:  10%|█         | 8/79 [00:25<01:26,  1.22s/it][1,1]<stderr>:test:   9%|▉         | 7/79 [00:25<02:26,  2.04s/it][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:26<01:31,  1.31s/it][1,0]<stderr>:test:  13%|█▎        | 10/79 [00:26<01:08,  1.01it/s][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:27<01:52,  1.61s/it][1,0]<stderr>:test:  15%|█▌        | 12/79 [00:27<00:42,  1.58it/s][1,1]<stderr>:test:  14%|█▍        | 11/79 [00:27<01:14,  1.09s/it][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:29<01:10,  1.06s/it][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:30<01:20,  1.22s/it][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:32<00:51,  1.19it/s][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:33<01:00,  1.02it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:35<00:45,  1.28it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:35<00:46,  1.24it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:37<00:37,  1.45it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:37<00:37,  1.43it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:40<00:34,  1.46it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:40<00:35,  1.41it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:42<00:29,  1.57it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:42<00:31,  1.46it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:44<00:27,  1.54it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:45<00:27,  1.50it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:47<00:24,  1.55it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:48<00:24,  1.53it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:49<00:20,  1.66it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:50<00:20,  1.63it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:51<00:18,  1.65it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:52<00:17,  1.72it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:54<00:15,  1.69it/s][1,1]<stderr>:test:  70%|██████▉   | 55/79 [00:55<00:13,  1.84it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:55<00:17,  1.47it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [00:58<00:15,  1.40it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:58<00:15,  1.44it/s][1,1]<stderr>:test:  75%|███████▍  | 59/79 [00:58<00:11,  1.68it/s][1,1]<stderr>:test:  77%|███████▋  | 61/79 [01:00<00:12,  1.41it/s][1,1]<stderr>:test:  80%|███████▉  | 63/79 [01:00<00:09,  1.73it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [01:01<00:12,  1.43it/s][1,1]<stderr>:test:  82%|████████▏ | 65/79 [01:03<00:10,  1.36it/s][1,1]<stderr>:test:  85%|████████▍ | 67/79 [01:03<00:06,  1.81it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [01:03<00:09,  1.41it/s][1,1]<stderr>:test:  87%|████████▋ | 69/79 [01:05<00:07,  1.37it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [01:06<00:06,  1.44it/s][1,1]<stderr>:test:  92%|█████████▏| 73/79 [01:08<00:04,  1.34it/s][1,1]<stderr>:test:  95%|█████████▍| 75/79 [01:09<00:02,  1.68it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [01:09<00:04,  1.41it/s][1,1]<stderr>:test:  97%|█████████▋| 77/79 [01:11<00:01,  1.30it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:11<00:00,  1.10it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [01:12<00:01,  1.46it/s][1,0]<stderr>:test:  99%|█████████▊| 78/79 [01:13<00:00,  1.39it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:13<00:00,  1.08it/s][1,0]<stdout>:
[1,0]<stdout>:[acc/test_top1] = 0.400000
[1,1]<stdout>:spend all time:486.7454719543457s
[1,0]<stdout>:[acc/test_top5] = 1.010000
[1,0]<stdout>:[acc/test_top1_best] = 0.400000
[1,0]<stdout>:[save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints
[1,0]<stdout>:spend all time:485.59961318969727s
[1,1]<stdout>:Running your script with the autograd profiler...
[1,0]<stdout>:Running your script with the autograd profiler...
[1,0]<stdout>:==> loading configs from ['configs/imagenet/vgg16_bn.py', 'configs/methods/wm0.py', 'configs/methods/fp16.py', 'configs/methods/int32.py']
[1,0]<stdout>:[train.save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:[seed] = 42
[1,0]<stdout>:[data]
[1,0]<stdout>:  [num_threads_per_worker] = 4
[1,0]<stdout>:[train]
[1,0]<stdout>:  [dgc] = False
[1,0]<stdout>:  [compression]
[1,0]<stdout>:    [func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:    [compress_ratio] = 0.05
[1,0]<stdout>:    [sample_ratio] = 0.01
[1,0]<stdout>:    [strided_sample] = True
[1,0]<stdout>:    [compress_upper_bound] = 1.3
[1,0]<stdout>:    [compress_lower_bound] = 0.8
[1,0]<stdout>:    [max_adaptation_iters] = 10
[1,0]<stdout>:    [resample] = True
[1,0]<stdout>:    [memory]
[1,0]<stdout>:      [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:      [momentum] = 0.9
[1,0]<stdout>:    [warmup_epochs] = 0
[1,0]<stdout>:    [fp16_values] = True
[1,0]<stdout>:    [int32_indices] = True
[1,0]<stdout>:  [criterion]
[1,0]<stdout>:    [func] = <class 'torch.nn.modules.loss.CrossEntropyLoss'>
[1,0]<stdout>:  [optimizer]
[1,0]<stdout>:    [func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:    [momentum] = 0.9
[1,0]<stdout>:    [lr] = 0.025
[1,0]<stdout>:    [weight_decay] = 5e-05
[1,0]<stdout>:  [schedule_lr_per_epoch] = True
[1,0]<stdout>:  [warmup_lr_epochs] = 5
[1,0]<stdout>:  [metric] = acc/test_top1
[1,0]<stdout>:  [meters]
[1,0]<stdout>:    [acc/{}_top1]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 1
[1,0]<stdout>:    [acc/{}_top5]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 5
[1,0]<stdout>:  [optimize_bn_separately] = False
[1,0]<stdout>:  [num_epochs] = 1
[1,0]<stdout>:  [batch_size] = 64
[1,0]<stdout>:  [scheduler]
[1,0]<stdout>:    [func] = <class 'torch.optim.lr_scheduler.MultiStepLR'>
[1,0]<stdout>:    [milestones] = [25, 55, 75]
[1,0]<stdout>:    [gamma] = 0.1
[1,0]<stdout>:  [topk] = False
[1,0]<stdout>:  [fp16] = False
[1,0]<stdout>:  [powersgd] = False
[1,0]<stdout>:  [sign] = False
[1,0]<stdout>:  [efsign] = False
[1,0]<stdout>:  [natural] = False
[1,0]<stdout>:  [onebit] = False
[1,0]<stdout>:  [qsgd] = False
[1,0]<stdout>:  [randomk] = False
[1,0]<stdout>:  [signum] = False
[1,0]<stdout>:  [terngrad] = False
[1,0]<stdout>:  [num_batches_per_step] = 1
[1,0]<stdout>:  [save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:  [checkpoint_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/e{epoch}-r0.pth
[1,0]<stdout>:  [latest_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/latest-r0.pth
[1,0]<stdout>:  [best_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/best-r0.pth
[1,0]<stdout>:  [base_lr] = 0.0125
[1,0]<stdout>:[dataset]
[1,0]<stdout>:  [func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:  [root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [image_size] = 224
[1,0]<stdout>:[model]
[1,0]<stdout>:  [func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [init_weights] = True
[1,0]<stdout>:[device] = cuda
[1,0]<stdout>:
[1,0]<stdout>:==> creating model "[func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[init_weights] = True"[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:==> creating dataset "[func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:[root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[image_size] = 224"
[1,0]<stdout>:
[1,0]<stdout>:==> loading dataset "{'num_workers': 4, 'pin_memory': True, 'multiprocessing_context': 'forkserver'}""
[1,0]<stdout>:
[1,0]<stdout>:==> creating optimizer "[func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:[momentum] = 0.9
[1,0]<stdout>:[lr] = 0.05
[1,0]<stdout>:[weight_decay] = 5e-05"
[1,1]<stdout>:Use hvd.none compression...
[1,0]<stdout>:
[1,0]<stdout>:==> creating compression "[func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:[compress_ratio] = 0.05
[1,0]<stdout>:[sample_ratio] = 0.01
[1,0]<stdout>:[strided_sample] = True
[1,0]<stdout>:[compress_upper_bound] = 1.3
[1,0]<stdout>:[compress_lower_bound] = 0.8
[1,0]<stdout>:[max_adaptation_iters] = 10
[1,0]<stdout>:[resample] = True
[1,0]<stdout>:[memory]
[1,0]<stdout>:  [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:  [momentum] = 0.9
[1,0]<stdout>:[warmup_epochs] = 0
[1,0]<stdout>:[fp16_values] = True
[1,0]<stdout>:[int32_indices] = True"
[1,0]<stdout>:Use hvd.none compression...
[1,0]<stdout>:
[1,0]<stdout>:==> train from scratch
[1,0]<stdout>:
[1,0]<stdout>:==> broadcasting paramters and optimizer state
[1,1]<stdout>:before evaluate
[1,0]<stdout>:before evaluate
[1,1]<stderr>:
[1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stderr>:
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stderr>:test:   1%|▏         | 1/79 [00:15<20:11, 15.53s/it][1,0]<stderr>:test:   1%|▏         | 1/79 [00:15<20:24, 15.70s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:17<03:25,  2.78s/it][1,0]<stderr>:test:   6%|▋         | 5/79 [00:17<03:28,  2.82s/it][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:19<01:45,  1.51s/it][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:19<01:47,  1.53s/it][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:21<01:12,  1.09s/it][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:21<01:11,  1.09s/it][1,1]<stderr>:test:  19%|█▉        | 15/79 [00:21<00:54,  1.18it/s][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:23<00:52,  1.19it/s][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:23<00:53,  1.17it/s][1,1]<stderr>:test:  24%|██▍       | 19/79 [00:23<00:39,  1.53it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:25<00:41,  1.38it/s][1,1]<stderr>:test:  29%|██▉       | 23/79 [00:25<00:30,  1.85it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:26<00:43,  1.34it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:28<00:35,  1.51it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:28<00:37,  1.43it/s][1,1]<stderr>:test:  34%|███▍      | 27/79 [00:28<00:28,  1.81it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:30<00:30,  1.64it/s][1,0]<stderr>:test:  38%|███▊      | 30/79 [00:30<00:27,  1.78it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:30<00:37,  1.34it/s][1,0]<stderr>:test:  39%|███▉      | 31/79 [00:31<00:28,  1.67it/s][1,1]<stderr>:test:  39%|███▉      | 31/79 [00:31<00:26,  1.82it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:32<00:27,  1.69it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:32<00:29,  1.55it/s][1,0]<stderr>:test:  44%|████▍     | 35/79 [00:33<00:24,  1.81it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:34<00:23,  1.82it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:34<00:22,  1.83it/s][1,0]<stderr>:test:  49%|████▉     | 39/79 [00:34<00:17,  2.25it/s][1,1]<stderr>:test:  49%|████▉     | 39/79 [00:34<00:17,  2.22it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:36<00:23,  1.65it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:36<00:21,  1.78it/s][1,1]<stderr>:test:  54%|█████▍    | 43/79 [00:36<00:16,  2.24it/s][1,0]<stderr>:test:  54%|█████▍    | 43/79 [00:37<00:19,  1.86it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:38<00:18,  1.85it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:38<00:19,  1.76it/s][1,1]<stderr>:test:  59%|█████▉    | 47/79 [00:38<00:14,  2.20it/s][1,0]<stderr>:test:  59%|█████▉    | 47/79 [00:39<00:16,  1.93it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:40<00:16,  1.78it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:40<00:17,  1.72it/s][1,1]<stderr>:test:  65%|██████▍   | 51/79 [00:41<00:14,  1.97it/s][1,0]<stderr>:test:  65%|██████▍   | 51/79 [00:41<00:14,  1.91it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:42<00:13,  1.90it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:42<00:15,  1.73it/s][1,1]<stderr>:test:  70%|██████▉   | 55/79 [00:43<00:11,  2.01it/s][1,0]<stderr>:test:  70%|██████▉   | 55/79 [00:43<00:11,  2.05it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [00:44<00:10,  2.03it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:45<00:12,  1.73it/s][1,1]<stderr>:test:  75%|███████▍  | 59/79 [00:45<00:09,  2.03it/s][1,0]<stderr>:test:  75%|███████▍  | 59/79 [00:46<00:11,  1.75it/s][1,1]<stderr>:test:  77%|███████▋  | 61/79 [00:46<00:09,  1.89it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [00:47<00:09,  1.85it/s][1,1]<stderr>:test:  80%|███████▉  | 63/79 [00:47<00:08,  1.97it/s][1,0]<stderr>:test:  78%|███████▊  | 62/79 [00:47<00:08,  2.08it/s][1,0]<stderr>:test:  80%|███████▉  | 63/79 [00:48<00:09,  1.66it/s][1,1]<stderr>:test:  82%|████████▏ | 65/79 [00:48<00:07,  1.93it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [00:49<00:06,  2.05it/s][1,1]<stderr>:test:  85%|████████▍ | 67/79 [00:49<00:05,  2.11it/s][1,0]<stderr>:test:  84%|████████▎ | 66/79 [00:49<00:06,  2.16it/s][1,0]<stderr>:test:  85%|████████▍ | 67/79 [00:50<00:07,  1.70it/s][1,1]<stderr>:test:  87%|████████▋ | 69/79 [00:50<00:05,  1.92it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [00:51<00:05,  1.80it/s][1,1]<stderr>:test:  90%|████████▉ | 71/79 [00:51<00:04,  1.91it/s][1,0]<stderr>:test:  89%|████████▊ | 70/79 [00:51<00:04,  2.10it/s][1,0]<stderr>:test:  90%|████████▉ | 71/79 [00:52<00:04,  1.66it/s][1,1]<stderr>:test:  92%|█████████▏| 73/79 [00:53<00:03,  1.68it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [00:53<00:03,  1.94it/s][1,1]<stderr>:test:  95%|█████████▍| 75/79 [00:53<00:01,  2.01it/s][1,0]<stderr>:test:  94%|█████████▎| 74/79 [00:53<00:02,  1.91it/s][1,0]<stderr>:test:  95%|█████████▍| 75/79 [00:55<00:03,  1.33it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [00:56<00:01,  1.46it/s][1,1]<stderr>:test:  97%|█████████▋| 77/79 [00:56<00:01,  1.23it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [00:56<00:00,  1.39it/s][1,0]<stderr>:test:  99%|█████████▊| 78/79 [00:57<00:00,  1.54it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [00:57<00:00,  1.38it/s][1,0]<stdout>:after evaluate
[1,1]<stdout>:after evaluate
[1,0]<stdout>:[acc/test_top1] = 0.060000
[1,0]<stdout>:[acc/test_top5] = 0.560000
[1,1]<stderr>:
[1,0]<stdout>:
[1,0]<stdout>:==> training epoch 0/1
[1,0]<stderr>:
[1,0]<stderr>:train:   0% 0/255 [00:00<?, ?it/s][1,0]<stderr>:train:   0% 1/255 [00:17<1:13:43, 17.42s/it][1,0]<stderr>:train:   1% 2/255 [00:19<35:05,  8.32s/it]  [1,0]<stderr>:train:   1% 3/255 [00:21<22:39,  5.40s/it][1,0]<stderr>:train:   2% 4/255 [00:23<16:46,  4.01s/it][1,0]<stderr>:train:   2% 5/255 [00:24<13:17,  3.19s/it][1,0]<stderr>:train:   2% 6/255 [00:26<11:11,  2.70s/it][1,0]<stderr>:train:   3% 7/255 [00:28<09:56,  2.40s/it][1,0]<stderr>:train:   3% 8/255 [00:30<09:00,  2.19s/it][1,0]<stderr>:train:   4% 9/255 [00:32<08:34,  2.09s/it][1,0]<stderr>:train:   4% 10/255 [00:33<08:20,  2.04s/it][1,0]<stderr>:train:   4% 11/255 [00:35<08:07,  2.00s/it][1,0]<stderr>:train:   5% 12/255 [00:37<07:50,  1.94s/it][1,0]<stderr>:train:   5% 13/255 [00:39<07:34,  1.88s/it][1,0]<stderr>:train:   5% 14/255 [00:41<07:26,  1.85s/it][1,0]<stderr>:train:   6% 15/255 [00:42<07:19,  1.83s/it][1,0]<stderr>:train:   6% 16/255 [00:44<07:14,  1.82s/it][1,0]<stderr>:train:   7% 17/255 [00:46<07:10,  1.81s/it][1,0]<stderr>:train:   7% 18/255 [00:48<07:01,  1.78s/it][1,0]<stderr>:train:   7% 19/255 [00:50<07:06,  1.81s/it][1,0]<stderr>:train:   8% 20/255 [00:51<07:00,  1.79s/it][1,0]<stderr>:train:   8% 21/255 [00:53<06:55,  1.78s/it][1,0]<stderr>:train:   9% 22/255 [00:55<06:50,  1.76s/it][1,0]<stderr>:train:   9% 23/255 [00:57<06:53,  1.78s/it][1,0]<stderr>:train:   9% 24/255 [00:58<06:48,  1.77s/it][1,0]<stderr>:train:  10% 25/255 [01:00<06:46,  1.77s/it][1,0]<stderr>:train:  10% 26/255 [01:02<06:44,  1.77s/it][1,0]<stderr>:train:  11% 27/255 [01:04<06:42,  1.77s/it][1,0]<stderr>:train:  11% 28/255 [01:06<06:47,  1.80s/it][1,0]<stderr>:train:  11% 29/255 [01:07<06:51,  1.82s/it][1,0]<stderr>:train:  12% 30/255 [01:09<06:46,  1.80s/it][1,0]<stderr>:train:  12% 31/255 [01:11<06:39,  1.79s/it][1,0]<stderr>:train:  13% 32/255 [01:13<06:34,  1.77s/it][1,0]<stderr>:train:  13% 33/255 [01:14<06:29,  1.76s/it][1,0]<stderr>:train:  13% 34/255 [01:16<06:39,  1.81s/it][1,0]<stderr>:train:  14% 35/255 [01:18<06:44,  1.84s/it][1,0]<stderr>:train:  14% 36/255 [01:20<06:46,  1.85s/it][1,0]<stderr>:train:  15% 37/255 [01:22<06:48,  1.87s/it][1,0]<stderr>:train:  15% 38/255 [01:24<06:38,  1.84s/it][1,0]<stderr>:train:  15% 39/255 [01:26<06:32,  1.82s/it][1,0]<stderr>:train:  16% 40/255 [01:27<06:35,  1.84s/it][1,0]<stderr>:train:  16% 41/255 [01:29<06:27,  1.81s/it][1,0]<stderr>:train:  16% 42/255 [01:31<06:31,  1.84s/it][1,0]<stderr>:train:  17% 43/255 [01:33<06:24,  1.82s/it][1,0]<stderr>:train:  17% 44/255 [01:35<06:29,  1.85s/it][1,0]<stderr>:train:  18% 45/255 [01:37<06:32,  1.87s/it][1,0]<stderr>:train:  18% 46/255 [01:39<06:33,  1.88s/it][1,0]<stderr>:train:  18% 47/255 [01:41<06:29,  1.87s/it][1,0]<stderr>:train:  19% 48/255 [01:42<06:18,  1.83s/it][1,0]<stderr>:train:  19% 49/255 [01:44<06:23,  1.86s/it][1,0]<stderr>:train:  20% 50/255 [01:46<06:23,  1.87s/it][1,0]<stderr>:train:  20% 51/255 [01:48<06:23,  1.88s/it][1,0]<stderr>:train:  20% 52/255 [01:50<06:13,  1.84s/it][1,0]<stderr>:train:  21% 53/255 [01:52<06:16,  1.87s/it][1,0]<stderr>:train:  21% 54/255 [01:54<06:17,  1.88s/it][1,0]<stderr>:train:  22% 55/255 [01:55<06:07,  1.84s/it][1,0]<stderr>:train:  22% 56/255 [01:57<05:57,  1.80s/it][1,0]<stderr>:train:  22% 57/255 [01:59<05:54,  1.79s/it][1,0]<stderr>:train:  23% 58/255 [02:01<05:58,  1.82s/it][1,0]<stderr>:train:  23% 59/255 [02:03<06:00,  1.84s/it][1,0]<stderr>:train:  24% 60/255 [02:04<06:01,  1.85s/it][1,0]<stderr>:train:  24% 61/255 [02:06<06:02,  1.87s/it][1,0]<stderr>:train:  24% 62/255 [02:08<06:02,  1.88s/it][1,0]<stderr>:train:  25% 63/255 [02:10<06:01,  1.89s/it][1,0]<stderr>:train:  25% 64/255 [02:12<06:00,  1.89s/it][1,0]<stderr>:train:  25% 65/255 [02:14<06:00,  1.90s/it][1,0]<stderr>:train:  26% 66/255 [02:16<06:00,  1.91s/it][1,0]<stderr>:train:  26% 67/255 [02:18<05:58,  1.91s/it][1,0]<stderr>:train:  27% 68/255 [02:20<05:46,  1.85s/it][1,0]<stderr>:train:  27% 69/255 [02:21<05:37,  1.82s/it][1,0]<stderr>:train:  27% 70/255 [02:23<05:40,  1.84s/it][1,0]<stderr>:train:  28% 71/255 [02:25<05:45,  1.88s/it][1,0]<stderr>:train:  28% 72/255 [02:27<05:35,  1.84s/it][1,0]<stderr>:train:  29% 73/255 [02:29<05:29,  1.81s/it][1,0]<stderr>:train:  29% 74/255 [02:30<05:21,  1.78s/it][1,0]<stderr>:train:  29% 75/255 [02:32<05:19,  1.77s/it][1,0]<stderr>:train:  30% 76/255 [02:34<05:19,  1.79s/it][1,0]<stderr>:train:  30% 77/255 [02:36<05:16,  1.78s/it][1,0]<stderr>:train:  31% 78/255 [02:37<05:13,  1.77s/it][1,0]<stderr>:train:  31% 79/255 [02:39<05:10,  1.77s/it][1,0]<stderr>:train:  31% 80/255 [02:41<05:15,  1.81s/it][1,0]<stderr>:train:  32% 81/255 [02:43<05:19,  1.83s/it][1,0]<stderr>:train:  32% 82/255 [02:45<05:16,  1.83s/it][1,0]<stderr>:train:  33% 83/255 [02:47<05:10,  1.81s/it][1,0]<stderr>:train:  33% 84/255 [02:48<05:12,  1.83s/it][1,0]<stderr>:train:  33% 85/255 [02:50<05:13,  1.84s/it][1,0]<stderr>:train:  34% 86/255 [02:52<05:06,  1.81s/it][1,0]<stderr>:train:  34% 87/255 [02:54<05:09,  1.84s/it][1,0]<stderr>:train:  35% 88/255 [02:56<05:02,  1.81s/it][1,0]<stderr>:train:  35% 89/255 [02:58<05:06,  1.85s/it][1,0]<stderr>:train:  35% 90/255 [02:59<05:00,  1.82s/it][1,0]<stderr>:train:  36% 91/255 [03:01<04:55,  1.80s/it][1,0]<stderr>:train:  36% 92/255 [03:03<04:52,  1.79s/it][1,0]<stderr>:train:  36% 93/255 [03:05<04:55,  1.82s/it][1,0]<stderr>:train:  37% 94/255 [03:07<04:51,  1.81s/it][1,0]<stderr>:train:  37% 95/255 [03:08<04:47,  1.80s/it][1,0]<stderr>:train:  38% 96/255 [03:10<04:51,  1.83s/it][1,0]<stderr>:train:  38% 97/255 [03:12<04:51,  1.84s/it][1,0]<stderr>:train:  38% 98/255 [03:14<04:46,  1.82s/it][1,0]<stderr>:train:  39% 99/255 [03:16<04:40,  1.80s/it][1,0]<stderr>:train:  39% 100/255 [03:17<04:35,  1.78s/it][1,0]<stderr>:train:  40% 101/255 [03:19<04:39,  1.82s/it][1,0]<stderr>:train:  40% 102/255 [03:21<04:34,  1.79s/it][1,0]<stderr>:train:  40% 103/255 [03:23<04:38,  1.83s/it][1,0]<stderr>:train:  41% 104/255 [03:25<04:32,  1.80s/it][1,0]<stderr>:train:  41% 105/255 [03:26<04:29,  1.80s/it][1,0]<stderr>:train:  42% 106/255 [03:28<04:24,  1.78s/it][1,0]<stderr>:train:  42% 107/255 [03:30<04:29,  1.82s/it][1,0]<stderr>:train:  42% 108/255 [03:32<04:24,  1.80s/it][1,0]<stderr>:train:  43% 109/255 [03:34<04:20,  1.78s/it][1,0]<stderr>:train:  43% 110/255 [03:35<04:15,  1.76s/it][1,0]<stderr>:train:  44% 111/255 [03:37<04:17,  1.79s/it][1,0]<stderr>:train:  44% 112/255 [03:39<04:13,  1.77s/it][1,0]<stderr>:train:  44% 113/255 [03:41<04:17,  1.82s/it][1,0]<stderr>:train:  45% 114/255 [03:43<04:12,  1.79s/it][1,0]<stderr>:train:  45% 115/255 [03:44<04:09,  1.78s/it][1,0]<stderr>:train:  45% 116/255 [03:46<04:10,  1.80s/it][1,0]<stderr>:train:  46% 117/255 [03:48<04:06,  1.79s/it][1,0]<stderr>:train:  46% 118/255 [03:50<04:03,  1.78s/it][1,0]<stderr>:train:  47% 119/255 [03:51<04:00,  1.77s/it][1,0]<stderr>:train:  47% 120/255 [03:53<03:57,  1.76s/it][1,0]<stderr>:train:  47% 121/255 [03:55<03:58,  1.78s/it][1,0]<stderr>:train:  48% 122/255 [03:57<03:55,  1.77s/it][1,0]<stderr>:train:  48% 123/255 [03:59<03:58,  1.81s/it][1,0]<stderr>:train:  49% 124/255 [04:00<03:54,  1.79s/it][1,0]<stderr>:train:  49% 125/255 [04:02<03:56,  1.82s/it][1,0]<stderr>:train:  49% 126/255 [04:04<03:56,  1.83s/it][1,0]<stderr>:train:  50% 127/255 [04:06<03:53,  1.82s/it][1,0]<stderr>:train:  50% 128/255 [04:08<03:53,  1.84s/it][1,0]<stderr>:train:  51% 129/255 [04:10<03:47,  1.80s/it][1,0]<stderr>:train:  51% 130/255 [04:11<03:49,  1.84s/it][1,0]<stderr>:train:  51% 131/255 [04:13<03:50,  1.86s/it][1,0]<stderr>:train:  52% 132/255 [04:15<03:49,  1.86s/it][1,0]<stderr>:train:  52% 133/255 [04:17<03:48,  1.87s/it][1,0]<stderr>:train:  53% 134/255 [04:19<03:47,  1.88s/it][1,0]<stderr>:train:  53% 135/255 [04:21<03:46,  1.89s/it][1,0]<stderr>:train:  53% 136/255 [04:23<03:45,  1.89s/it][1,0]<stderr>:train:  54% 137/255 [04:25<03:44,  1.90s/it][1,0]<stderr>:train:  54% 138/255 [04:27<03:40,  1.89s/it][1,0]<stderr>:train:  55% 139/255 [04:29<03:40,  1.90s/it][1,0]<stderr>:train:  55% 140/255 [04:30<03:39,  1.90s/it][1,0]<stderr>:train:  55% 141/255 [04:32<03:37,  1.91s/it][1,0]<stderr>:train:  56% 142/255 [04:34<03:35,  1.91s/it][1,0]<stderr>:train:  56% 143/255 [04:36<03:33,  1.90s/it][1,0]<stderr>:train:  56% 144/255 [04:38<03:32,  1.92s/it][1,0]<stderr>:train:  57% 145/255 [04:40<03:30,  1.91s/it][1,0]<stderr>:train:  57% 146/255 [04:42<03:23,  1.86s/it][1,0]<stderr>:train:  58% 147/255 [04:44<03:21,  1.87s/it][1,0]<stderr>:train:  58% 148/255 [04:45<03:16,  1.84s/it][1,0]<stderr>:train:  58% 149/255 [04:47<03:12,  1.81s/it][1,0]<stderr>:train:  59% 150/255 [04:49<03:15,  1.87s/it][1,0]<stderr>:train:  59% 151/255 [04:51<03:14,  1.87s/it][1,0]<stderr>:train:  60% 152/255 [04:53<03:13,  1.88s/it][1,0]<stderr>:train:  60% 153/255 [04:55<03:12,  1.89s/it][1,0]<stderr>:train:  60% 154/255 [04:57<03:12,  1.90s/it][1,0]<stderr>:train:  61% 155/255 [04:59<03:10,  1.91s/it][1,0]<stderr>:train:  61% 156/255 [05:01<03:08,  1.90s/it][1,0]<stderr>:train:  62% 157/255 [05:02<03:06,  1.90s/it][1,0]<stderr>:train:  62% 158/255 [05:04<03:04,  1.90s/it][1,0]<stderr>:train:  62% 159/255 [05:06<03:02,  1.90s/it][1,0]<stderr>:train:  63% 160/255 [05:08<03:01,  1.91s/it][1,0]<stderr>:train:  63% 161/255 [05:10<02:55,  1.87s/it][1,0]<stderr>:train:  64% 162/255 [05:12<02:53,  1.87s/it][1,0]<stderr>:train:  64% 163/255 [05:14<02:52,  1.88s/it][1,0]<stderr>:train:  64% 164/255 [05:16<02:51,  1.89s/it][1,0]<stderr>:train:  65% 165/255 [05:18<02:51,  1.90s/it][1,0]<stderr>:train:  65% 166/255 [05:20<02:49,  1.90s/it][1,0]<stderr>:train:  65% 167/255 [05:21<02:47,  1.90s/it][1,0]<stderr>:train:  66% 168/255 [05:23<02:43,  1.88s/it][1,0]<stderr>:train:  66% 169/255 [05:25<02:42,  1.89s/it][1,0]<stderr>:train:  67% 170/255 [05:27<02:36,  1.84s/it][1,0]<stderr>:train:  67% 171/255 [05:29<02:36,  1.86s/it][1,0]<stderr>:train:  67% 172/255 [05:31<02:37,  1.89s/it][1,0]<stderr>:train:  68% 173/255 [05:33<02:35,  1.89s/it][1,0]<stderr>:train:  68% 174/255 [05:35<02:34,  1.90s/it][1,0]<stderr>:train:  69% 175/255 [05:36<02:32,  1.90s/it][1,0]<stderr>:train:  69% 176/255 [05:38<02:25,  1.85s/it][1,0]<stderr>:train:  69% 177/255 [05:40<02:21,  1.82s/it][1,0]<stderr>:train:  70% 178/255 [05:42<02:21,  1.84s/it][1,0]<stderr>:train:  70% 179/255 [05:44<02:21,  1.86s/it][1,0]<stderr>:train:  71% 180/255 [05:46<02:20,  1.87s/it][1,0]<stderr>:train:  71% 181/255 [05:47<02:18,  1.87s/it][1,0]<stderr>:train:  71% 182/255 [05:49<02:17,  1.88s/it][1,0]<stderr>:train:  72% 183/255 [05:51<02:12,  1.84s/it][1,0]<stderr>:train:  72% 184/255 [05:53<02:11,  1.85s/it][1,0]<stderr>:train:  73% 185/255 [05:55<02:09,  1.84s/it][1,0]<stderr>:train:  73% 186/255 [05:57<02:08,  1.87s/it][1,0]<stderr>:train:  73% 187/255 [05:59<02:08,  1.89s/it][1,0]<stderr>:train:  74% 188/255 [06:01<02:07,  1.90s/it][1,0]<stderr>:train:  74% 189/255 [06:03<02:05,  1.90s/it][1,0]<stderr>:train:  75% 190/255 [06:04<02:03,  1.90s/it][1,0]<stderr>:train:  75% 191/255 [06:06<02:00,  1.89s/it][1,0]<stderr>:train:  75% 192/255 [06:08<01:56,  1.85s/it][1,0]<stderr>:train:  76% 193/255 [06:10<01:52,  1.82s/it][1,0]<stderr>:train:  76% 194/255 [06:12<01:52,  1.84s/it][1,0]<stderr>:train:  76% 195/255 [06:14<01:51,  1.86s/it][1,0]<stderr>:train:  77% 196/255 [06:15<01:50,  1.87s/it][1,0]<stderr>:train:  77% 197/255 [06:17<01:48,  1.87s/it][1,0]<stderr>:train:  78% 198/255 [06:19<01:47,  1.88s/it][1,0]<stderr>:train:  78% 199/255 [06:21<01:45,  1.88s/it][1,0]<stderr>:train:  78% 200/255 [06:23<01:43,  1.89s/it][1,0]<stderr>:train:  79% 201/255 [06:25<01:42,  1.89s/it][1,0]<stderr>:train:  79% 202/255 [06:27<01:40,  1.90s/it][1,0]<stderr>:train:  80% 203/255 [06:29<01:38,  1.90s/it][1,0]<stderr>:train:  80% 204/255 [06:31<01:36,  1.90s/it][1,0]<stderr>:train:  80% 205/255 [06:33<01:34,  1.89s/it][1,0]<stderr>:train:  81% 206/255 [06:34<01:30,  1.85s/it][1,0]<stderr>:train:  81% 207/255 [06:36<01:28,  1.85s/it][1,0]<stderr>:train:  82% 208/255 [06:38<01:27,  1.86s/it][1,0]<stderr>:train:  82% 209/255 [06:40<01:26,  1.87s/it][1,0]<stderr>:train:  82% 210/255 [06:42<01:24,  1.87s/it][1,0]<stderr>:train:  83% 211/255 [06:44<01:22,  1.87s/it][1,0]<stderr>:train:  83% 212/255 [06:46<01:20,  1.88s/it][1,0]<stderr>:train:  84% 213/255 [06:47<01:19,  1.88s/it][1,0]<stderr>:train:  84% 214/255 [06:49<01:17,  1.89s/it][1,0]<stderr>:train:  84% 215/255 [06:51<01:16,  1.90s/it][1,0]<stderr>:train:  85% 216/255 [06:53<01:13,  1.88s/it][1,0]<stderr>:train:  85% 217/255 [06:55<01:11,  1.89s/it][1,0]<stderr>:train:  85% 218/255 [06:57<01:09,  1.89s/it][1,0]<stderr>:train:  86% 219/255 [06:59<01:07,  1.89s/it][1,0]<stderr>:train:  86% 220/255 [07:01<01:05,  1.88s/it][1,0]<stderr>:train:  87% 221/255 [07:02<01:02,  1.84s/it][1,0]<stderr>:train:  87% 222/255 [07:04<01:01,  1.85s/it][1,0]<stderr>:train:  87% 223/255 [07:06<00:58,  1.83s/it][1,0]<stderr>:train:  88% 224/255 [07:08<00:57,  1.84s/it][1,0]<stderr>:train:  88% 225/255 [07:10<00:55,  1.86s/it][1,0]<stderr>:train:  89% 226/255 [07:12<00:53,  1.84s/it][1,0]<stderr>:train:  89% 227/255 [07:14<00:52,  1.86s/it][1,0]<stderr>:train:  89% 228/255 [07:15<00:49,  1.82s/it][1,0]<stderr>:train:  90% 229/255 [07:17<00:48,  1.85s/it][1,0]<stderr>:train:  90% 230/255 [07:19<00:45,  1.82s/it][1,0]<stderr>:train:  91% 231/255 [07:21<00:44,  1.84s/it][1,0]<stderr>:train:  91% 232/255 [07:23<00:41,  1.82s/it][1,0]<stderr>:train:  91% 233/255 [07:25<00:40,  1.86s/it][1,0]<stderr>:train:  92% 234/255 [07:26<00:39,  1.88s/it][1,0]<stderr>:train:  92% 235/255 [07:28<00:36,  1.85s/it][1,0]<stderr>:train:  93% 236/255 [07:30<00:35,  1.85s/it][1,0]<stderr>:train:  93% 237/255 [07:32<00:32,  1.82s/it][1,0]<stderr>:train:  93% 238/255 [07:34<00:31,  1.83s/it][1,0]<stderr>:train:  94% 239/255 [07:35<00:29,  1.83s/it][1,0]<stderr>:train:  94% 240/255 [07:37<00:27,  1.81s/it][1,0]<stderr>:train:  95% 241/255 [07:39<00:25,  1.84s/it][1,0]<stderr>:train:  95% 242/255 [07:41<00:23,  1.82s/it][1,0]<stderr>:train:  95% 243/255 [07:43<00:22,  1.83s/it][1,0]<stderr>:train:  96% 244/255 [07:45<00:20,  1.86s/it][1,0]<stderr>:train:  96% 245/255 [07:46<00:18,  1.82s/it][1,0]<stderr>:train:  96% 246/255 [07:48<00:16,  1.85s/it][1,0]<stderr>:train:  97% 247/255 [07:50<00:14,  1.82s/it][1,0]<stderr>:train:  97% 248/255 [07:52<00:12,  1.79s/it][1,0]<stderr>:train:  98% 249/255 [07:54<00:10,  1.77s/it][1,0]<stderr>:train:  98% 250/255 [07:55<00:08,  1.76s/it][1,0]<stderr>:train:  98% 251/255 [07:57<00:07,  1.80s/it][1,0]<stderr>:train:  99% 252/255 [07:59<00:05,  1.82s/it][1,0]<stderr>:train:  99% 253/255 [08:01<00:03,  1.85s/it][1,0]<stderr>:train: 100% 254/255 [08:03<00:01,  1.86s/it][1,0]<stderr>:train: 100% 255/255 [08:04<00:00,  1.67s/it][1,0]<stderr>:train: 100% 255/255 [08:04<00:00,  1.90s/it][1,0]<stdout>:         932586 function calls (918759 primitive calls) in 484.592 seconds
[1,0]<stdout>:
[1,0]<stdout>:   Ordered by: internal time
[1,0]<stdout>:
[1,0]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,0]<stdout>:    15045  181.790    0.012  181.790    0.012 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,0]<stdout>:      255  170.989    0.671  170.989    0.671 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,0]<stdout>:      511  111.147    0.218  111.147    0.218 {method 'item' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        4   11.614    2.904   11.614    2.904 {method 'write' of '_io.BufferedWriter' objects}
[1,0]<stdout>:     1064    3.686    0.003    3.686    0.003 {method 'acquire' of '_thread.lock' objects}
[1,0]<stdout>:    15045    0.840    0.000  182.634    0.012 mpi_ops.py:928(synchronize)
[1,0]<stdout>:     3315    0.610    0.000    0.610    0.000 {built-in method conv2d}
[1,0]<stdout>:    29580    0.439    0.000    0.439    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    14790    0.432    0.000    0.432    0.000 {method 'set_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315    0.362    0.000    0.362    0.000 {built-in method batch_norm}
[1,0]<stdout>:    15045    0.320    0.000    0.320    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    14790    0.227    0.000    0.227    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315    0.145    0.000    0.607    0.000 batchnorm.py:99(forward)
[1,0]<stdout>:      510    0.135    0.000    0.135    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.118    0.000  181.973    0.714 optimizer.py:232(synchronize)
[1,0]<stdout>:     3825    0.118    0.000    0.118    0.000 {built-in method relu_}
[1,0]<stdout>:     1275    0.114    0.000    0.114    0.000 {built-in method max_pool2d}
[1,0]<stdout>:14280/510    0.109    0.000    1.935    0.004 module.py:710(_call_impl)
[1,0]<stdout>:        1    0.102    0.102  484.592  484.592 train.py:338(train)
[1,0]<stdout>:      267    0.095    0.000    0.095    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,0]<stdout>:    88740    0.086    0.000    0.097    0.000 tensor.py:725(grad)
[1,0]<stdout>:      765    0.085    0.000    0.085    0.000 {built-in method addmm}
[1,0]<stdout>:        8    0.069    0.009    0.070    0.009 {method 'dump' of '_pickle.Pickler' objects}
[1,0]<stdout>:      255    0.060    0.000    0.845    0.003 sgd.py:75(step)
[1,0]<stdout>:    14790    0.058    0.000    0.058    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      510    0.048    0.000    0.048    0.000 {built-in method dropout}
[1,0]<stdout>:      255    0.041    0.000    0.369    0.001 optimizer.py:166(zero_grad)
[1,0]<stdout>:      510    0.029    0.000    1.819    0.004 container.py:115(forward)
[1,0]<stdout>:     3315    0.029    0.000    0.411    0.000 functional.py:1998(batch_norm)
[1,0]<stdout>:    29070    0.026    0.000    0.026    0.000 module.py:758(__getattr__)
[1,0]<stdout>:     3370    0.026    0.000    0.031    0.000 module.py:774(__setattr__)
[1,0]<stdout>:       14    0.026    0.002    0.026    0.002 {method 'poll' of 'select.poll' objects}
[1,0]<stdout>:      255    0.025    0.000    0.025    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.023    0.000    0.023    0.000 {built-in method torch._C._nn.nll_loss}
[1,0]<stdout>:      255    0.017    0.000    0.055    0.000 summary.py:137(scalar)
[1,0]<stdout>:   160553    0.016    0.000    0.016    0.000 {built-in method builtins.isinstance}
[1,0]<stdout>:    14280    0.013    0.000    0.013    0.000 {built-in method torch._C._get_tracing_state}
[1,0]<stdout>:      255    0.013    0.000    0.013    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,0]<stdout>:    91045    0.012    0.000    0.012    0.000 {built-in method builtins.hasattr}
[1,0]<stdout>:     3315    0.012    0.000    0.624    0.000 conv.py:410(_conv_forward)
[1,0]<stdout>:    44370    0.012    0.000    0.020    0.000 tensor.py:458(__hash__)
[1,0]<stdout>:      257    0.012    0.000    0.022    0.000 std.py:355(format_meter)
[1,0]<stdout>:      765    0.011    0.000    0.011    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      256    0.011    0.000    0.022    0.000 sampler.py:206(__iter__)
[1,0]<stdout>:     3315    0.010    0.000    0.011    0.000 functional.py:1980(_verify_batch_size)
[1,0]<stdout>:     3315    0.010    0.000    0.638    0.000 conv.py:418(forward)
[1,0]<stdout>:     3825    0.010    0.000    0.136    0.000 activation.py:101(forward)
[1,0]<stdout>:      255    0.009    0.000    1.308    0.005 {built-in method apply}
[1,0]<stdout>:      255    0.009    0.000    0.009    0.000 {built-in method ones_like}
[1,0]<stdout>:    57630    0.009    0.000    0.009    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,0]<stdout>:      255    0.009    0.000    0.025    0.000 x2num.py:11(check_nan)
[1,0]<stdout>:    44399    0.008    0.000    0.008    0.000 {built-in method builtins.id}
[1,0]<stdout>:     3825    0.007    0.000    0.126    0.000 functional.py:1106(relu)
[1,0]<stdout>:      255    0.007    0.000    0.007    0.000 {built-in method tensor}
[1,0]<stdout>:      255    0.007    0.000    0.007    0.000 {method 'reduce' of 'numpy.ufunc' objects}
[1,0]<stdout>:      255    0.007    0.000    0.007    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,0]<stdout>:51524/51521    0.007    0.000    0.007    0.000 {built-in method builtins.len}
[1,0]<stdout>:      255    0.007    0.000  182.834    0.717 optimizer.py:337(step)
[1,0]<stdout>:      255    0.006    0.000    0.158    0.001 std.py:1197(update)
[1,0]<stdout>:      511    0.006    0.000    0.006    0.000 basics.py:183(size)
[1,0]<stdout>:     4080    0.006    0.000    0.006    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      765    0.006    0.000    0.111    0.000 functional.py:1655(linear)
[1,0]<stdout>:      255    0.006    0.000  171.012    0.671 tensor.py:155(backward)
[1,0]<stdout>:      255    0.006    0.000    0.006    0.000 {built-in method flatten}
[1,0]<stdout>:    11449    0.006    0.000    0.008    0.000 utils.py:330(<genexpr>)
[1,0]<stdout>:      515    0.005    0.000    0.021    0.000 queues.py:80(put)
[1,0]<stdout>:      255    0.005    0.000    1.861    0.007 vgg.py:42(forward)
[1,0]<stdout>:      255    0.005    0.000    0.022    0.000 writer.py:131(add_summary)
[1,0]<stdout>:      255    0.005    0.000    0.005    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      256    0.005    0.000   15.627    0.061 std.py:1159(__iter__)
[1,0]<stdout>:     1275    0.005    0.000    0.125    0.000 pooling.py:156(forward)
[1,0]<stdout>:      255    0.005    0.000    0.084    0.000 writer.py:401(add_scalar)
[1,0]<stdout>:        8    0.005    0.001    0.075    0.009 reduction.py:58(dump)
[1,0]<stdout>:      255    0.005    0.000  182.839    0.717 lr_scheduler.py:62(wrapper)
[1,0]<stdout>:     1579    0.005    0.000    0.005    0.000 {method 'format' of 'str' objects}
[1,0]<stdout>:      776    0.004    0.000    0.010    0.000 threading.py:341(notify)
[1,0]<stdout>:      256    0.004    0.000    3.751    0.015 dataloader.py:945(_next_data)
[1,0]<stdout>:      521    0.004    0.000    0.004    0.000 {method 'release' of '_thread.lock' objects}
[1,0]<stdout>:        1    0.004    0.004    0.004    0.004 {built-in method randperm}
[1,0]<stdout>:      510    0.004    0.000    0.054    0.000 functional.py:950(dropout)
[1,0]<stdout>:     1530    0.004    0.000    0.004    0.000 std.py:233(__call__)
[1,0]<stdout>:     2040    0.004    0.000    0.005    0.000 {built-in method builtins.any}
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {built-in method numpy.array}
[1,0]<stdout>:      255    0.004    0.000  171.006    0.671 __init__.py:57(backward)
[1,0]<stdout>:      255    0.004    0.000    0.035    0.000 x2num.py:18(make_np)
[1,0]<stdout>:      255    0.004    0.000    0.854    0.003 grad_mode.py:12(decorate_context)
[1,0]<stdout>:      256    0.004    0.000    0.004    0.000 {built-in method now}
[1,0]<stdout>:      255    0.003    0.000    0.017    0.000 writer.py:115(add_event)
[1,0]<stdout>:    15048    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,0]<stdout>:      255    0.003    0.000    0.020    0.000 mpi_ops.py:105(_allreduce_async)
[1,0]<stdout>:      255    0.003    0.000    3.696    0.014 dataloader.py:912(_get_data)
[1,0]<stdout>:      257    0.003    0.000    0.004    0.000 std.py:1445(format_dict)
[1,0]<stdout>:      255    0.003    0.000    1.298    0.005 mpi_ops.py:191(forward)
[1,0]<stdout>:     3315    0.003    0.000    0.005    0.000 batchnorm.py:275(_check_input_dim)
[1,0]<stdout>:      255    0.003    0.000    0.013    0.000 __init__.py:25(_make_grads)
[1,0]<stdout>:     1275    0.003    0.000    0.117    0.000 functional.py:564(_max_pool2d)
[1,0]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,0]<stdout>:      255    0.003    0.000    1.311    0.005 mpi_ops.py:209(allreduce)
[1,0]<stdout>:     1275    0.003    0.000    0.120    0.000 _jit_internal.py:237(fn)
[1,0]<stdout>:      255    0.003    0.000    0.372    0.001 optimizer.py:353(zero_grad)
[1,0]<stdout>:      765    0.003    0.000    0.115    0.000 linear.py:90(forward)
[1,0]<stdout>:        1    0.003    0.003    0.003    0.003 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      256    0.003    0.000    0.149    0.001 std.py:1324(refresh)
[1,0]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,0]<stdout>:      255    0.003    0.000    0.008    0.000 train.py:409(adjust_learning_rate)
[1,0]<stdout>:      255    0.003    0.000    0.027    0.000 functional.py:2158(nll_loss)
[1,0]<stdout>:      263    0.003    0.000    0.034    0.000 dataloader.py:991(_try_put_index)
[1,0]<stdout>:     3315    0.003    0.000    0.004    0.000 __init__.py:31(__get__)
[1,0]<stdout>:      255    0.003    0.000    0.013    0.000 fromnumeric.py:2123(sum)
[1,0]<stdout>:      255    0.003    0.000    3.688    0.014 queue.py:153(get)
[1,0]<stdout>:    11192    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 utils.py:29(_list_with_default)
[1,0]<stdout>:      257    0.002    0.000    0.143    0.001 std.py:1463(display)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:65(__enter__)
[1,0]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,0]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,0]<stdout>:      257    0.002    0.000    0.113    0.000 std.py:348(print_status)
[1,0]<stdout>:      255    0.002    0.000    0.017    0.000 <__array_function__ internals>:2(sum)
[1,0]<stdout>:      255    0.002    0.000    0.010    0.000 fromnumeric.py:69(_wrapreduction)
[1,0]<stdout>:      255    0.002    0.000    0.029    0.000 mpi_ops.py:152(allreduce_async)
[1,0]<stdout>:      255    0.002    0.000    0.055    0.000 functional.py:2370(cross_entropy)
[1,0]<stdout>:      257    0.002    0.000    0.027    0.000 std.py:1149(__str__)
[1,0]<stdout>:      255    0.002    0.000    0.058    0.000 loss.py:946(forward)
[1,0]<stdout>:     4335    0.002    0.000    0.002    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.002    0.000    0.019    0.000 functional.py:909(adaptive_avg_pool2d)
[1,0]<stdout>:      255    0.002    0.000    0.021    0.000 pooling.py:1110(forward)
[1,0]<stdout>:      257    0.002    0.000    0.010    0.000 {built-in method builtins.sum}
[1,0]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,0]<stdout>:      512    0.002    0.000    0.002    0.000 {method 'sub' of 're.Pattern' objects}
[1,0]<stdout>:      255    0.002    0.000    3.690    0.014 dataloader.py:766(_try_get_data)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,0]<stdout>:      260    0.002    0.000    0.002    0.000 std.py:104(acquire)
[1,0]<stdout>:      255    0.002    0.000    0.002    0.000 numeric.py:1858(isscalar)
[1,0]<stdout>:      255    0.002    0.000    0.002    0.000 writer.py:318(_check_caffe2_blob)
[1,0]<stdout>:      783    0.001    0.000    0.002    0.000 threading.py:246(__enter__)
[1,0]<stdout>:     3315    0.001    0.000    0.001    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,0]<stdout>:      255    0.001    0.000    0.014    0.000 event_file_writer.py:132(add_event)
[1,0]<stdout>:      255    0.001    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,0]<stdout>:      257    0.001    0.000    0.097    0.000 std.py:342(fp_write)
[1,0]<stdout>:      765    0.001    0.000    0.006    0.000 _overrides.py:779(has_torch_function)
[1,0]<stdout>:      510    0.001    0.000    0.055    0.000 dropout.py:57(forward)
[1,0]<stdout>:      513    0.001    0.000    0.003    0.000 std.py:288(format_interval)
[1,0]<stdout>:      510    0.001    0.000    0.002    0.000 container.py:107(__iter__)
[1,0]<stdout>:      260    0.001    0.000    0.002    0.000 std.py:108(release)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}
[1,0]<stdout>:      255    0.001    0.000    0.003    0.000 summary.py:28(_clean_tag)
[1,0]<stdout>:      255    0.001    0.000    0.002    0.000 grad_mode.py:149(__init__)
[1,0]<stdout>:      255    0.001    0.000    0.014    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}
[1,0]<stdout>:      779    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:      256    0.001    0.000    3.752    0.015 dataloader.py:362(__next__)
[1,0]<stdout>:       20    0.001    0.000    0.003    0.000 synchronize.py:50(__init__)
[1,0]<stdout>:      269    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}
[1,0]<stdout>:      255    0.001    0.000    0.005    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 writer.py:333(_get_file_writer)
[1,0]<stdout>:      257    0.001    0.000    0.013    0.000 utils.py:333(disp_len)
[1,0]<stdout>:      783    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}
[1,0]<stdout>:     2295    0.001    0.000    0.002    0.000 _overrides.py:792(<genexpr>)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,0]<stdout>:      510    0.001    0.000    0.001    0.000 _VF.py:13(__getattr__)
[1,0]<stdout>:      255    0.001    0.000    0.024    0.000 dataloader.py:1010(_process_data)
[1,0]<stdout>:      257    0.001    0.000    0.011    0.000 utils.py:329(_text_width)
[1,0]<stdout>:      255    0.001    0.000    0.026    0.000 functional.py:1567(log_softmax)
[1,0]<stdout>:      255    0.001    0.000    0.007    0.000 mpi_ops.py:92(_check_function)
[1,0]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 queue.py:216(_get)
[1,0]<stdout>:      881    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,0]<stdout>:      784    0.001    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,0]<stdout>:      783    0.001    0.000    0.001    0.000 threading.py:249(__exit__)
[1,0]<stdout>:      512    0.001    0.000    0.001    0.000 {built-in method builtins.iter}
[1,0]<stdout>:        1    0.001    0.001    0.001    0.001 __init__.py:128(is_initialized)
[1,0]<stdout>:      528    0.001    0.000    0.001    0.000 {method 'append' of 'collections.deque' objects}
[1,0]<stdout>:        1    0.001    0.001   11.710   11.710 dataloader.py:690(__init__)
[1,0]<stdout>:       88    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 fromnumeric.py:70(<dictcomp>)
[1,0]<stdout>:        1    0.001    0.001    0.007    0.007 distributed.py:68(__iter__)
[1,0]<stdout>:      516    0.001    0.000    0.096    0.000 utils.py:143(inner)
[1,0]<stdout>:        4    0.000    0.000   11.691    2.923 popen_forkserver.py:41(_launch)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
[1,0]<stdout>:      603    0.000    0.000    0.024    0.000 {built-in method builtins.next}
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}
[1,0]<stdout>:      257    0.000    0.000    0.000    0.000 {built-in method builtins.max}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
[1,0]<stdout>:      256    0.000    0.000    0.001    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,0]<stdout>:      263    0.000    0.000    0.023    0.000 dataloader.py:356(_next_index)
[1,0]<stdout>:     1277    0.000    0.000    0.000    0.000 {built-in method time.time}
[1,0]<stdout>:     1026    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,0]<stdout>:      256    0.000    0.000    0.000    0.000 queue.py:208(_qsize)
[1,0]<stdout>:        6    0.000    0.000    0.003    0.001 queues.py:158(_start_thread)
[1,0]<stdout>:       36    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,0]<stdout>:      297    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,0]<stdout>:      765    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,0]<stdout>:        7    0.000    0.000    0.001    0.000 threading.py:761(__init__)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,0]<stdout>:        1    0.000    0.000  484.592  484.592 {built-in method builtins.exec}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      512    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:285(choice)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,0]<stdout>:        4    0.000    0.000   11.691    2.923 popen_fork.py:15(__init__)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,0]<stdout>:        4    0.000    0.000   11.692    2.923 process.py:110(start)
[1,0]<stdout>:      783    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,0]<stdout>:       14    0.000    0.000    0.026    0.002 connection.py:917(wait)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 fromnumeric.py:2118(_sum_dispatcher)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
[1,0]<stdout>:      271    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,0]<stdout>:        5    0.000    0.000    0.003    0.001 queues.py:36(__init__)
[1,0]<stdout>:       40    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,0]<stdout>:        5    0.000    0.000    0.004    0.001 context.py:100(Queue)
[1,0]<stdout>:      261    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:       29    0.000    0.000    0.001    0.000 util.py:205(__call__)
[1,0]<stdout>:        1    0.000    0.000  484.592  484.592 <string>:1(<module>)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,0]<stdout>:      272    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 forkserver.py:76(connect_to_new_process)
[1,0]<stdout>:       84    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,0]<stdout>:        7    0.000    0.000    0.003    0.000 threading.py:540(wait)
[1,0]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,0]<stdout>:       48    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)
[1,0]<stdout>:        8    0.000    0.000    3.685    0.461 threading.py:270(wait)
[1,0]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,0]<stdout>:        2    0.000    0.000    0.027    0.014 dataloader.py:1040(_shutdown_workers)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,0]<stdout>:       11    0.000    0.000    0.002    0.000 context.py:65(Lock)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,0]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,0]<stdout>:        7    0.000    0.000    0.004    0.001 threading.py:834(start)
[1,0]<stdout>:     55/1    0.000    0.000    0.000    0.000 module.py:1253(train)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,0]<stdout>:       48    0.000    0.000    0.000    0.000 resource_tracker.py:134(_check_alive)
[1,0]<stdout>:        4    0.000    0.000   11.691    2.923 context.py:288(_Popen)
[1,0]<stdout>:       14    0.000    0.000    0.026    0.002 selectors.py:402(select)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,0]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method posix.close}
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 reduction.py:145(sendfds)
[1,0]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,0]<stdout>:        4    0.000    0.000    0.026    0.006 popen_fork.py:40(wait)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,0]<stdout>:       84    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,0]<stdout>:       53    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,0]<stdout>:      106    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 process.py:61(_cleanup)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:846(__init__)
[1,0]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ee8110b9a0}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,0]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,0]<stdout>:        4    0.000    0.000    0.026    0.006 process.py:142(join)
[1,0]<stdout>:       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
[1,0]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,0]<stdout>:        4    0.000    0.000   11.691    2.923 popen_forkserver.py:33(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,0]<stdout>:       72    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 resource_tracker.py:145(register)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:583(_decr_instances)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 __init__.py:382(current_device)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7f4bc715bc10}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 resource_tracker.py:149(unregister)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:134(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_linux)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 __init__.py:161(_lazy_init)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,0]<stdout>:       22    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:200(_finalize_close)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,0]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,0]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:296(<listcomp>)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:670(__getitem__)
[1,0]<stdout>:        1    0.000    0.000   11.710   11.710 dataloader.py:287(__iter__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,0]<stdout>:       29    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:329(status_printer)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:75(Condition)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,0]<stdout>:       18    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,0]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1285(fp_write)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:748(encode)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:90(Event)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:979(join)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)
[1,0]<stdout>:        6    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:171(__eq__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:215(_supports_unicode)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:201(_is_utf)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 std.py:228(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:88(__getattr__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:231(_screen_shape_wrapper)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1300(<lambda>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:this epoch's train spend:484.6046099662781s
[1,1]<stdout>:         886401 function calls (872574 primitive calls) in 484.595 seconds
[1,1]<stdout>:
[1,1]<stdout>:   Ordered by: internal time
[1,1]<stdout>:
[1,1]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,1]<stdout>:    15045  185.447    0.012  185.447    0.012 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,1]<stdout>:      255  152.194    0.597  152.194    0.597 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,1]<stdout>:      511  126.977    0.248  126.977    0.248 {method 'item' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        4   11.606    2.902   11.606    2.902 {method 'write' of '_io.BufferedWriter' objects}
[1,1]<stdout>:      817    3.828    0.005    3.828    0.005 {method 'acquire' of '_thread.lock' objects}
[1,1]<stdout>:    15045    1.068    0.000  186.518    0.012 mpi_ops.py:928(synchronize)
[1,1]<stdout>:     3315    0.490    0.000    0.490    0.000 {built-in method conv2d}
[1,1]<stdout>:    29580    0.381    0.000    0.381    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    14790    0.321    0.000    0.321    0.000 {method 'set_' of 'torch._C._TensorBase' objects}
[1,0]<stderr>:
[1,1]<stdout>:    15045    0.288    0.000    0.288    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.284    0.000    0.284    0.000 {built-in method batch_norm}
[1,1]<stdout>:    14790    0.170    0.000    0.170    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.138    0.000    0.498    0.000 batchnorm.py:99(forward)
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stdout>:      255    0.101    0.000  185.842    0.729 optimizer.py:232(synchronize)
[1,1]<stdout>:      510    0.099    0.000    0.099    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:14280/510    0.087    0.000    1.524    0.003 module.py:710(_call_impl)
[1,1]<stdout>:     3825    0.086    0.000    0.086    0.000 {built-in method relu_}
[1,1]<stdout>:        1    0.075    0.075  484.594  484.594 train.py:338(train)
[1,1]<stdout>:    88740    0.075    0.000    0.085    0.000 tensor.py:725(grad)
[1,1]<stdout>:      765    0.073    0.000    0.073    0.000 {built-in method addmm}
[1,1]<stdout>:        8    0.067    0.008    0.067    0.008 {method 'dump' of '_pickle.Pickler' objects}
[1,1]<stdout>:     1275    0.064    0.000    0.064    0.000 {built-in method max_pool2d}
[1,1]<stdout>:    14790    0.057    0.000    0.057    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.056    0.000    0.751    0.003 sgd.py:75(step)
[1,1]<stdout>:      255    0.027    0.000    0.289    0.001 optimizer.py:166(zero_grad)
[1,1]<stdout>:      510    0.025    0.000    0.025    0.000 {built-in method dropout}
[1,1]<stdout>:       14    0.024    0.002    0.024    0.002 {method 'poll' of 'select.poll' objects}
[1,1]<stdout>:      510    0.023    0.000    1.439    0.003 container.py:115(forward)
[1,1]<stdout>:    29070    0.021    0.000    0.021    0.000 module.py:758(__getattr__)
[1,1]<stdout>:     3370    0.021    0.000    0.025    0.000 module.py:774(__setattr__)
[1,1]<stdout>:      255    0.020    0.000    0.020    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,1]<stdout>:      765    0.019    0.000    0.019    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315    0.017    0.000    0.319    0.000 functional.py:1998(batch_norm)
[1,1]<stdout>:   159020    0.015    0.000    0.015    0.000 {built-in method builtins.isinstance}
[1,1]<stdout>:      255    0.013    0.000    0.013    0.000 {built-in method torch._C._nn.nll_loss}
[1,1]<stdout>:    44370    0.012    0.000    0.020    0.000 tensor.py:458(__hash__)
[1,1]<stdout>:      255    0.012    0.000    0.012    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    90530    0.011    0.000    0.011    0.000 {built-in method builtins.hasattr}
[1,1]<stdout>:    14280    0.011    0.000    0.011    0.000 {built-in method torch._C._get_tracing_state}
[1,1]<stdout>:      256    0.011    0.000    0.020    0.000 sampler.py:206(__iter__)
[1,1]<stdout>:     3315    0.010    0.000    0.501    0.000 conv.py:410(_conv_forward)
[1,1]<stdout>:      255    0.009    0.000    1.186    0.005 {built-in method apply}
[1,1]<stdout>:     3315    0.008    0.000    0.513    0.000 conv.py:418(forward)
[1,1]<stdout>:     3315    0.008    0.000    0.009    0.000 functional.py:1980(_verify_batch_size)
[1,1]<stdout>:      255    0.008    0.000    0.008    0.000 {built-in method ones_like}
[1,1]<stdout>:    44399    0.008    0.000    0.008    0.000 {built-in method builtins.id}
[1,1]<stdout>:      255    0.008    0.000    0.008    0.000 {built-in method tensor}
[1,1]<stdout>:    57630    0.007    0.000    0.007    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,1]<stdout>:      255    0.006    0.000    0.006    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,1]<stdout>:     3825    0.006    0.000    0.093    0.000 functional.py:1106(relu)
[1,1]<stdout>:51531/51528    0.006    0.000    0.006    0.000 {built-in method builtins.len}
[1,1]<stdout>:     4080    0.005    0.000    0.005    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.005    0.000    0.005    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.005    0.000  152.214    0.597 tensor.py:155(backward)
[1,1]<stdout>:        8    0.005    0.001    0.072    0.009 reduction.py:58(dump)
[1,1]<stdout>:     3825    0.005    0.000    0.098    0.000 activation.py:101(forward)
[1,1]<stdout>:      255    0.005    0.000    0.005    0.000 {built-in method flatten}
[1,1]<stdout>:      765    0.005    0.000    0.102    0.000 functional.py:1655(linear)
[1,1]<stdout>:      255    0.005    0.000    1.482    0.006 vgg.py:42(forward)
[1,1]<stdout>:     1275    0.005    0.000    0.073    0.000 pooling.py:156(forward)
[1,1]<stdout>:      255    0.005    0.000  186.605    0.732 optimizer.py:337(step)
[1,1]<stdout>:      255    0.004    0.000  186.609    0.732 lr_scheduler.py:62(wrapper)
[1,1]<stdout>:      256    0.004    0.000    3.894    0.015 dataloader.py:945(_next_data)
[1,1]<stdout>:      510    0.004    0.000    0.030    0.000 functional.py:950(dropout)
[1,1]<stdout>:      255    0.003    0.000    0.003    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.003    0.000  152.208    0.597 __init__.py:57(backward)
[1,1]<stdout>:      255    0.003    0.000    3.832    0.015 queue.py:153(get)
[1,1]<stdout>:        1    0.003    0.003    0.003    0.003 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      256    0.003    0.000    0.003    0.000 basics.py:183(size)
[1,1]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,1]<stdout>:      255    0.003    0.000    1.178    0.005 mpi_ops.py:191(forward)
[1,1]<stdout>:      255    0.003    0.000    0.018    0.000 mpi_ops.py:105(_allreduce_async)
[1,1]<stdout>:    15050    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,1]<stdout>:      255    0.003    0.000    0.005    0.000 train.py:409(adjust_learning_rate)
[1,1]<stdout>:      255    0.003    0.000    0.011    0.000 __init__.py:25(_make_grads)
[1,1]<stdout>:      255    0.003    0.000    0.758    0.003 grad_mode.py:12(decorate_context)
[1,1]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,1]<stdout>:     3315    0.003    0.000    0.004    0.000 batchnorm.py:275(_check_input_dim)
[1,1]<stdout>:      521    0.002    0.000    0.005    0.000 threading.py:341(notify)
[1,1]<stdout>:      263    0.002    0.000    0.032    0.000 dataloader.py:991(_try_put_index)
[1,1]<stdout>:      255    0.002    0.000    1.189    0.005 mpi_ops.py:209(allreduce)
[1,1]<stdout>:      765    0.002    0.000    0.105    0.000 linear.py:90(forward)
[1,1]<stdout>:     1275    0.002    0.000    0.069    0.000 _jit_internal.py:237(fn)
[1,1]<stdout>:     1275    0.002    0.000    0.066    0.000 functional.py:564(_max_pool2d)
[1,1]<stdout>:      255    0.002    0.000    3.839    0.015 dataloader.py:912(_get_data)
[1,1]<stdout>:      255    0.002    0.000    0.016    0.000 functional.py:2158(nll_loss)
[1,1]<stdout>:      260    0.002    0.000    0.010    0.000 queues.py:80(put)
[1,1]<stdout>:      255    0.002    0.000    0.002    0.000 grad_mode.py:65(__enter__)
[1,1]<stdout>:      256    0.002    0.000   15.594    0.061 std.py:1159(__iter__)
[1,1]<stdout>:     3315    0.002    0.000    0.003    0.000 __init__.py:31(__get__)
[1,1]<stdout>:      255    0.002    0.000    0.002    0.000 utils.py:29(_list_with_default)
[1,1]<stdout>:      255    0.002    0.000    0.034    0.000 loss.py:946(forward)
[1,1]<stdout>:      255    0.002    0.000    0.026    0.000 mpi_ops.py:152(allreduce_async)
[1,1]<stdout>:      270    0.002    0.000    0.002    0.000 {method 'release' of '_thread.lock' objects}
[1,1]<stdout>:     4335    0.002    0.000    0.002    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.002    0.000    0.031    0.000 functional.py:2370(cross_entropy)
[1,1]<stdout>:      255    0.002    0.000    0.290    0.001 optimizer.py:353(zero_grad)
[1,1]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,1]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,1]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,1]<stdout>:        1    0.002    0.002    0.002    0.002 {built-in method randperm}
[1,1]<stdout>:      510    0.002    0.000    0.032    0.000 dropout.py:57(forward)
[1,1]<stdout>:      255    0.002    0.000    0.025    0.000 functional.py:909(adaptive_avg_pool2d)
[1,1]<stdout>:      255    0.001    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,1]<stdout>:     2040    0.001    0.000    0.003    0.000 {built-in method builtins.any}
[1,1]<stdout>:      255    0.001    0.000    3.833    0.015 dataloader.py:766(_try_get_data)
[1,1]<stdout>:     3315    0.001    0.000    0.001    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,1]<stdout>:       20    0.001    0.000    0.003    0.000 synchronize.py:50(__init__)
[1,1]<stdout>:      255    0.001    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,1]<stdout>:      255    0.001    0.000    0.026    0.000 pooling.py:1110(forward)
[1,1]<stdout>:      765    0.001    0.000    0.003    0.000 _overrides.py:779(has_torch_function)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 grad_mode.py:149(__init__)
[1,1]<stdout>:      255    0.001    0.000    0.005    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,1]<stdout>:      510    0.001    0.000    0.001    0.000 container.py:107(__iter__)
[1,1]<stdout>:       88    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,1]<stdout>:      256    0.001    0.000    3.895    0.015 dataloader.py:362(__next__)
[1,1]<stdout>:        6    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}
[1,1]<stdout>:      269    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}
[1,1]<stdout>:      255    0.001    0.000    0.024    0.000 dataloader.py:1010(_process_data)
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 threading.py:246(__enter__)
[1,1]<stdout>:      256    0.001    0.000    0.002    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,1]<stdout>:     2295    0.001    0.000    0.001    0.000 _overrides.py:792(<genexpr>)
[1,1]<stdout>:      255    0.001    0.000    0.006    0.000 mpi_ops.py:92(_check_function)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,1]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,1]<stdout>:      510    0.001    0.000    0.001    0.000 _VF.py:13(__getattr__)
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}
[1,1]<stdout>:      875    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,1]<stdout>:      601    0.001    0.000    0.021    0.000 {built-in method builtins.next}
[1,1]<stdout>:        1    0.001    0.001    0.005    0.005 distributed.py:68(__iter__)
[1,1]<stdout>:      255    0.001    0.000    0.013    0.000 functional.py:1567(log_softmax)
[1,1]<stdout>:      266    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 threading.py:249(__exit__)
[1,1]<stdout>:      255    0.000    0.000    0.001    0.000 queue.py:216(_get)
[1,1]<stdout>:      512    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
[1,1]<stdout>:        1    0.000    0.000   11.696   11.696 dataloader.py:690(__init__)
[1,1]<stdout>:        4    0.000    0.000   11.680    2.920 popen_forkserver.py:41(_launch)
[1,1]<stdout>:      531    0.000    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
[1,1]<stdout>:      263    0.000    0.000    0.020    0.000 dataloader.py:356(_next_index)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,1]<stdout>:      259    0.000    0.000    0.000    0.000 queue.py:208(_qsize)
[1,1]<stdout>:      275    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,1]<stdout>:       14    0.000    0.000    0.025    0.002 connection.py:917(wait)
[1,1]<stdout>:       34    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,1]<stdout>:      295    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,1]<stdout>:        5    0.000    0.000    0.003    0.001 queues.py:158(_start_thread)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,1]<stdout>:        1    0.000    0.000  484.595  484.595 {built-in method builtins.exec}
[1,1]<stdout>:       40    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,1]<stdout>:        1    0.000    0.000  484.595  484.595 <string>:1(<module>)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:       29    0.000    0.000    0.002    0.000 util.py:205(__call__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,1]<stdout>:      160    0.000    0.000    0.001    0.000 random.py:285(choice)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,1]<stdout>:       15    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.004    0.001 context.py:100(Queue)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,1]<stdout>:        4    0.000    0.000   11.681    2.920 process.py:110(start)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,1]<stdout>:        5    0.000    0.000    0.004    0.001 queues.py:36(__init__)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:761(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,1]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,1]<stdout>:        2    0.000    0.000    0.027    0.013 dataloader.py:1040(_shutdown_workers)
[1,1]<stdout>:      527    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,1]<stdout>:       48    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,1]<stdout>:      275    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,1]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,1]<stdout>:      269    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,1]<stdout>:       10    0.000    0.000    3.827    0.383 threading.py:270(wait)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,1]<stdout>:       14    0.000    0.000    0.024    0.002 selectors.py:402(select)
[1,1]<stdout>:        4    0.000    0.000    0.001    0.000 forkserver.py:76(connect_to_new_process)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,1]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        4    0.000    0.000   11.681    2.920 popen_fork.py:15(__init__)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,1]<stdout>:        4    0.000    0.000    0.025    0.006 popen_fork.py:40(wait)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,1]<stdout>:       11    0.000    0.000    0.003    0.000 context.py:65(Lock)
[1,1]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,1]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method posix.close}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,1]<stdout>:        4    0.000    0.000    0.025    0.006 process.py:142(join)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,1]<stdout>:       48    0.000    0.000    0.001    0.000 resource_tracker.py:134(_check_alive)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,1]<stdout>:     55/1    0.000    0.000    0.000    0.000 module.py:1253(train)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,1]<stdout>:      292    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,1]<stdout>:       11    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
[1,1]<stdout>:        6    0.000    0.000    0.003    0.001 threading.py:834(start)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,1]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 reduction.py:145(sendfds)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,1]<stdout>:        4    0.000    0.000   11.681    2.920 context.py:288(_Popen)
[1,1]<stdout>:        6    0.000    0.000    0.002    0.000 threading.py:540(wait)
[1,1]<stdout>:      104    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,1]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:145(register)
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e8bf7bc9a0}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:200(_finalize_close)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:134(close)
[1,1]<stdout>:       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)
[1,1]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,1]<stdout>:       50    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,1]<stdout>:        4    0.000    0.000    0.001    0.000 process.py:61(_cleanup)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:149(unregister)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,1]<stdout>:       70    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7fe279c02c10}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,1]<stdout>:        4    0.000    0.000   11.681    2.920 popen_forkserver.py:33(__init__)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,1]<stdout>:       23    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:846(__init__)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:128(is_initialized)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:382(current_device)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,1]<stdout>:       29    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,1]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,1]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,1]<stdout>:       18    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:161(_lazy_init)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,1]<stdout>:        1    0.000    0.000   11.696   11.696 dataloader.py:287(__iter__)
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:104(acquire)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:108(release)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,1]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:979(join)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:90(Event)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:75(Condition)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,1]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:this epoch's train spend:484.61772990226746s
[1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stderr>:test:   1%|▏         | 1/79 [00:21<27:21, 21.05s/it][1,1]<stderr>:test:   4%|▍         | 3/79 [00:21<07:06,  5.61s/it][1,1]<stderr>:test:   5%|▌         | 4/79 [00:21<04:40,  3.74s/it][1,0]<stderr>:test:   1%|▏         | 1/79 [00:22<28:40, 22.06s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:23<03:44,  3.04s/it][1,1]<stderr>:test:   8%|▊         | 6/79 [00:23<02:40,  2.20s/it][1,0]<stderr>:test:   6%|▋         | 5/79 [00:23<04:33,  3.69s/it][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:25<01:28,  1.27s/it][1,1]<stderr>:test:  13%|█▎        | 10/79 [00:25<01:13,  1.07s/it][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:25<02:15,  1.93s/it][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:27<00:52,  1.25it/s][1,1]<stderr>:test:  18%|█▊        | 14/79 [00:27<00:46,  1.40it/s][1,1]<stderr>:test:  19%|█▉        | 15/79 [00:27<00:38,  1.66it/s][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:27<01:26,  1.31s/it][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:30<00:50,  1.24it/s][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:30<01:04,  1.04s/it][1,1]<stderr>:test:  23%|██▎       | 18/79 [00:30<00:42,  1.45it/s][1,0]<stderr>:test:  24%|██▍       | 19/79 [00:30<00:51,  1.17it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:32<00:38,  1.51it/s][1,1]<stderr>:test:  28%|██▊       | 22/79 [00:32<00:32,  1.74it/s][1,1]<stderr>:test:  30%|███       | 24/79 [00:32<00:23,  2.37it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:32<00:52,  1.11it/s][1,0]<stderr>:test:  29%|██▉       | 23/79 [00:32<00:38,  1.46it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:35<00:43,  1.24it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:35<00:43,  1.23it/s][1,1]<stderr>:test:  33%|███▎      | 26/79 [00:35<00:36,  1.43it/s][1,0]<stderr>:test:  34%|███▍      | 27/79 [00:35<00:35,  1.46it/s][1,1]<stderr>:test:  35%|███▌      | 28/79 [00:36<00:27,  1.85it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:37<00:37,  1.32it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:37<00:38,  1.31it/s][1,1]<stderr>:test:  38%|███▊      | 30/79 [00:37<00:32,  1.51it/s][1,0]<stderr>:test:  39%|███▉      | 31/79 [00:38<00:28,  1.71it/s][1,1]<stderr>:test:  41%|████      | 32/79 [00:38<00:24,  1.89it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:40<00:37,  1.21it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:40<00:34,  1.34it/s][1,0]<stderr>:test:  44%|████▍     | 35/79 [00:40<00:24,  1.81it/s][1,1]<stderr>:test:  46%|████▌     | 36/79 [00:41<00:24,  1.79it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:42<00:29,  1.41it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:42<00:28,  1.45it/s][1,0]<stderr>:test:  49%|████▉     | 39/79 [00:42<00:20,  1.98it/s][1,1]<stderr>:test:  48%|████▊     | 38/79 [00:42<00:25,  1.59it/s][1,1]<stderr>:test:  51%|█████     | 40/79 [00:44<00:24,  1.59it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:45<00:29,  1.29it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:45<00:30,  1.26it/s][1,1]<stderr>:test:  56%|█████▌    | 44/79 [00:47<00:25,  1.36it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:48<00:25,  1.33it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:48<00:28,  1.21it/s][1,1]<stderr>:test:  61%|██████    | 48/79 [00:50<00:20,  1.49it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:50<00:20,  1.44it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:50<00:20,  1.50it/s][1,1]<stderr>:test:  66%|██████▌   | 52/79 [00:52<00:16,  1.66it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:53<00:15,  1.65it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:53<00:16,  1.55it/s][1,1]<stderr>:test:  68%|██████▊   | 54/79 [00:53<00:13,  1.91it/s][1,1]<stderr>:test:  71%|███████   | 56/79 [00:54<00:14,  1.61it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [00:55<00:13,  1.68it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:55<00:13,  1.60it/s][1,1]<stderr>:test:  73%|███████▎  | 58/79 [00:55<00:11,  1.85it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [00:57<00:10,  1.66it/s][1,1]<stderr>:test:  76%|███████▌  | 60/79 [00:57<00:13,  1.39it/s][1,1]<stderr>:test:  78%|███████▊  | 62/79 [00:58<00:09,  1.76it/s][1,0]<stderr>:test:  80%|███████▉  | 63/79 [00:58<00:08,  1.82it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [01:00<00:09,  1.46it/s][1,1]<stderr>:test:  81%|████████  | 64/79 [01:00<00:12,  1.24it/s][1,1]<stderr>:test:  84%|████████▎ | 66/79 [01:01<00:07,  1.72it/s][1,1]<stderr>:test:  86%|████████▌ | 68/79 [01:02<00:07,  1.48it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [01:03<00:06,  1.55it/s][1,1]<stderr>:test:  89%|████████▊ | 70/79 [01:03<00:05,  1.80it/s][1,1]<stderr>:test:  91%|█████████ | 72/79 [01:05<00:05,  1.33it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [01:06<00:04,  1.40it/s][1,1]<stderr>:test:  94%|█████████▎| 74/79 [01:06<00:03,  1.61it/s][1,1]<stderr>:test:  96%|█████████▌| 76/79 [01:08<00:01,  1.51it/s][1,1]<stderr>:test:  99%|█████████▊| 78/79 [01:09<00:00,  1.58it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [01:09<00:01,  1.43it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:09<00:00,  1.14it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:09<00:00,  1.14it/s][1,0]<stdout>:
[1,0]<stdout>:[acc/test_top1] = 0.430000
[1,0]<stdout>:[acc/test_top5] = 0.780000
[1,0]<stdout>:[acc/test_top1_best] = 0.430000
[1,1]<stdout>:spend all time:484.61772990226746s
[1,0]<stdout>:[save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints
[1,0]<stdout>:spend all time:484.6046099662781s
[1,0]<stdout>:==> loading configs from ['configs/imagenet/vgg16_bn.py', 'configs/methods/wm0.py', 'configs/methods/fp16.py', 'configs/methods/int32.py']
[1,0]<stdout>:[train.save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:[seed] = 42
[1,0]<stdout>:[data]
[1,0]<stdout>:  [num_threads_per_worker] = 4
[1,0]<stdout>:[train]
[1,0]<stdout>:  [dgc] = False
[1,0]<stdout>:  [compression]
[1,0]<stdout>:    [func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:    [compress_ratio] = 0.05
[1,0]<stdout>:    [sample_ratio] = 0.01
[1,0]<stdout>:    [strided_sample] = True
[1,0]<stdout>:    [compress_upper_bound] = 1.3
[1,0]<stdout>:    [compress_lower_bound] = 0.8
[1,0]<stdout>:    [max_adaptation_iters] = 10
[1,0]<stdout>:    [resample] = True
[1,0]<stdout>:    [memory]
[1,0]<stdout>:      [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:      [momentum] = 0.9
[1,0]<stdout>:    [warmup_epochs] = 0
[1,0]<stdout>:    [fp16_values] = True
[1,0]<stdout>:    [int32_indices] = True
[1,0]<stdout>:  [criterion]
[1,0]<stdout>:    [func] = <class 'torch.nn.modules.loss.CrossEntropyLoss'>
[1,0]<stdout>:  [optimizer]
[1,0]<stdout>:    [func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:    [momentum] = 0.9
[1,0]<stdout>:    [lr] = 0.05
[1,0]<stdout>:    [weight_decay] = 5e-05
[1,0]<stdout>:  [schedule_lr_per_epoch] = True
[1,0]<stdout>:  [warmup_lr_epochs] = 5
[1,0]<stdout>:  [metric] = acc/test_top1
[1,0]<stdout>:  [meters]
[1,0]<stdout>:    [acc/{}_top1]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 1
[1,0]<stdout>:    [acc/{}_top5]
[1,0]<stdout>:      [func] = <class 'torchpack.mtpack.meters.class_meter.TopKClassMeter'>
[1,0]<stdout>:      [k] = 5
[1,0]<stdout>:  [optimize_bn_separately] = False
[1,0]<stdout>:  [num_epochs] = 1
[1,0]<stdout>:  [batch_size] = 64
[1,0]<stdout>:  [scheduler]
[1,0]<stdout>:    [func] = <class 'torch.optim.lr_scheduler.MultiStepLR'>
[1,0]<stdout>:    [milestones] = [25, 55, 75]
[1,0]<stdout>:    [gamma] = 0.1
[1,0]<stdout>:  [topk] = False
[1,0]<stdout>:  [fp16] = False
[1,0]<stdout>:  [powersgd] = False
[1,0]<stdout>:  [sign] = False
[1,0]<stdout>:  [efsign] = False
[1,0]<stdout>:  [natural] = False
[1,0]<stdout>:  [onebit] = False
[1,0]<stdout>:  [qsgd] = False
[1,0]<stdout>:  [randomk] = False
[1,0]<stdout>:  [signum] = False
[1,0]<stdout>:  [terngrad] = False
[1,0]<stdout>:  [num_batches_per_step] = 1
[1,0]<stdout>:  [save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2
[1,0]<stdout>:  [checkpoint_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/e{epoch}-r0.pth
[1,0]<stdout>:  [latest_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/latest-r0.pth
[1,0]<stdout>:  [best_pth_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints/best-r0.pth
[1,0]<stdout>:  [base_lr] = 0.025
[1,0]<stdout>:[dataset]
[1,0]<stdout>:  [func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:  [root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [image_size] = 224
[1,0]<stdout>:[model]
[1,0]<stdout>:  [func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:  [num_classes] = 1000
[1,0]<stdout>:  [init_weights] = True
[1,0]<stdout>:[device] = cuda
[1,0]<stdout>:
[1,0]<stdout>:==> creating model "[func] = <function vgg16_bn at 0x7f4bc6b20b80>
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[init_weights] = True"
[1,0]<stdout>:
[1,0]<stdout>:==> creating dataset "[func] = <class 'torchpack.mtpack.datasets.vision.imagenet.ImageNet'>
[1,0]<stdout>:[root] = /gs/home/lwang20/jzb_horovod_test/deep-gradient-compression/data/imagenet
[1,0]<stdout>:[num_classes] = 1000
[1,0]<stdout>:[image_size] = 224"
[1,0]<stdout>:
[1,0]<stdout>:==> loading dataset "{'num_workers': 4, 'pin_memory': True, 'multiprocessing_context': 'forkserver'}""
[1,0]<stdout>:
[1,0]<stdout>:==> creating optimizer "[func] = <class 'src.optim.sgd.DGCSGD'>
[1,0]<stdout>:[momentum] = 0.9
[1,0]<stdout>:[lr] = 0.1
[1,0]<stdout>:[weight_decay] = 5e-05"
[1,1]<stdout>:Use hvd.none compression...
[1,0]<stdout>:
[1,0]<stdout>:==> creating compression "[func] = <class 'src.compression.DGCCompressor'>
[1,0]<stdout>:[compress_ratio] = 0.05
[1,0]<stdout>:[sample_ratio] = 0.01
[1,0]<stdout>:[strided_sample] = True
[1,0]<stdout>:[compress_upper_bound] = 1.3
[1,0]<stdout>:[compress_lower_bound] = 0.8
[1,0]<stdout>:[max_adaptation_iters] = 10
[1,0]<stdout>:[resample] = True
[1,0]<stdout>:[memory]
[1,0]<stdout>:  [func] = <class 'src.memory.DGCSGDMemory'>
[1,0]<stdout>:  [momentum] = 0.9
[1,0]<stdout>:[warmup_epochs] = 0
[1,0]<stdout>:[fp16_values] = True
[1,0]<stdout>:[int32_indices] = True"
[1,0]<stdout>:Use hvd.none compression...
[1,0]<stdout>:
[1,0]<stdout>:==> train from scratch
[1,0]<stdout>:
[1,0]<stdout>:==> broadcasting paramters and optimizer state
[1,0]<stdout>:before evaluate
[1,1]<stdout>:before evaluate
[1,0]<stderr>:
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,1]<stderr>:
[1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stderr>:test:   1%|▏         | 1/79 [00:19<25:47, 19.83s/it][1,1]<stderr>:test:   1%|▏         | 1/79 [00:20<26:01, 20.02s/it][1,0]<stderr>:test:   3%|▎         | 2/79 [00:20<10:43,  8.36s/it][1,1]<stderr>:test:   3%|▎         | 2/79 [00:20<10:49,  8.44s/it][1,0]<stderr>:test:   4%|▍         | 3/79 [00:20<05:56,  4.70s/it][1,1]<stderr>:test:   4%|▍         | 3/79 [00:20<05:59,  4.74s/it][1,0]<stderr>:test:   5%|▌         | 4/79 [00:20<03:42,  2.97s/it][1,1]<stderr>:test:   5%|▌         | 4/79 [00:21<03:44,  3.00s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:21<02:46,  2.25s/it][1,0]<stderr>:test:   6%|▋         | 5/79 [00:21<02:51,  2.32s/it][1,1]<stderr>:test:   8%|▊         | 6/79 [00:22<01:56,  1.60s/it][1,0]<stderr>:test:   8%|▊         | 6/79 [00:22<01:59,  1.64s/it][1,1]<stderr>:test:   9%|▉         | 7/79 [00:22<01:25,  1.18s/it][1,0]<stderr>:test:   9%|▉         | 7/79 [00:22<01:27,  1.21s/it][1,1]<stderr>:test:  10%|█         | 8/79 [00:22<01:04,  1.10it/s][1,0]<stderr>:test:  10%|█         | 8/79 [00:22<01:06,  1.07it/s][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:24<01:07,  1.04it/s][1,0]<stderr>:test:  13%|█▎        | 10/79 [00:24<00:52,  1.30it/s][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:24<01:17,  1.11s/it][1,0]<stderr>:test:  14%|█▍        | 11/79 [00:24<00:43,  1.58it/s][1,1]<stderr>:test:  13%|█▎        | 10/79 [00:24<00:59,  1.15it/s][1,0]<stderr>:test:  15%|█▌        | 12/79 [00:24<00:36,  1.85it/s][1,1]<stderr>:test:  14%|█▍        | 11/79 [00:25<00:47,  1.42it/s][1,1]<stderr>:test:  15%|█▌        | 12/79 [00:25<00:39,  1.70it/s][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:26<00:48,  1.37it/s][1,0]<stderr>:test:  18%|█▊        | 14/79 [00:26<00:41,  1.58it/s][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:26<00:49,  1.33it/s][1,0]<stderr>:test:  19%|█▉        | 15/79 [00:26<00:34,  1.85it/s][1,1]<stderr>:test:  18%|█▊        | 14/79 [00:26<00:40,  1.60it/s][1,0]<stderr>:test:  20%|██        | 16/79 [00:27<00:30,  2.09it/s][1,1]<stderr>:test:  19%|█▉        | 15/79 [00:27<00:34,  1.86it/s][1,1]<stderr>:test:  20%|██        | 16/79 [00:27<00:29,  2.11it/s][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:28<00:49,  1.26it/s][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:29<00:52,  1.19it/s][1,0]<stderr>:test:  23%|██▎       | 18/79 [00:29<00:44,  1.38it/s][1,1]<stderr>:test:  23%|██▎       | 18/79 [00:29<00:41,  1.45it/s][1,0]<stderr>:test:  24%|██▍       | 19/79 [00:29<00:37,  1.60it/s][1,1]<stderr>:test:  24%|██▍       | 19/79 [00:29<00:34,  1.72it/s][1,0]<stderr>:test:  25%|██▌       | 20/79 [00:30<00:31,  1.86it/s][1,1]<stderr>:test:  25%|██▌       | 20/79 [00:30<00:29,  1.98it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:30<00:37,  1.56it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:31<00:36,  1.59it/s][1,1]<stderr>:test:  28%|██▊       | 22/79 [00:31<00:30,  1.85it/s][1,0]<stderr>:test:  28%|██▊       | 22/79 [00:31<00:37,  1.52it/s][1,1]<stderr>:test:  29%|██▉       | 23/79 [00:31<00:26,  2.10it/s][1,0]<stderr>:test:  29%|██▉       | 23/79 [00:31<00:31,  1.78it/s][1,1]<stderr>:test:  30%|███       | 24/79 [00:32<00:23,  2.31it/s][1,0]<stderr>:test:  30%|███       | 24/79 [00:32<00:27,  2.04it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:32<00:25,  2.09it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:33<00:34,  1.59it/s][1,1]<stderr>:test:  33%|███▎      | 26/79 [00:33<00:28,  1.85it/s][1,0]<stderr>:test:  33%|███▎      | 26/79 [00:33<00:35,  1.48it/s][1,1]<stderr>:test:  34%|███▍      | 27/79 [00:33<00:24,  2.10it/s][1,0]<stderr>:test:  34%|███▍      | 27/79 [00:34<00:29,  1.75it/s][1,1]<stderr>:test:  35%|███▌      | 28/79 [00:34<00:22,  2.31it/s][1,0]<stderr>:test:  35%|███▌      | 28/79 [00:34<00:25,  2.00it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:34<00:23,  2.14it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:35<00:32,  1.55it/s][1,1]<stderr>:test:  38%|███▊      | 30/79 [00:35<00:27,  1.81it/s][1,1]<stderr>:test:  39%|███▉      | 31/79 [00:36<00:23,  2.06it/s][1,0]<stderr>:test:  38%|███▊      | 30/79 [00:36<00:36,  1.34it/s][1,1]<stderr>:test:  41%|████      | 32/79 [00:36<00:20,  2.28it/s][1,0]<stderr>:test:  39%|███▉      | 31/79 [00:36<00:29,  1.61it/s][1,0]<stderr>:test:  41%|████      | 32/79 [00:36<00:25,  1.88it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:37<00:21,  2.12it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:37<00:31,  1.44it/s][1,1]<stderr>:test:  43%|████▎     | 34/79 [00:38<00:26,  1.71it/s][1,1]<stderr>:test:  44%|████▍     | 35/79 [00:38<00:22,  1.97it/s][1,0]<stderr>:test:  43%|████▎     | 34/79 [00:38<00:29,  1.54it/s][1,1]<stderr>:test:  46%|████▌     | 36/79 [00:38<00:19,  2.20it/s][1,0]<stderr>:test:  44%|████▍     | 35/79 [00:38<00:24,  1.81it/s][1,0]<stderr>:test:  46%|████▌     | 36/79 [00:39<00:20,  2.05it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:39<00:20,  2.08it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:39<00:27,  1.53it/s][1,1]<stderr>:test:  48%|████▊     | 38/79 [00:40<00:22,  1.80it/s][1,1]<stderr>:test:  49%|████▉     | 39/79 [00:40<00:19,  2.05it/s][1,0]<stderr>:test:  48%|████▊     | 38/79 [00:40<00:26,  1.55it/s][1,1]<stderr>:test:  51%|█████     | 40/79 [00:40<00:17,  2.27it/s][1,0]<stderr>:test:  49%|████▉     | 39/79 [00:40<00:22,  1.82it/s][1,0]<stderr>:test:  51%|█████     | 40/79 [00:41<00:18,  2.06it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:42<00:26,  1.44it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:42<00:23,  1.65it/s][1,1]<stderr>:test:  53%|█████▎    | 42/79 [00:42<00:23,  1.60it/s][1,0]<stderr>:test:  53%|█████▎    | 42/79 [00:42<00:21,  1.72it/s][1,1]<stderr>:test:  54%|█████▍    | 43/79 [00:42<00:19,  1.86it/s][1,0]<stderr>:test:  54%|█████▍    | 43/79 [00:42<00:18,  1.97it/s][1,1]<stderr>:test:  56%|█████▌    | 44/79 [00:43<00:16,  2.11it/s][1,0]<stderr>:test:  56%|█████▌    | 44/79 [00:43<00:15,  2.20it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:44<00:20,  1.69it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:44<00:23,  1.46it/s][1,1]<stderr>:test:  58%|█████▊    | 46/79 [00:44<00:21,  1.51it/s][1,0]<stderr>:test:  58%|█████▊    | 46/79 [00:45<00:23,  1.39it/s][1,1]<stderr>:test:  59%|█████▉    | 47/79 [00:45<00:18,  1.77it/s][1,0]<stderr>:test:  59%|█████▉    | 47/79 [00:45<00:19,  1.66it/s][1,1]<stderr>:test:  61%|██████    | 48/79 [00:45<00:15,  2.02it/s][1,0]<stderr>:test:  61%|██████    | 48/79 [00:45<00:16,  1.92it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:46<00:16,  1.80it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:46<00:19,  1.51it/s][1,1]<stderr>:test:  63%|██████▎   | 50/79 [00:47<00:16,  1.78it/s][1,0]<stderr>:test:  63%|██████▎   | 50/79 [00:47<00:18,  1.59it/s][1,1]<stderr>:test:  65%|██████▍   | 51/79 [00:47<00:13,  2.03it/s][1,0]<stderr>:test:  65%|██████▍   | 51/79 [00:47<00:15,  1.85it/s][1,1]<stderr>:test:  66%|██████▌   | 52/79 [00:47<00:11,  2.25it/s][1,0]<stderr>:test:  66%|██████▌   | 52/79 [00:47<00:12,  2.10it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:48<00:11,  2.28it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:48<00:13,  1.91it/s][1,1]<stderr>:test:  68%|██████▊   | 54/79 [00:49<00:16,  1.49it/s][1,1]<stderr>:test:  70%|██████▉   | 55/79 [00:49<00:13,  1.76it/s][1,0]<stderr>:test:  68%|██████▊   | 54/79 [00:49<00:20,  1.23it/s][1,1]<stderr>:test:  71%|███████   | 56/79 [00:50<00:11,  2.01it/s][1,0]<stderr>:test:  70%|██████▉   | 55/79 [00:50<00:15,  1.50it/s][1,0]<stderr>:test:  71%|███████   | 56/79 [00:50<00:13,  1.77it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [00:51<00:15,  1.45it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:51<00:13,  1.65it/s][1,1]<stderr>:test:  73%|███████▎  | 58/79 [00:51<00:12,  1.71it/s][1,1]<stderr>:test:  75%|███████▍  | 59/79 [00:51<00:10,  1.97it/s][1,0]<stderr>:test:  73%|███████▎  | 58/79 [00:52<00:13,  1.56it/s][1,1]<stderr>:test:  76%|███████▌  | 60/79 [00:52<00:08,  2.20it/s][1,0]<stderr>:test:  75%|███████▍  | 59/79 [00:52<00:10,  1.83it/s][1,0]<stderr>:test:  76%|███████▌  | 60/79 [00:52<00:09,  2.08it/s][1,1]<stderr>:test:  77%|███████▋  | 61/79 [00:53<00:11,  1.57it/s][1,1]<stderr>:test:  78%|███████▊  | 62/79 [00:54<00:11,  1.44it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [00:54<00:13,  1.31it/s][1,1]<stderr>:test:  80%|███████▉  | 63/79 [00:54<00:10,  1.54it/s][1,0]<stderr>:test:  78%|███████▊  | 62/79 [00:54<00:12,  1.36it/s][1,1]<stderr>:test:  81%|████████  | 64/79 [00:54<00:08,  1.81it/s][1,0]<stderr>:test:  80%|███████▉  | 63/79 [00:55<00:09,  1.63it/s][1,0]<stderr>:test:  81%|████████  | 64/79 [00:55<00:07,  1.89it/s][1,1]<stderr>:test:  82%|████████▏ | 65/79 [00:56<00:11,  1.21it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [00:56<00:09,  1.42it/s][1,1]<stderr>:test:  84%|████████▎ | 66/79 [00:56<00:08,  1.48it/s][1,0]<stderr>:test:  84%|████████▎ | 66/79 [00:57<00:08,  1.57it/s][1,1]<stderr>:test:  85%|████████▍ | 67/79 [00:57<00:07,  1.61it/s][1,0]<stderr>:test:  85%|████████▍ | 67/79 [00:57<00:06,  1.83it/s][1,1]<stderr>:test:  86%|████████▌ | 68/79 [00:57<00:05,  1.89it/s][1,0]<stderr>:test:  86%|████████▌ | 68/79 [00:57<00:05,  2.08it/s][1,1]<stderr>:test:  87%|████████▋ | 69/79 [00:58<00:06,  1.64it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [00:58<00:05,  1.72it/s][1,1]<stderr>:test:  89%|████████▊ | 70/79 [00:58<00:04,  1.90it/s][1,1]<stderr>:test:  90%|████████▉ | 71/79 [00:59<00:04,  1.71it/s][1,0]<stderr>:test:  89%|████████▊ | 70/79 [00:59<00:06,  1.35it/s][1,1]<stderr>:test:  91%|█████████ | 72/79 [00:59<00:03,  1.97it/s][1,0]<stderr>:test:  90%|████████▉ | 71/79 [00:59<00:04,  1.62it/s][1,0]<stderr>:test:  91%|█████████ | 72/79 [01:00<00:03,  1.89it/s][1,1]<stderr>:test:  92%|█████████▏| 73/79 [01:00<00:03,  1.52it/s][1,1]<stderr>:test:  94%|█████████▎| 74/79 [01:01<00:02,  1.79it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [01:01<00:04,  1.48it/s][1,1]<stderr>:test:  95%|█████████▍| 75/79 [01:01<00:02,  1.61it/s][1,1]<stderr>:test:  96%|█████████▌| 76/79 [01:02<00:01,  1.87it/s][1,0]<stderr>:test:  94%|█████████▎| 74/79 [01:02<00:03,  1.36it/s][1,0]<stderr>:test:  95%|█████████▍| 75/79 [01:02<00:02,  1.63it/s][1,0]<stderr>:test:  96%|█████████▌| 76/79 [01:02<00:01,  1.89it/s][1,1]<stderr>:test:  97%|█████████▋| 77/79 [01:03<00:01,  1.41it/s][1,1]<stderr>:test:  99%|█████████▊| 78/79 [01:03<00:00,  1.68it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [01:03<00:01,  1.61it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:03<00:00,  2.20it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s][1,0]<stderr>:test:  99%|█████████▊| 78/79 [01:04<00:00,  1.26it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:05<00:00,  1.69it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:05<00:00,  1.21it/s][1,1]<stdout>:after evaluate
[1,0]<stdout>:after evaluate
[1,0]<stdout>:[acc/test_top1] = 0.060000
[1,0]<stdout>:[acc/test_top5] = 0.560000
[1,1]<stderr>:
[1,0]<stdout>:
[1,0]<stdout>:==> training epoch 0/1[1,0]<stdout>:
[1,0]<stderr>:
[1,0]<stderr>:train:   0% 0/255 [00:00<?, ?it/s][1,0]<stderr>:train:   0% 1/255 [00:19<1:23:47, 19.79s/it][1,0]<stderr>:train:   1% 2/255 [00:21<39:02,  9.26s/it]  [1,0]<stderr>:train:   1% 3/255 [00:23<24:53,  5.93s/it][1,0]<stderr>:train:   2% 4/255 [00:25<18:07,  4.33s/it][1,0]<stderr>:train:   2% 5/255 [00:27<14:15,  3.42s/it][1,0]<stderr>:train:   2% 6/255 [00:29<12:02,  2.90s/it][1,0]<stderr>:train:   3% 7/255 [00:31<10:41,  2.59s/it][1,0]<stderr>:train:   3% 8/255 [00:33<09:48,  2.38s/it][1,0]<stderr>:train:   4% 9/255 [00:34<09:04,  2.21s/it][1,0]<stderr>:train:   4% 10/255 [00:36<08:32,  2.09s/it][1,0]<stderr>:train:   4% 11/255 [00:38<08:17,  2.04s/it][1,0]<stderr>:train:   5% 12/255 [00:40<08:01,  1.98s/it][1,0]<stderr>:train:   5% 13/255 [00:42<07:23,  1.83s/it][1,0]<stderr>:train:   5% 14/255 [00:43<07:18,  1.82s/it][1,0]<stderr>:train:   6% 15/255 [00:45<07:24,  1.85s/it][1,0]<stderr>:train:   6% 16/255 [00:47<07:28,  1.88s/it][1,0]<stderr>:train:   7% 17/255 [00:49<07:25,  1.87s/it][1,0]<stderr>:train:   7% 18/255 [00:51<07:30,  1.90s/it][1,0]<stderr>:train:   7% 19/255 [00:53<07:31,  1.91s/it][1,0]<stderr>:train:   8% 20/255 [00:55<07:22,  1.88s/it][1,0]<stderr>:train:   8% 21/255 [00:57<07:11,  1.84s/it][1,0]<stderr>:train:   9% 22/255 [00:58<07:16,  1.87s/it][1,0]<stderr>:train:   9% 23/255 [01:00<07:10,  1.86s/it][1,0]<stderr>:train:   9% 24/255 [01:02<07:14,  1.88s/it][1,0]<stderr>:train:  10% 25/255 [01:04<07:14,  1.89s/it][1,0]<stderr>:train:  10% 26/255 [01:06<07:15,  1.90s/it][1,0]<stderr>:train:  11% 27/255 [01:08<07:13,  1.90s/it][1,0]<stderr>:train:  11% 28/255 [01:10<07:11,  1.90s/it][1,0]<stderr>:train:  11% 29/255 [01:12<07:08,  1.89s/it][1,0]<stderr>:train:  12% 30/255 [01:14<07:07,  1.90s/it][1,0]<stderr>:train:  12% 31/255 [01:16<07:06,  1.90s/it][1,0]<stderr>:train:  13% 32/255 [01:17<06:58,  1.88s/it][1,0]<stderr>:train:  13% 33/255 [01:19<07:00,  1.90s/it][1,0]<stderr>:train:  13% 34/255 [01:21<06:57,  1.89s/it][1,0]<stderr>:train:  14% 35/255 [01:23<06:56,  1.89s/it][1,0]<stderr>:train:  14% 36/255 [01:25<06:45,  1.85s/it][1,0]<stderr>:train:  15% 37/255 [01:27<06:48,  1.88s/it][1,0]<stderr>:train:  15% 38/255 [01:29<06:48,  1.88s/it][1,0]<stderr>:train:  15% 39/255 [01:30<06:42,  1.86s/it][1,0]<stderr>:train:  16% 40/255 [01:32<06:38,  1.85s/it][1,0]<stderr>:train:  16% 41/255 [01:34<06:40,  1.87s/it][1,0]<stderr>:train:  16% 42/255 [01:36<06:39,  1.88s/it][1,0]<stderr>:train:  17% 43/255 [01:38<06:40,  1.89s/it][1,0]<stderr>:train:  17% 44/255 [01:40<06:42,  1.91s/it][1,0]<stderr>:train:  18% 45/255 [01:42<06:42,  1.92s/it][1,0]<stderr>:train:  18% 46/255 [01:44<06:41,  1.92s/it][1,0]<stderr>:train:  18% 47/255 [01:46<06:39,  1.92s/it][1,0]<stderr>:train:  19% 48/255 [01:48<06:36,  1.91s/it][1,0]<stderr>:train:  19% 49/255 [01:50<06:34,  1.92s/it][1,0]<stderr>:train:  20% 50/255 [01:51<06:14,  1.83s/it][1,0]<stderr>:train:  20% 51/255 [01:53<06:12,  1.83s/it][1,0]<stderr>:train:  20% 52/255 [01:55<06:11,  1.83s/it][1,0]<stderr>:train:  21% 53/255 [01:57<06:15,  1.86s/it][1,0]<stderr>:train:  21% 54/255 [01:59<06:17,  1.88s/it][1,0]<stderr>:train:  22% 55/255 [02:01<06:14,  1.87s/it][1,0]<stderr>:train:  22% 56/255 [02:03<06:17,  1.90s/it][1,0]<stderr>:train:  22% 57/255 [02:04<06:16,  1.90s/it][1,0]<stderr>:train:  23% 58/255 [02:06<06:09,  1.88s/it][1,0]<stderr>:train:  23% 59/255 [02:08<06:08,  1.88s/it][1,0]<stderr>:train:  24% 60/255 [02:10<06:11,  1.91s/it][1,0]<stderr>:train:  24% 61/255 [02:12<06:05,  1.88s/it][1,0]<stderr>:train:  24% 62/255 [02:14<06:06,  1.90s/it][1,0]<stderr>:train:  25% 63/255 [02:16<06:05,  1.90s/it][1,0]<stderr>:train:  25% 64/255 [02:18<05:58,  1.88s/it][1,0]<stderr>:train:  25% 65/255 [02:19<05:53,  1.86s/it][1,0]<stderr>:train:  26% 66/255 [02:21<05:55,  1.88s/it][1,0]<stderr>:train:  26% 67/255 [02:23<05:56,  1.89s/it][1,0]<stderr>:train:  27% 68/255 [02:25<05:54,  1.89s/it][1,0]<stderr>:train:  27% 69/255 [02:27<05:50,  1.88s/it][1,0]<stderr>:train:  27% 70/255 [02:29<05:50,  1.89s/it][1,0]<stderr>:train:  28% 71/255 [02:31<05:43,  1.87s/it][1,0]<stderr>:train:  28% 72/255 [02:33<05:41,  1.86s/it][1,0]<stderr>:train:  29% 73/255 [02:34<05:36,  1.85s/it][1,0]<stderr>:train:  29% 74/255 [02:36<05:38,  1.87s/it][1,0]<stderr>:train:  29% 75/255 [02:38<05:33,  1.85s/it][1,0]<stderr>:train:  30% 76/255 [02:40<05:33,  1.86s/it][1,0]<stderr>:train:  30% 77/255 [02:42<05:24,  1.82s/it][1,0]<stderr>:train:  31% 78/255 [02:44<05:21,  1.81s/it][1,0]<stderr>:train:  31% 79/255 [02:46<05:27,  1.86s/it][1,0]<stderr>:train:  31% 80/255 [02:47<05:18,  1.82s/it][1,0]<stderr>:train:  32% 81/255 [02:49<05:20,  1.84s/it][1,0]<stderr>:train:  32% 82/255 [02:51<05:21,  1.86s/it][1,0]<stderr>:train:  33% 83/255 [02:53<05:23,  1.88s/it][1,0]<stderr>:train:  33% 84/255 [02:55<05:17,  1.86s/it][1,0]<stderr>:train:  33% 85/255 [02:57<05:13,  1.85s/it][1,0]<stderr>:train:  34% 86/255 [02:58<05:10,  1.84s/it][1,0]<stderr>:train:  34% 87/255 [03:00<05:13,  1.87s/it][1,0]<stderr>:train:  35% 88/255 [03:02<05:08,  1.85s/it][1,0]<stderr>:train:  35% 89/255 [03:04<05:05,  1.84s/it][1,0]<stderr>:train:  35% 90/255 [03:06<05:07,  1.86s/it][1,0]<stderr>:train:  36% 91/255 [03:08<05:01,  1.84s/it][1,0]<stderr>:train:  36% 92/255 [03:10<05:05,  1.87s/it][1,0]<stderr>:train:  36% 93/255 [03:12<05:03,  1.87s/it][1,0]<stderr>:train:  37% 94/255 [03:13<05:02,  1.88s/it][1,0]<stderr>:train:  37% 95/255 [03:15<04:58,  1.87s/it][1,0]<stderr>:train:  38% 96/255 [03:17<04:59,  1.89s/it][1,0]<stderr>:train:  38% 97/255 [03:19<05:00,  1.90s/it][1,0]<stderr>:train:  38% 98/255 [03:21<05:02,  1.92s/it][1,0]<stderr>:train:  39% 99/255 [03:23<04:56,  1.90s/it][1,0]<stderr>:train:  39% 100/255 [03:25<04:57,  1.92s/it][1,0]<stderr>:train:  40% 101/255 [03:27<04:56,  1.93s/it][1,0]<stderr>:train:  40% 102/255 [03:29<04:50,  1.90s/it][1,0]<stderr>:train:  40% 103/255 [03:31<04:49,  1.91s/it][1,0]<stderr>:train:  41% 104/255 [03:32<04:45,  1.89s/it][1,0]<stderr>:train:  41% 105/255 [03:34<04:33,  1.82s/it][1,0]<stderr>:train:  42% 106/255 [03:36<04:27,  1.79s/it][1,0]<stderr>:train:  42% 107/255 [03:38<04:25,  1.79s/it][1,0]<stderr>:train:  42% 108/255 [03:40<04:26,  1.81s/it][1,0]<stderr>:train:  43% 109/255 [03:41<04:30,  1.85s/it][1,0]<stderr>:train:  43% 110/255 [03:43<04:26,  1.84s/it][1,0]<stderr>:train:  44% 111/255 [03:45<04:19,  1.80s/it][1,0]<stderr>:train:  44% 112/255 [03:47<04:22,  1.83s/it][1,0]<stderr>:train:  44% 113/255 [03:49<04:20,  1.83s/it][1,0]<stderr>:train:  45% 114/255 [03:51<04:17,  1.83s/it][1,0]<stderr>:train:  45% 115/255 [03:52<04:12,  1.80s/it][1,0]<stderr>:train:  45% 116/255 [03:54<04:14,  1.83s/it][1,0]<stderr>:train:  46% 117/255 [03:56<04:16,  1.86s/it][1,0]<stderr>:train:  46% 118/255 [03:58<04:12,  1.84s/it][1,0]<stderr>:train:  47% 119/255 [04:00<04:07,  1.82s/it][1,0]<stderr>:train:  47% 120/255 [04:01<04:03,  1.81s/it][1,0]<stderr>:train:  47% 121/255 [04:03<04:00,  1.80s/it][1,0]<stderr>:train:  48% 122/255 [04:05<03:58,  1.79s/it][1,0]<stderr>:train:  48% 123/255 [04:07<04:02,  1.84s/it][1,0]<stderr>:train:  49% 124/255 [04:09<04:01,  1.84s/it][1,0]<stderr>:train:  49% 125/255 [04:11<03:57,  1.83s/it][1,0]<stderr>:train:  49% 126/255 [04:13<03:59,  1.86s/it][1,0]<stderr>:train:  50% 127/255 [04:14<03:57,  1.86s/it][1,0]<stderr>:train:  50% 128/255 [04:16<03:53,  1.84s/it][1,0]<stderr>:train:  51% 129/255 [04:18<03:51,  1.83s/it][1,0]<stderr>:train:  51% 130/255 [04:20<03:53,  1.87s/it][1,0]<stderr>:train:  51% 131/255 [04:22<03:49,  1.85s/it][1,0]<stderr>:train:  52% 132/255 [04:24<03:45,  1.84s/it][1,0]<stderr>:train:  52% 133/255 [04:25<03:42,  1.82s/it][1,0]<stderr>:train:  53% 134/255 [04:27<03:42,  1.84s/it][1,0]<stderr>:train:  53% 135/255 [04:29<03:28,  1.73s/it][1,0]<stderr>:train:  53% 136/255 [04:31<03:33,  1.79s/it][1,0]<stderr>:train:  54% 137/255 [04:32<03:29,  1.77s/it][1,0]<stderr>:train:  54% 138/255 [04:34<03:34,  1.83s/it][1,0]<stderr>:train:  55% 139/255 [04:36<03:31,  1.82s/it][1,0]<stderr>:train:  55% 140/255 [04:38<03:28,  1.81s/it][1,0]<stderr>:train:  55% 141/255 [04:40<03:30,  1.85s/it][1,0]<stderr>:train:  56% 142/255 [04:42<03:27,  1.83s/it][1,0]<stderr>:train:  56% 143/255 [04:44<03:27,  1.85s/it][1,0]<stderr>:train:  56% 144/255 [04:45<03:24,  1.84s/it][1,0]<stderr>:train:  57% 145/255 [04:47<03:18,  1.81s/it][1,0]<stderr>:train:  57% 146/255 [04:49<03:21,  1.84s/it][1,0]<stderr>:train:  58% 147/255 [04:51<03:14,  1.80s/it][1,0]<stderr>:train:  58% 148/255 [04:53<03:15,  1.83s/it][1,0]<stderr>:train:  58% 149/255 [04:54<03:10,  1.80s/it][1,0]<stderr>:train:  59% 150/255 [04:56<03:09,  1.80s/it][1,0]<stderr>:train:  59% 151/255 [04:58<03:04,  1.77s/it][1,0]<stderr>:train:  60% 152/255 [05:00<03:04,  1.79s/it][1,0]<stderr>:train:  60% 153/255 [05:02<03:03,  1.80s/it][1,0]<stderr>:train:  60% 154/255 [05:03<03:04,  1.83s/it][1,0]<stderr>:train:  61% 155/255 [05:05<03:06,  1.86s/it][1,0]<stderr>:train:  61% 156/255 [05:07<03:05,  1.87s/it][1,0]<stderr>:train:  62% 157/255 [05:09<03:04,  1.89s/it][1,0]<stderr>:train:  62% 158/255 [05:11<03:03,  1.90s/it][1,0]<stderr>:train:  62% 159/255 [05:13<03:02,  1.90s/it][1,0]<stderr>:train:  63% 160/255 [05:15<02:58,  1.88s/it][1,0]<stderr>:train:  63% 161/255 [05:17<02:53,  1.85s/it][1,0]<stderr>:train:  64% 162/255 [05:18<02:48,  1.81s/it][1,0]<stderr>:train:  64% 163/255 [05:20<02:46,  1.82s/it][1,0]<stderr>:train:  64% 164/255 [05:22<02:45,  1.82s/it][1,0]<stderr>:train:  65% 165/255 [05:24<02:46,  1.85s/it][1,0]<stderr>:train:  65% 166/255 [05:26<02:43,  1.83s/it][1,0]<stderr>:train:  65% 167/255 [05:28<02:40,  1.83s/it][1,0]<stderr>:train:  66% 168/255 [05:29<02:42,  1.87s/it][1,0]<stderr>:train:  66% 169/255 [05:31<02:42,  1.89s/it][1,0]<stderr>:train:  67% 170/255 [05:33<02:39,  1.88s/it][1,0]<stderr>:train:  67% 171/255 [05:35<02:37,  1.87s/it][1,0]<stderr>:train:  67% 172/255 [05:37<02:35,  1.87s/it][1,0]<stderr>:train:  68% 173/255 [05:39<02:32,  1.86s/it][1,0]<stderr>:train:  68% 174/255 [05:41<02:31,  1.87s/it][1,0]<stderr>:train:  69% 175/255 [05:43<02:31,  1.89s/it][1,0]<stderr>:train:  69% 176/255 [05:45<02:30,  1.90s/it][1,0]<stderr>:train:  69% 177/255 [05:47<02:28,  1.91s/it][1,0]<stderr>:train:  70% 178/255 [05:48<02:27,  1.92s/it][1,0]<stderr>:train:  70% 179/255 [05:50<02:23,  1.89s/it][1,0]<stderr>:train:  71% 180/255 [05:52<02:20,  1.87s/it][1,0]<stderr>:train:  71% 181/255 [05:54<02:17,  1.86s/it][1,0]<stderr>:train:  71% 182/255 [05:56<02:14,  1.84s/it][1,0]<stderr>:train:  72% 183/255 [05:58<02:12,  1.83s/it][1,0]<stderr>:train:  72% 184/255 [05:59<02:10,  1.83s/it][1,0]<stderr>:train:  73% 185/255 [06:01<02:10,  1.86s/it][1,0]<stderr>:train:  73% 186/255 [06:03<02:10,  1.88s/it][1,0]<stderr>:train:  73% 187/255 [06:05<02:07,  1.88s/it][1,0]<stderr>:train:  74% 188/255 [06:07<01:59,  1.79s/it][1,0]<stderr>:train:  74% 189/255 [06:09<02:01,  1.83s/it][1,0]<stderr>:train:  75% 190/255 [06:11<02:00,  1.86s/it][1,0]<stderr>:train:  75% 191/255 [06:12<01:56,  1.82s/it][1,0]<stderr>:train:  75% 192/255 [06:14<01:53,  1.81s/it][1,0]<stderr>:train:  76% 193/255 [06:16<01:52,  1.82s/it][1,0]<stderr>:train:  76% 194/255 [06:18<01:50,  1.81s/it][1,0]<stderr>:train:  76% 195/255 [06:20<01:50,  1.84s/it][1,0]<stderr>:train:  77% 196/255 [06:22<01:50,  1.88s/it][1,0]<stderr>:train:  77% 197/255 [06:23<01:47,  1.86s/it][1,0]<stderr>:train:  78% 198/255 [06:25<01:43,  1.82s/it][1,0]<stderr>:train:  78% 199/255 [06:27<01:42,  1.83s/it][1,0]<stderr>:train:  78% 200/255 [06:29<01:42,  1.86s/it][1,0]<stderr>:train:  79% 201/255 [06:31<01:42,  1.89s/it][1,0]<stderr>:train:  79% 202/255 [06:33<01:39,  1.87s/it][1,0]<stderr>:train:  80% 203/255 [06:35<01:38,  1.89s/it][1,0]<stderr>:train:  80% 204/255 [06:36<01:34,  1.85s/it][1,0]<stderr>:train:  80% 205/255 [06:38<01:34,  1.88s/it][1,0]<stderr>:train:  81% 206/255 [06:40<01:31,  1.86s/it][1,0]<stderr>:train:  81% 207/255 [06:42<01:30,  1.88s/it][1,0]<stderr>:train:  82% 208/255 [06:44<01:26,  1.84s/it][1,0]<stderr>:train:  82% 209/255 [06:46<01:25,  1.86s/it][1,0]<stderr>:train:  82% 210/255 [06:48<01:23,  1.85s/it][1,0]<stderr>:train:  83% 211/255 [06:49<01:22,  1.88s/it][1,0]<stderr>:train:  83% 212/255 [06:51<01:21,  1.90s/it][1,0]<stderr>:train:  84% 213/255 [06:53<01:20,  1.91s/it][1,0]<stderr>:train:  84% 214/255 [06:55<01:17,  1.88s/it][1,0]<stderr>:train:  84% 215/255 [06:57<01:16,  1.90s/it][1,0]<stderr>:train:  85% 216/255 [06:59<01:14,  1.91s/it][1,0]<stderr>:train:  85% 217/255 [07:01<01:13,  1.92s/it][1,0]<stderr>:train:  85% 218/255 [07:03<01:09,  1.89s/it][1,0]<stderr>:train:  86% 219/255 [07:05<01:07,  1.88s/it][1,0]<stderr>:train:  86% 220/255 [07:06<01:04,  1.84s/it][1,0]<stderr>:train:  87% 221/255 [07:08<00:59,  1.76s/it][1,0]<stderr>:train:  87% 222/255 [07:10<00:59,  1.79s/it][1,0]<stderr>:train:  87% 223/255 [07:12<00:58,  1.83s/it][1,0]<stderr>:train:  88% 224/255 [07:14<00:57,  1.85s/it][1,0]<stderr>:train:  88% 225/255 [07:16<00:56,  1.88s/it][1,0]<stderr>:train:  89% 226/255 [07:18<00:55,  1.90s/it][1,0]<stderr>:train:  89% 227/255 [07:19<00:52,  1.86s/it][1,0]<stderr>:train:  89% 228/255 [07:21<00:49,  1.83s/it][1,0]<stderr>:train:  90% 229/255 [07:23<00:48,  1.87s/it][1,0]<stderr>:train:  90% 230/255 [07:25<00:47,  1.89s/it][1,0]<stderr>:train:  91% 231/255 [07:27<00:44,  1.87s/it][1,0]<stderr>:train:  91% 232/255 [07:29<00:42,  1.85s/it][1,0]<stderr>:train:  91% 233/255 [07:30<00:40,  1.84s/it][1,0]<stderr>:train:  92% 234/255 [07:32<00:38,  1.82s/it][1,0]<stderr>:train:  92% 235/255 [07:34<00:37,  1.87s/it][1,0]<stderr>:train:  93% 236/255 [07:36<00:35,  1.86s/it][1,0]<stderr>:train:  93% 237/255 [07:38<00:33,  1.88s/it][1,0]<stderr>:train:  93% 238/255 [07:40<00:31,  1.86s/it][1,0]<stderr>:train:  94% 239/255 [07:42<00:30,  1.89s/it][1,0]<stderr>:train:  94% 240/255 [07:44<00:28,  1.91s/it][1,0]<stderr>:train:  95% 241/255 [07:46<00:26,  1.88s/it][1,0]<stderr>:train:  95% 242/255 [07:47<00:24,  1.86s/it][1,0]<stderr>:train:  95% 243/255 [07:49<00:22,  1.85s/it][1,0]<stderr>:train:  96% 244/255 [07:51<00:20,  1.84s/it][1,0]<stderr>:train:  96% 245/255 [07:53<00:18,  1.87s/it][1,0]<stderr>:train:  96% 246/255 [07:55<00:16,  1.82s/it][1,0]<stderr>:train:  97% 247/255 [07:56<00:14,  1.78s/it][1,0]<stderr>:train:  97% 248/255 [07:58<00:12,  1.79s/it][1,0]<stderr>:train:  98% 249/255 [08:00<00:10,  1.80s/it][1,0]<stderr>:train:  98% 250/255 [08:02<00:09,  1.81s/it][1,0]<stderr>:train:  98% 251/255 [08:04<00:07,  1.80s/it][1,0]<stderr>:train:  99% 252/255 [08:05<00:05,  1.83s/it][1,0]<stderr>:train:  99% 253/255 [08:07<00:03,  1.83s/it][1,0]<stderr>:train: 100% 254/255 [08:09<00:01,  1.83s/it][1,0]<stderr>:train: 100% 255/255 [08:10<00:00,  1.62s/it][1,0]<stderr>:train: 100% 255/255 [08:10<00:00,  1.92s/it][1,1]<stdout>:         886401 function calls (872574 primitive calls) in 490.799 seconds
[1,1]<stdout>:
[1,1]<stdout>:   Ordered by: internal time
[1,1]<stdout>:
[1,1]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,1]<stdout>:    15045  158.309    0.011  158.309    0.011 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,1]<stdout>:      255  138.307    0.542  138.307    0.542 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,1]<stdout>:      511   75.460    0.148   75.460    0.148 {method 'item' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3315   55.825    0.017   55.825    0.017 {built-in method batch_norm}
[1,1]<stdout>:        4   14.058    3.514   14.058    3.514 {method 'write' of '_io.BufferedWriter' objects}
[1,1]<stdout>:     3315   13.577    0.004   13.577    0.004 {built-in method conv2d}
[1,1]<stdout>:    14790   12.642    0.001   12.642    0.001 {method 'set_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      510    8.165    0.016    8.165    0.016 {built-in method dropout}
[1,1]<stdout>:      817    3.711    0.005    3.711    0.005 {method 'acquire' of '_thread.lock' objects}
[1,1]<stdout>:      255    1.874    0.007    1.874    0.007 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    1.761    1.761  490.799  490.799 train.py:338(train)
[1,1]<stdout>:     3825    1.473    0.000    1.473    0.000 {built-in method relu_}
[1,1]<stdout>:    29580    0.851    0.000    0.851    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    15045    0.712    0.000    0.712    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:    14790    0.594    0.000    0.594    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      765    0.410    0.001    0.410    0.001 {built-in method addmm}
[1,1]<stdout>:    14790    0.366    0.000    0.366    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     1275    0.346    0.000    0.346    0.000 {built-in method max_pool2d}
[1,1]<stdout>:    15045    0.312    0.000  158.623    0.011 mpi_ops.py:928(synchronize)
[1,1]<stdout>:     3315    0.264    0.000   56.205    0.017 batchnorm.py:99(forward)
[1,1]<stdout>:      255    0.247    0.001    0.247    0.001 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,1]<stdout>:      510    0.135    0.000    0.135    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.133    0.001  170.578    0.669 optimizer.py:232(synchronize)
[1,1]<stdout>:14280/510    0.127    0.000   82.868    0.162 module.py:710(_call_impl)
[1,1]<stdout>:      255    0.112    0.000    0.112    0.000 {built-in method flatten}
[1,1]<stdout>:    88740    0.090    0.000    0.101    0.000 tensor.py:725(grad)
[1,1]<stdout>:        8    0.079    0.010    0.080    0.010 {method 'dump' of '_pickle.Pickler' objects}
[1,1]<stdout>:      255    0.067    0.000    1.645    0.006 sgd.py:75(step)
[1,1]<stdout>:      765    0.059    0.000    0.059    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      510    0.049    0.000   80.536    0.158 container.py:115(forward)
[1,1]<stdout>:      255    0.047    0.000    0.047    0.000 {built-in method torch._C._nn.nll_loss}
[1,1]<stdout>:     3370    0.036    0.000    0.040    0.000 module.py:774(__setattr__)
[1,1]<stdout>:      255    0.032    0.000    1.033    0.004 optimizer.py:166(zero_grad)
[1,1]<stdout>:     3315    0.030    0.000   55.881    0.017 functional.py:1998(batch_norm)
[1,1]<stdout>:      256    0.027    0.000    0.047    0.000 sampler.py:206(__iter__)
[1,1]<stdout>:    29070    0.025    0.000    0.025    0.000 module.py:758(__getattr__)
[1,1]<stdout>:       14    0.024    0.002    0.024    0.002 {method 'poll' of 'select.poll' objects}
[1,1]<stdout>:     3315    0.022    0.000   13.600    0.004 conv.py:410(_conv_forward)
[1,1]<stdout>:    14280    0.019    0.000    0.019    0.000 {built-in method torch._C._get_tracing_state}
[1,1]<stdout>:   159020    0.018    0.000    0.018    0.000 {built-in method builtins.isinstance}
[1,1]<stdout>:     3315    0.016    0.000   13.620    0.004 conv.py:418(forward)
[1,1]<stdout>:      255    0.015    0.000    0.015    0.000 {built-in method ones_like}
[1,1]<stdout>:      255    0.015    0.000    0.015    0.000 {built-in method tensor}
[1,1]<stdout>:    90530    0.013    0.000    0.013    0.000 {built-in method builtins.hasattr}
[1,1]<stdout>:    44370    0.013    0.000    0.022    0.000 tensor.py:458(__hash__)
[1,1]<stdout>:     3315    0.013    0.000    0.014    0.000 functional.py:1980(_verify_batch_size)
[1,1]<stdout>:      255    0.012    0.000    0.938    0.004 {built-in method apply}
[1,1]<stdout>:        1    0.012    0.012    0.012    0.012 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3825    0.011    0.000    1.485    0.000 functional.py:1106(relu)
[1,1]<stdout>:     4080    0.011    0.000    0.011    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.010    0.000    0.010    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:     3825    0.010    0.000    1.495    0.000 activation.py:101(forward)
[1,1]<stdout>:      255    0.009    0.000    0.009    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,1]<stdout>:    44399    0.009    0.000    0.009    0.000 {built-in method builtins.id}
[1,1]<stdout>:    57630    0.009    0.000    0.009    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,1]<stdout>:     1275    0.008    0.000    0.363    0.000 pooling.py:156(forward)
[1,1]<stdout>:      255    0.008    0.000  172.246    0.675 lr_scheduler.py:62(wrapper)
[1,1]<stdout>:      765    0.007    0.000    0.483    0.001 functional.py:1655(linear)
[1,1]<stdout>:51533/51530    0.007    0.000    0.007    0.000 {built-in method builtins.len}
[1,1]<stdout>:      255    0.007    0.000   80.918    0.317 vgg.py:42(forward)
[1,1]<stdout>:      255    0.007    0.000  172.238    0.675 optimizer.py:337(step)
[1,1]<stdout>:      255    0.006    0.000  138.337    0.542 tensor.py:155(backward)
[1,1]<stdout>:        8    0.006    0.001    0.085    0.011 reduction.py:58(dump)
[1,1]<stdout>:      510    0.005    0.000    8.171    0.016 functional.py:950(dropout)
[1,1]<stdout>:      255    0.005    0.000    0.057    0.000 functional.py:2158(nll_loss)
[1,1]<stdout>:      256    0.005    0.000    3.798    0.015 dataloader.py:945(_next_data)
[1,1]<stdout>:     3315    0.005    0.000    0.007    0.000 batchnorm.py:275(_check_input_dim)
[1,1]<stdout>:      269    0.004    0.000    0.004    0.000 {method 'clear' of 'dict' objects}
[1,1]<stdout>:     1275    0.004    0.000    0.350    0.000 functional.py:564(_max_pool2d)
[1,1]<stdout>:      255    0.004    0.000    0.004    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.004    0.000  138.330    0.542 __init__.py:57(backward)
[1,1]<stdout>:     1275    0.004    0.000    0.355    0.000 _jit_internal.py:237(fn)
[1,1]<stdout>:      765    0.004    0.000    0.488    0.001 linear.py:90(forward)
[1,1]<stdout>:      255    0.003    0.000    1.654    0.006 grad_mode.py:12(decorate_context)
[1,1]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,1]<stdout>:      270    0.003    0.000    0.003    0.000 {method 'release' of '_thread.lock' objects}
[1,1]<stdout>:      255    0.003    0.000    0.005    0.000 train.py:409(adjust_learning_rate)
[1,1]<stdout>:      255    0.003    0.000    0.019    0.000 __init__.py:25(_make_grads)
[1,1]<stdout>:      255    0.003    0.000    3.715    0.015 queue.py:153(get)
[1,1]<stdout>:      263    0.003    0.000    0.061    0.000 dataloader.py:991(_try_put_index)
[1,1]<stdout>:    15051    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,1]<stdout>:     3315    0.003    0.000    0.005    0.000 __init__.py:31(__get__)
[1,1]<stdout>:      255    0.003    0.000    0.023    0.000 mpi_ops.py:105(_allreduce_async)
[1,1]<stdout>:      255    0.003    0.000    0.926    0.004 mpi_ops.py:191(forward)
[1,1]<stdout>:     4335    0.003    0.000    0.003    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      521    0.003    0.000    0.007    0.000 threading.py:341(notify)
[1,1]<stdout>:      255    0.003    0.000    0.941    0.004 mpi_ops.py:209(allreduce)
[1,1]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,1]<stdout>:      260    0.003    0.000    0.010    0.000 queues.py:80(put)
[1,1]<stdout>:      255    0.003    0.000    1.938    0.008 loss.py:946(forward)
[1,1]<stdout>:      255    0.003    0.000    3.722    0.015 dataloader.py:912(_get_data)
[1,1]<stdout>:      255    0.002    0.000    1.935    0.008 functional.py:2370(cross_entropy)
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 utils.py:29(_list_with_default)
[1,1]<stdout>:      255    0.002    0.000    1.035    0.004 optimizer.py:353(zero_grad)
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:65(__enter__)
[1,1]<stdout>:      510    0.002    0.000    8.174    0.016 dropout.py:57(forward)
[1,1]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,1]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,1]<stdout>:      256    0.002    0.000    0.002    0.000 basics.py:183(size)
[1,1]<stdout>:     2040    0.002    0.000    0.004    0.000 {built-in method builtins.any}
[1,1]<stdout>:      255    0.002    0.000    0.036    0.000 mpi_ops.py:152(allreduce_async)
[1,1]<stdout>:      255    0.002    0.000    0.252    0.001 functional.py:909(adaptive_avg_pool2d)
[1,1]<stdout>:      256    0.002    0.000   17.971    0.070 std.py:1159(__iter__)
[1,1]<stdout>:     3315    0.002    0.000    0.002    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,1]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,1]<stdout>:        1    0.002    0.002    0.002    0.002 {built-in method randperm}
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,1]<stdout>:        1    0.002    0.002    0.016    0.016 distributed.py:68(__iter__)
[1,1]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,1]<stdout>:      255    0.002    0.000    0.254    0.001 pooling.py:1110(forward)
[1,1]<stdout>:      765    0.001    0.000    0.005    0.000 _overrides.py:779(has_torch_function)
[1,1]<stdout>:      255    0.001    0.000    0.002    0.000 grad_mode.py:149(__init__)
[1,1]<stdout>:      255    0.001    0.000    3.716    0.015 dataloader.py:766(_try_get_data)
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}
[1,1]<stdout>:      510    0.001    0.000    0.002    0.000 container.py:107(__iter__)
[1,1]<stdout>:     2295    0.001    0.000    0.002    0.000 _overrides.py:792(<genexpr>)
[1,1]<stdout>:      255    0.001    0.000    0.006    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,1]<stdout>:      256    0.001    0.000    3.799    0.015 dataloader.py:362(__next__)
[1,1]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,1]<stdout>:       20    0.001    0.000    0.003    0.000 synchronize.py:50(__init__)
[1,1]<stdout>:      255    0.001    0.000    0.043    0.000 dataloader.py:1010(_process_data)
[1,1]<stdout>:      527    0.001    0.000    0.002    0.000 threading.py:246(__enter__)
[1,1]<stdout>:      255    0.001    0.000    0.007    0.000 mpi_ops.py:92(_check_function)
[1,1]<stdout>:      266    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:      510    0.001    0.000    0.001    0.000 _VF.py:13(__getattr__)
[1,1]<stdout>:       88    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,1]<stdout>:      601    0.001    0.000    0.049    0.000 {built-in method builtins.next}
[1,1]<stdout>:      875    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,1]<stdout>:      255    0.001    0.000    1.875    0.007 functional.py:1567(log_softmax)
[1,1]<stdout>:      512    0.001    0.000    0.001    0.000 {built-in method builtins.iter}
[1,1]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 threading.py:249(__exit__)
[1,1]<stdout>:      527    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}
[1,1]<stdout>:      531    0.001    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,1]<stdout>:      256    0.001    0.000    0.002    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,1]<stdout>:      255    0.000    0.000    0.001    0.000 queue.py:216(_get)
[1,1]<stdout>:      263    0.000    0.000    0.048    0.000 dataloader.py:356(_next_index)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
[1,1]<stdout>:        1    0.000    0.000   14.170   14.170 dataloader.py:690(__init__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,1]<stdout>:      259    0.000    0.000    0.000    0.000 queue.py:208(_qsize)
[1,1]<stdout>:        1    0.000    0.000  490.799  490.799 {built-in method builtins.exec}
[1,1]<stdout>:        4    0.000    0.000   14.144    3.536 popen_forkserver.py:41(_launch)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,1]<stdout>:      295    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,1]<stdout>:       34    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,1]<stdout>:        5    0.000    0.000    0.002    0.000 queues.py:158(_start_thread)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:285(choice)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:761(__init__)
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,1]<stdout>:       15    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,1]<stdout>:      269    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,1]<stdout>:      275    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,1]<stdout>:       29    0.000    0.000    0.002    0.000 util.py:205(__call__)
[1,1]<stdout>:      527    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,1]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,1]<stdout>:       14    0.000    0.000    0.024    0.002 connection.py:917(wait)
[1,1]<stdout>:      275    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,1]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,1]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,1]<stdout>:       40    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,1]<stdout>:        1    0.000    0.000  490.799  490.799 <string>:1(<module>)
[1,1]<stdout>:     55/1    0.000    0.000    0.001    0.001 module.py:1253(train)
[1,1]<stdout>:        5    0.000    0.000    0.003    0.001 context.py:100(Queue)
[1,1]<stdout>:        5    0.000    0.000    0.003    0.001 queues.py:36(__init__)
[1,1]<stdout>:       10    0.000    0.000    3.709    0.371 threading.py:270(wait)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,1]<stdout>:        4    0.000    0.000   14.145    3.536 popen_fork.py:15(__init__)
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        4    0.000    0.000    0.001    0.000 forkserver.py:76(connect_to_new_process)
[1,1]<stdout>:        4    0.000    0.000   14.145    3.536 process.py:110(start)
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,1]<stdout>:       48    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,1]<stdout>:        2    0.000    0.000    0.027    0.014 dataloader.py:1040(_shutdown_workers)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,1]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,1]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,1]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,1]<stdout>:       11    0.000    0.000    0.002    0.000 context.py:65(Lock)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,1]<stdout>:        6    0.000    0.000    0.003    0.000 threading.py:834(start)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,1]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,1]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method posix.close}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,1]<stdout>:       11    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,1]<stdout>:       23    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,1]<stdout>:       14    0.000    0.000    0.024    0.002 selectors.py:402(select)
[1,1]<stdout>:      289    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,1]<stdout>:       48    0.000    0.000    0.001    0.000 resource_tracker.py:134(_check_alive)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 reduction.py:145(sendfds)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,1]<stdout>:        6    0.000    0.000    0.002    0.000 threading.py:540(wait)
[1,1]<stdout>:        4    0.000    0.000   14.145    3.536 context.py:288(_Popen)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      104    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,1]<stdout>:       50    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,1]<stdout>:       84    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
[1,1]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,1]<stdout>:        4    0.000    0.000    0.024    0.006 popen_fork.py:40(wait)
[1,1]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,1]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e8bf7bc9a0}
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,1]<stdout>:       70    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,1]<stdout>:        4    0.000    0.000    0.024    0.006 process.py:142(join)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,1]<stdout>:       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:846(__init__)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:128(is_initialized)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:61(_cleanup)
[1,1]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,1]<stdout>:        1    0.000    0.000   14.170   14.170 dataloader.py:287(__iter__)
[1,1]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:145(register)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,1]<stdout>:       25    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7fe279c02c10}
[1,1]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,1]<stdout>:        5    0.000    0.000    0.002    0.000 queues.py:134(close)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,1]<stdout>:        4    0.000    0.000   14.145    3.536 popen_forkserver.py:33(__init__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:382(current_device)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 queues.py:200(_finalize_close)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,1]<stdout>:        6    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,1]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:161(_lazy_init)
[1,0]<stdout>:         932600 function calls (918773 primitive calls) in 490.779 seconds
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:104(acquire)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,1]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:149(unregister)
[1,0]<stdout>:
[1,0]<stdout>:   Ordered by: internal time
[1,0]<stdout>:
[1,1]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,0]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,0]<stdout>:    15045  153.624    0.010  153.624    0.010 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,1]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,0]<stdout>:      255  138.071    0.541  138.071    0.541 {method 'run_backward' of 'torch._C._EngineBase' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,0]<stdout>:      511   79.086    0.155   79.086    0.155 {method 'item' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3315   55.637    0.017   55.637    0.017 {built-in method batch_norm}
[1,0]<stdout>:        4   14.024    3.506   14.024    3.506 {method 'write' of '_io.BufferedWriter' objects}
[1,0]<stdout>:    14790   13.831    0.001   13.831    0.001 {method 'set_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:108(release)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:75(Condition)
[1,0]<stdout>:     3315   13.624    0.004   13.624    0.004 {built-in method conv2d}
[1,0]<stdout>:      510    8.199    0.016    8.199    0.016 {built-in method dropout}
[1,1]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,1]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,1]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,0]<stdout>:     1072    3.651    0.003    3.651    0.003 {method 'acquire' of '_thread.lock' objects}
[1,0]<stdout>:      255    1.880    0.007    1.880    0.007 {method 'log_softmax' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        1    1.656    1.656  490.778  490.778 train.py:338(train)
[1,0]<stdout>:     3825    1.456    0.000    1.456    0.000 {built-in method relu_}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,0]<stdout>:    29580    0.917    0.000    0.917    0.000 {method 'add_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    15045    0.683    0.000    0.683    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    14790    0.648    0.000    0.648    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,0]<stdout>:      765    0.395    0.001    0.395    0.001 {built-in method addmm}
[1,0]<stdout>:    15045    0.357    0.000  153.984    0.010 mpi_ops.py:928(synchronize)
[1,0]<stdout>:     1275    0.348    0.000    0.348    0.000 {built-in method max_pool2d}
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,0]<stdout>:    14790    0.323    0.000    0.323    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 context.py:90(Event)
[1,0]<stdout>:     3315    0.270    0.000   56.017    0.017 batchnorm.py:99(forward)
[1,0]<stdout>:      255    0.246    0.001    0.246    0.001 {built-in method torch._C._nn.adaptive_avg_pool2d}
[1,0]<stdout>:      510    0.183    0.000    0.183    0.000 {method 'to' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.136    0.001  167.250    0.656 optimizer.py:232(synchronize)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,0]<stdout>:14280/510    0.128    0.000   82.738    0.162 module.py:710(_call_impl)
[1,0]<stdout>:      255    0.110    0.000    0.110    0.000 {built-in method flatten}
[1,0]<stdout>:    88740    0.098    0.000    0.110    0.000 tensor.py:725(grad)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,0]<stdout>:      267    0.091    0.000    0.091    0.000 {method 'flush' of '_io.TextIOWrapper' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,1]<stdout>:       29    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,0]<stdout>:        8    0.087    0.011    0.088    0.011 {method 'dump' of '_pickle.Pickler' objects}
[1,0]<stdout>:      765    0.070    0.000    0.070    0.000 {method 't' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.069    0.000    1.687    0.007 sgd.py:75(step)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,0]<stdout>:      255    0.050    0.000    0.050    0.000 {built-in method torch._C._nn.nll_loss}
[1,0]<stdout>:      510    0.049    0.000   80.396    0.158 container.py:115(forward)
[1,0]<stdout>:      255    0.035    0.000    1.050    0.004 optimizer.py:166(zero_grad)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,0]<stdout>:     3370    0.034    0.000    0.040    0.000 module.py:774(__setattr__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,0]<stdout>:     3315    0.027    0.000   55.687    0.017 functional.py:1998(batch_norm)
[1,0]<stdout>:    29070    0.025    0.000    0.025    0.000 module.py:758(__getattr__)
[1,0]<stdout>:       14    0.024    0.002    0.024    0.002 {method 'poll' of 'select.poll' objects}
[1,0]<stdout>:      256    0.023    0.000    0.042    0.000 sampler.py:206(__iter__)
[1,1]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,0]<stdout>:     3315    0.020    0.000   13.646    0.004 conv.py:410(_conv_forward)
[1,0]<stdout>:   160553    0.020    0.000    0.020    0.000 {built-in method builtins.isinstance}
[1,0]<stdout>:    14280    0.018    0.000    0.018    0.000 {built-in method torch._C._get_tracing_state}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,1]<stdout>:        1    0.000    0.000    0.001    0.001 threading.py:979(join)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,0]<stdout>:      255    0.016    0.000    0.051    0.000 summary.py:137(scalar)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,0]<stdout>:      255    0.015    0.000    0.828    0.003 {built-in method apply}
[1,0]<stdout>:      255    0.015    0.000    0.015    0.000 {built-in method tensor}
[1,0]<stdout>:      255    0.015    0.000    0.015    0.000 {built-in method ones_like}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,0]<stdout>:      255    0.014    0.000    0.014    0.000 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_allreduce_async_torch_FloatTensor}
[1,0]<stdout>:    91045    0.014    0.000    0.014    0.000 {built-in method builtins.hasattr}
[1,0]<stdout>:     3315    0.013    0.000   13.664    0.004 conv.py:418(forward)
[1,1]<stdout>:       18    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,0]<stdout>:    44370    0.012    0.000    0.021    0.000 tensor.py:458(__hash__)
[1,0]<stdout>:        1    0.012    0.012    0.012    0.012 {method 'tolist' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    57630    0.012    0.000    0.012    0.000 {method 'values' of 'collections.OrderedDict' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,1]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,0]<stdout>:     3315    0.011    0.000    0.012    0.000 functional.py:1980(_verify_batch_size)
[1,0]<stdout>:     4080    0.011    0.000    0.011    0.000 {method 'size' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3825    0.010    0.000    1.467    0.000 functional.py:1106(relu)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,0]<stdout>:      257    0.010    0.000    0.021    0.000 std.py:355(format_meter)
[1,0]<stdout>:    44399    0.009    0.000    0.009    0.000 {built-in method builtins.id}
[1,0]<stdout>:      255    0.008    0.000    0.024    0.000 x2num.py:11(check_nan)
[1,0]<stdout>:      783    0.008    0.000    0.008    0.000 {method '__enter__' of '_thread.lock' objects}
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,0]<stdout>:     3825    0.008    0.000    1.475    0.000 activation.py:101(forward)
[1,0]<stdout>:      255    0.008    0.000    0.008    0.000 {method 'reduce' of 'numpy.ufunc' objects}
[1,0]<stdout>:      255    0.008    0.000  168.960    0.663 lr_scheduler.py:62(wrapper)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,1]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,0]<stdout>:      765    0.007    0.000    0.479    0.001 functional.py:1655(linear)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,0]<stdout>:      255    0.007    0.000    0.007    0.000 {method 'new' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      255    0.007    0.000  138.102    0.542 tensor.py:155(backward)
[1,0]<stdout>:      515    0.007    0.000    0.030    0.000 queues.py:80(put)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,0]<stdout>:51528/51525    0.007    0.000    0.007    0.000 {built-in method builtins.len}
[1,0]<stdout>:     1275    0.006    0.000    0.362    0.000 pooling.py:156(forward)
[1,1]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,1]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,0]<stdout>:      255    0.006    0.000    0.154    0.001 std.py:1197(update)
[1,0]<stdout>:      255    0.006    0.000   80.778    0.317 vgg.py:42(forward)
[1,0]<stdout>:        8    0.006    0.001    0.093    0.012 reduction.py:58(dump)
[1,0]<stdout>:    11449    0.005    0.000    0.008    0.000 utils.py:330(<genexpr>)
[1,1]<stdout>:        5    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,0]<stdout>:      256    0.005    0.000   18.045    0.070 std.py:1159(__iter__)
[1,0]<stdout>:      255    0.005    0.000  168.952    0.663 optimizer.py:337(step)
[1,0]<stdout>:     1577    0.005    0.000    0.005    0.000 {method 'format' of 'str' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,0]<stdout>:      256    0.005    0.000    3.737    0.015 dataloader.py:945(_next_data)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,0]<stdout>:     1530    0.005    0.000    0.005    0.000 std.py:233(__call__)
[1,0]<stdout>:      255    0.005    0.000    0.255    0.001 functional.py:909(adaptive_avg_pool2d)
[1,0]<stdout>:      255    0.004    0.000    0.023    0.000 writer.py:131(add_summary)
[1,0]<stdout>:      776    0.004    0.000    0.009    0.000 threading.py:341(notify)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,0]<stdout>:      510    0.004    0.000    8.205    0.016 functional.py:950(dropout)
[1,0]<stdout>:      255    0.004    0.000  138.094    0.542 __init__.py:57(backward)
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {method 'type' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,0]<stdout>:     3315    0.004    0.000    0.006    0.000 batchnorm.py:275(_check_input_dim)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,1]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,0]<stdout>:     1275    0.004    0.000    0.352    0.000 functional.py:564(_max_pool2d)
[1,0]<stdout>:      255    0.004    0.000    1.697    0.007 grad_mode.py:12(decorate_context)
[1,0]<stdout>:      256    0.004    0.000    0.004    0.000 {built-in method now}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,0]<stdout>:      269    0.004    0.000    0.004    0.000 {method 'clear' of 'dict' objects}
[1,0]<stdout>:      255    0.004    0.000    0.004    0.000 {built-in method numpy.array}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,1]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,0]<stdout>:      255    0.004    0.000    0.019    0.000 __init__.py:25(_make_grads)
[1,0]<stdout>:      255    0.003    0.000    0.058    0.000 functional.py:2158(nll_loss)
[1,0]<stdout>:      255    0.003    0.000    0.032    0.000 x2num.py:18(make_np)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,0]<stdout>:    15051    0.003    0.000    0.003    0.000 {method 'pop' of 'dict' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,0]<stdout>:      255    0.003    0.000    3.662    0.014 dataloader.py:912(_get_data)
[1,0]<stdout>:      524    0.003    0.000    0.003    0.000 {method 'release' of '_thread.lock' objects}
[1,0]<stdout>:      765    0.003    0.000    0.483    0.001 linear.py:90(forward)
[1,0]<stdout>:      511    0.003    0.000    0.003    0.000 basics.py:183(size)
[1,0]<stdout>:     1275    0.003    0.000    0.355    0.000 _jit_internal.py:237(fn)
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,0]<stdout>:      255    0.003    0.000    0.080    0.000 writer.py:401(add_scalar)
[1,0]<stdout>:      255    0.003    0.000    0.006    0.000 train.py:409(adjust_learning_rate)
[1,0]<stdout>:      257    0.003    0.000    0.004    0.000 std.py:1445(format_dict)
[1,1]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,1]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:      255    0.003    0.000    0.019    0.000 writer.py:115(add_event)
[1,1]<stdout>:
[1,1]<stdout>:
[1,0]<stdout>:      263    0.003    0.000    0.061    0.000 dataloader.py:991(_try_put_index)
[1,0]<stdout>:      255    0.003    0.000    0.831    0.003 mpi_ops.py:209(allreduce)
[1,0]<stdout>:      255    0.003    0.000    3.654    0.014 queue.py:153(get)
[1,0]<stdout>:     3315    0.003    0.000    0.005    0.000 __init__.py:31(__get__)
[1,0]<stdout>:      255    0.003    0.000    0.027    0.000 mpi_ops.py:105(_allreduce_async)
[1,0]<stdout>:      255    0.003    0.000    0.813    0.003 mpi_ops.py:191(forward)
[1,0]<stdout>:      255    0.003    0.000    0.003    0.000 basics.py:365(rocm_built)
[1,0]<stdout>:      256    0.003    0.000    0.143    0.001 std.py:1324(refresh)
[1,0]<stdout>:      257    0.003    0.000    0.137    0.001 std.py:1463(display)
[1,0]<stdout>:      255    0.003    0.000    1.053    0.004 optimizer.py:353(zero_grad)
[1,0]<stdout>:    16573    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}
[1,0]<stdout>:      257    0.002    0.000    0.108    0.000 std.py:348(print_status)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 utils.py:29(_list_with_default)
[1,0]<stdout>:      255    0.002    0.000    0.013    0.000 fromnumeric.py:2123(sum)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:65(__enter__)
[1,0]<stdout>:     4335    0.002    0.000    0.002    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:    11192    0.002    0.000    0.002    0.000 {built-in method unicodedata.east_asian_width}
[1,0]<stdout>:    10114    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}
[1,0]<stdout>:      255    0.002    0.000    0.010    0.000 fromnumeric.py:69(_wrapreduction)
[1,0]<stdout>:    10710    0.002    0.000    0.002    0.000 __init__.py:2277(is_scripting)
[1,0]<stdout>:      255    0.002    0.000    1.941    0.008 functional.py:2370(cross_entropy)
[1,0]<stdout>:      257    0.002    0.000    0.027    0.000 std.py:1149(__str__)
[1,0]<stdout>:      255    0.002    0.000    0.257    0.001 pooling.py:1110(forward)
[1,0]<stdout>:      255    0.002    0.000    0.037    0.000 mpi_ops.py:152(allreduce_async)
[1,0]<stdout>:    14790    0.002    0.000    0.002    0.000 compression.py:630(decompress)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 threading.py:1071(is_alive)
[1,0]<stdout>:      255    0.002    0.000    1.944    0.008 loss.py:946(forward)
[1,0]<stdout>:      512    0.002    0.000    0.002    0.000 {method 'sub' of 're.Pattern' objects}
[1,0]<stdout>:        1    0.002    0.002    0.002    0.002 {built-in method randperm}
[1,0]<stdout>:     2040    0.002    0.000    0.003    0.000 {built-in method builtins.any}
[1,0]<stdout>:      783    0.002    0.000    0.010    0.000 threading.py:246(__enter__)
[1,0]<stdout>:      260    0.002    0.000    0.002    0.000 std.py:104(acquire)
[1,0]<stdout>:      255    0.002    0.000    0.003    0.000 grad_mode.py:69(__exit__)
[1,0]<stdout>:      257    0.002    0.000    0.009    0.000 {built-in method builtins.sum}
[1,0]<stdout>:     3315    0.002    0.000    0.002    0.000 {built-in method torch._C._get_cudnn_enabled}
[1,0]<stdout>:      255    0.002    0.000    0.016    0.000 event_file_writer.py:132(add_event)
[1,0]<stdout>:      513    0.002    0.000    0.004    0.000 std.py:288(format_interval)
[1,0]<stdout>:      510    0.002    0.000    8.206    0.016 dropout.py:57(forward)
[1,0]<stdout>:      260    0.002    0.000    0.002    0.000 std.py:108(release)
[1,0]<stdout>:       20    0.002    0.000    0.004    0.000 synchronize.py:50(__init__)
[1,0]<stdout>:      255    0.002    0.000    3.655    0.014 dataloader.py:766(_try_get_data)
[1,0]<stdout>:        1    0.001    0.001    0.015    0.015 distributed.py:68(__iter__)
[1,1]<stdout>:this epoch's train spend:490.8108286857605s
[1,0]<stdout>:      765    0.001    0.000    0.004    0.000 _overrides.py:779(has_torch_function)
[1,0]<stdout>:      255    0.001    0.000    0.016    0.000 <__array_function__ internals>:2(sum)
[1,0]<stdout>:      256    0.001    0.000    3.738    0.015 dataloader.py:362(__next__)
[1,0]<stdout>:      257    0.001    0.000    0.093    0.000 std.py:342(fp_write)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}
[1,0]<stdout>:      779    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 numeric.py:1858(isscalar)
[1,0]<stdout>:      510    0.001    0.000    0.002    0.000 container.py:107(__iter__)
[1,0]<stdout>:      255    0.001    0.000    0.002    0.000 grad_mode.py:149(__init__)
[1,0]<stdout>:      255    0.001    0.000    0.003    0.000 summary.py:28(_clean_tag)
[1,0]<stdout>:      255    0.001    0.000    0.006    0.000 mpi_ops.py:101(_allreduce_function_factory)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 writer.py:318(_check_caffe2_blob)
[1,0]<stdout>:      255    0.001    0.000    0.043    0.000 dataloader.py:1010(_process_data)
[1,0]<stdout>:      257    0.001    0.000    0.012    0.000 utils.py:333(disp_len)
[1,0]<stdout>:      255    0.001    0.000    0.014    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}
[1,0]<stdout>:      765    0.001    0.000    0.001    0.000 functional.py:1670(<listcomp>)
[1,0]<stdout>:      510    0.001    0.000    0.002    0.000 _VF.py:13(__getattr__)
[1,0]<stdout>:     2295    0.001    0.000    0.002    0.000 _overrides.py:792(<genexpr>)
[1,0]<stdout>:        7    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}
[1,0]<stdout>:      257    0.001    0.000    0.010    0.000 utils.py:329(_text_width)
[1,0]<stdout>:      786    0.001    0.000    0.001    0.000 threading.py:261(_is_owned)
[1,0]<stdout>:      530    0.001    0.000    0.001    0.000 {method 'append' of 'collections.deque' objects}
[1,0]<stdout>:      255    0.001    0.000    1.881    0.007 functional.py:1567(log_softmax)
[1,0]<stdout>:      783    0.001    0.000    0.001    0.000 threading.py:249(__exit__)
[1,0]<stdout>:      512    0.001    0.000    0.001    0.000 {built-in method builtins.iter}
[1,0]<stdout>:      255    0.001    0.000    0.007    0.000 mpi_ops.py:92(_check_function)
[1,0]<stdout>:      881    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 writer.py:333(_get_file_writer)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 util.py:221(impl)
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 queue.py:216(_get)
[1,0]<stdout>:       84    0.001    0.000    0.001    0.000 {built-in method posix.write}
[1,0]<stdout>:      603    0.001    0.000    0.044    0.000 {built-in method builtins.next}
[1,0]<stdout>:      255    0.001    0.000    0.001    0.000 {method 'replace' of 'str' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
[1,0]<stdout>:      263    0.000    0.000    0.043    0.000 dataloader.py:356(_next_index)
[1,0]<stdout>:      258    0.000    0.000    0.001    0.000 queue.py:208(_qsize)
[1,0]<stdout>:        1    0.000    0.000  490.779  490.779 {built-in method builtins.exec}
[1,0]<stdout>:      516    0.000    0.000    0.091    0.000 utils.py:143(inner)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)
[1,0]<stdout>:        1    0.000    0.000   14.146   14.146 dataloader.py:690(__init__)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}
[1,0]<stdout>:      257    0.000    0.000    0.000    0.000 {built-in method builtins.max}
[1,0]<stdout>:        4    0.000    0.000   14.119    3.530 popen_forkserver.py:41(_launch)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2415(<listcomp>)
[1,0]<stdout>:     1026    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 utils.py:35(<listcomp>)
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}
[1,0]<stdout>:      256    0.000    0.000    0.001    0.000 threading.py:1017(_wait_for_tstate_lock)
[1,0]<stdout>:     1277    0.000    0.000    0.000    0.000 {built-in method time.time}
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}
[1,0]<stdout>:       36    0.000    0.000    0.000    0.000 util.py:186(__init__)
[1,0]<stdout>:        1    0.000    0.000  490.778  490.778 <string>:1(<module>)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)
[1,0]<stdout>:      160    0.000    0.000    0.001    0.000 random.py:285(choice)
[1,0]<stdout>:      295    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:234(<dictcomp>)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 functional.py:2204(<listcomp>)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 optimizer.py:235(<listcomp>)
[1,0]<stdout>:      510    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1168(named_children)
[1,0]<stdout>:     55/1    0.000    0.000    0.001    0.001 module.py:1253(train)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'is_contiguous' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      513    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}
[1,0]<stdout>:      765    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)
[1,0]<stdout>:       27    0.000    0.000    0.001    0.000 util.py:205(__call__)
[1,0]<stdout>:       21    0.000    0.000    0.000    0.000 {built-in method posix.close}
[1,0]<stdout>:        6    0.000    0.000    0.004    0.001 queues.py:158(_start_thread)
[1,0]<stdout>:       14    0.000    0.000    0.025    0.002 connection.py:917(wait)
[1,0]<stdout>:      271    0.000    0.000    0.000    0.000 threading.py:513(is_set)
[1,0]<stdout>:        5    0.000    0.000    0.004    0.001 queues.py:36(__init__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 threading.py:222(__init__)
[1,0]<stdout>:       38    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:761(__init__)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}
[1,0]<stdout>:      783    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:144(__next__)
[1,1]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stdout>:        5    0.000    0.000    0.004    0.001 context.py:100(Queue)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 forkserver.py:328(read_signed)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:150(get_preparation_data)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 fromnumeric.py:2118(_sum_dispatcher)
[1,0]<stdout>:       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)
[1,0]<stdout>:      261    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}
[1,0]<stdout>:       82    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)
[1,0]<stdout>:       10    0.000    0.000    3.649    0.365 threading.py:270(wait)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:80(__init__)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}
[1,0]<stdout>:      259    0.000    0.000    0.000    0.000 {built-in method builtins.abs}
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 tempfile.py:147(<listcomp>)
[1,0]<stdout>:      274    0.000    0.000    0.000    0.000 {built-in method time.monotonic}
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)
[1,0]<stdout>:        4    0.000    0.000   14.120    3.530 process.py:110(start)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method io.open}
[1,0]<stdout>:       11    0.000    0.000    0.003    0.000 context.py:65(Lock)
[1,0]<stdout>:       46    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 forkserver.py:76(connect_to_new_process)
[1,0]<stdout>:      109    0.000    0.000    0.000    0.000 module.py:1159(children)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method empty}
[1,0]<stdout>:       14    0.000    0.000    0.001    0.000 popen_forkserver.py:61(poll)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 std.py:846(__init__)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:35(compress)
[1,0]<stdout>:        4    0.000    0.000   14.119    3.530 popen_fork.py:15(__init__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:296(<listcomp>)
[1,0]<stdout>:       18    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
[1,0]<stdout>:        2    0.000    0.000    0.027    0.013 dataloader.py:1040(_shutdown_workers)
[1,0]<stdout>:       23    0.000    0.000    0.000    0.000 weakref.py:103(remove)
[1,0]<stdout>:      260    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}
[1,0]<stdout>:       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:234(register)
[1,0]<stdout>:       14    0.000    0.000    0.024    0.002 selectors.py:402(select)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)
[1,0]<stdout>:      275    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:670(__getitem__)
[1,0]<stdout>:       46    0.000    0.000    0.000    0.000 resource_tracker.py:134(_check_alive)
[1,0]<stdout>:      104    0.000    0.000    0.000    0.000 {built-in method posix.getpid}
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:219(__init__)
[1,0]<stdout>:       82    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:338(__init__)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 tempfile.py:133(rng)
[1,0]<stdout>:      255    0.000    0.000    0.000    0.000 compression.py:40(decompress)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:328(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:347(__init__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:351(register)
[1,0]<stdout>:       18    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 dataloader.py:1017(_shutdown_worker)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 reduction.py:145(sendfds)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)
[1,0]<stdout>:       25    0.000    0.000    0.000    0.000 weakref.py:323(__new__)
[1,0]<stdout>:        7    0.000    0.000    0.004    0.001 threading.py:834(start)
[1,0]<stdout>:        7    0.000    0.000    0.003    0.000 threading.py:540(wait)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:209(__init__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:382(current_device)
[1,0]<stdout>:        4    0.000    0.000   14.120    3.530 context.py:288(_Popen)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)
[1,0]<stdout>:        4    0.000    0.000    0.025    0.006 popen_fork.py:40(wait)
[1,0]<stdout>:        4    0.000    0.000    0.025    0.006 process.py:142(join)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'sendmsg' of '_socket.socket' objects}
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 context.py:85(BoundedSemaphore)
[1,0]<stdout>:       53    0.000    0.000    0.000    0.000 util.py:48(debug)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 forkserver.py:105(ensure_running)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_linux)
[1,0]<stdout>:      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}
[1,0]<stdout>:       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)
[1,0]<stdout>:       24    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 process.py:61(_cleanup)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)
[1,0]<stdout>:       40    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ee8110b9a0}
[1,0]<stdout>:       11    0.000    0.000    0.003    0.000 synchronize.py:161(__init__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:505(__init__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 util.py:229(cancel)
[1,0]<stdout>:       20    0.000    0.000    0.001    0.000 resource_tracker.py:145(register)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:433(_flush_std_streams)
[1,0]<stdout>:       72    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {built-in method posix.read}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:268(close)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:134(close)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 context.py:80(Semaphore)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:37(duplicate_for_child)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:560(__new__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:202(__exit__)
[1,0]<stdout>:        4    0.000    0.000   14.119    3.530 popen_forkserver.py:33(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 os.py:748(encode)
[1,0]<stdout>:       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {function socket.close at 0x7f4bc715bc10}
[1,0]<stdout>:       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:200(_finalize_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:329(status_printer)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:734(_newname)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:128(is_initialized)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1264(close)
[1,0]<stdout>:       23    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)
[1,0]<stdout>:       18    0.000    0.000    0.000    0.000 resource_tracker.py:149(unregister)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)
[1,0]<stdout>:       27    0.000    0.000    0.000    0.000 context.py:187(get_context)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 queues.py:150(cancel_join_thread)
[1,0]<stdout>:        7    0.000    0.000    0.000    0.000 threading.py:1110(daemon)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 context.py:75(Condition)
[1,0]<stdout>:       24    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:583(_decr_instances)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 popen_forkserver.py:20(__init__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:215(_fileobj_lookup)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:255(_release_save)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 <string>:1(__new__)
[1,0]<stdout>:       10    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:162(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:33(__init__)
[1,0]<stdout>:       28    0.000    0.000    0.000    0.000 process.py:37(current_process)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:161(_lazy_init)
[1,0]<stdout>:       55    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)
[1,0]<stdout>:        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)
[1,0]<stdout>:       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:168(fileno)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 {method 'unpack' of 'Struct' objects}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:173(close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 dataloader.py:758(<genexpr>)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:492(_real_close)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:234(ident)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 threading.py:1095(daemon)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:201(_is_utf)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 __init__.py:47(is_available)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:63(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:309(__len__)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 context.py:90(Event)
[1,0]<stdout>:        4    0.000    0.000    0.001    0.000 synchronize.py:125(__init__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:496(close)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 synchronize.py:212(__init__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:112(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 synchronize.py:323(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:944(_stop)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:238(__exit__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 container.py:7(__getattr__)
[1,0]<stdout>:       27    0.000    0.000    0.000    0.000 util.py:44(sub_debug)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:519(set)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:297(_index_sampler)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:189(name)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 folder.py:145(__len__)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:205(daemon)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:88(__len__)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 {built-in method select.poll}
[1,0]<stdout>:       17    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 basics.py:223(rank)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method posix.dup}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:171(__eq__)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}
[1,0]<stdout>:        1    0.000    0.000   14.146   14.146 dataloader.py:287(__iter__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1285(fp_write)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1156(__hash__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:215(_supports_unicode)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 std.py:115(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}
[1,0]<stdout>:        1    0.000    0.000    0.001    0.001 threading.py:979(join)
[1,0]<stdout>:        5    0.000    0.000    0.000    0.000 connection.py:360(_close)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:657(get_lock)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:158(readable)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 sampler.py:216(__len__)
[1,0]<stdout>:       16    0.000    0.000    0.000    0.000 connection.py:163(writable)
[1,0]<stdout>:       14    0.000    0.000    0.000    0.000 selectors.py:199(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 dataloader.py:1100(__del__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
[1,0]<stdout>:        8    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:105(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 queue.py:205(_init)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 process.py:213(authkey)
[1,0]<stdout>:        9    0.000    0.000    0.000    0.000 connection.py:130(__del__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 std.py:228(__init__)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 utils.py:88(__getattr__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:74(__eq__)
[1,0]<stdout>:        3    0.000    0.000    0.000    0.000 dataloader.py:293(_auto_collation)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)
[1,0]<stdout>:        6    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 distributed.py:91(set_epoch)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 std.py:1152(_comparable)
[1,0]<stdout>:        2    0.000    0.000    0.000    0.000 dataloader.py:248(multiprocessing_context)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 threading.py:364(notify_all)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1146(__del__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 utils.py:231(_screen_shape_wrapper)
[1,0]<stdout>:        4    0.000    0.000    0.000    0.000 socket.py:235(__enter__)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 std.py:1300(<lambda>)
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}
[1,0]<stdout>:        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:this epoch's train spend:490.79300713539124s
[1,0]<stderr>:
[1,0]<stderr>:test:   0%|          | 0/79 [00:00<?, ?it/s][1,0]<stderr>:test:   1%|▏         | 1/79 [00:24<31:47, 24.46s/it][1,0]<stderr>:test:   3%|▎         | 2/79 [00:24<13:10, 10.26s/it][1,1]<stderr>:test:   1%|▏         | 1/79 [00:24<32:21, 24.90s/it][1,0]<stderr>:test:   4%|▍         | 3/79 [00:25<07:15,  5.73s/it][1,1]<stderr>:test:   3%|▎         | 2/79 [00:25<13:24, 10.45s/it][1,0]<stderr>:test:   5%|▌         | 4/79 [00:25<04:29,  3.60s/it][1,1]<stderr>:test:   4%|▍         | 3/79 [00:25<07:22,  5.83s/it][1,1]<stderr>:test:   5%|▌         | 4/79 [00:25<04:34,  3.66s/it][1,0]<stderr>:test:   6%|▋         | 5/79 [00:26<03:23,  2.74s/it][1,0]<stderr>:test:   8%|▊         | 6/79 [00:27<02:20,  1.92s/it][1,1]<stderr>:test:   6%|▋         | 5/79 [00:27<03:26,  2.79s/it][1,0]<stderr>:test:   9%|▉         | 7/79 [00:27<01:40,  1.40s/it][1,1]<stderr>:test:   8%|▊         | 6/79 [00:27<02:22,  1.95s/it][1,0]<stderr>:test:  10%|█         | 8/79 [00:27<01:15,  1.06s/it][1,1]<stderr>:test:   9%|▉         | 7/79 [00:27<01:42,  1.42s/it][1,1]<stderr>:test:  10%|█         | 8/79 [00:28<01:16,  1.08s/it][1,0]<stderr>:test:  11%|█▏        | 9/79 [00:29<01:28,  1.26s/it][1,0]<stderr>:test:  13%|█▎        | 10/79 [00:29<01:07,  1.02it/s][1,1]<stderr>:test:  11%|█▏        | 9/79 [00:29<01:27,  1.24s/it][1,0]<stderr>:test:  14%|█▍        | 11/79 [00:30<00:52,  1.28it/s][1,1]<stderr>:test:  13%|█▎        | 10/79 [00:30<01:06,  1.04it/s][1,0]<stderr>:test:  15%|█▌        | 12/79 [00:30<00:43,  1.56it/s][1,1]<stderr>:test:  14%|█▍        | 11/79 [00:30<00:52,  1.30it/s][1,1]<stderr>:test:  15%|█▌        | 12/79 [00:30<00:42,  1.57it/s][1,0]<stderr>:test:  16%|█▋        | 13/79 [00:31<00:56,  1.16it/s][1,0]<stderr>:test:  18%|█▊        | 14/79 [00:32<00:54,  1.18it/s][1,0]<stderr>:test:  19%|█▉        | 15/79 [00:32<00:44,  1.45it/s][1,0]<stderr>:test:  20%|██        | 16/79 [00:33<00:36,  1.72it/s][1,1]<stderr>:test:  16%|█▋        | 13/79 [00:33<01:22,  1.25s/it][1,1]<stderr>:test:  18%|█▊        | 14/79 [00:33<01:03,  1.03it/s][1,1]<stderr>:test:  19%|█▉        | 15/79 [00:34<00:49,  1.29it/s][1,1]<stderr>:test:  20%|██        | 16/79 [00:34<00:40,  1.56it/s][1,0]<stderr>:test:  22%|██▏       | 17/79 [00:34<00:51,  1.20it/s][1,0]<stderr>:test:  23%|██▎       | 18/79 [00:35<00:51,  1.19it/s][1,1]<stderr>:test:  22%|██▏       | 17/79 [00:35<00:52,  1.19it/s][1,0]<stderr>:test:  24%|██▍       | 19/79 [00:35<00:41,  1.46it/s][1,1]<stderr>:test:  23%|██▎       | 18/79 [00:36<00:41,  1.45it/s][1,0]<stderr>:test:  25%|██▌       | 20/79 [00:36<00:34,  1.73it/s][1,1]<stderr>:test:  24%|██▍       | 19/79 [00:36<00:34,  1.72it/s][1,1]<stderr>:test:  25%|██▌       | 20/79 [00:36<00:29,  1.98it/s][1,0]<stderr>:test:  27%|██▋       | 21/79 [00:36<00:37,  1.55it/s][1,0]<stderr>:test:  28%|██▊       | 22/79 [00:37<00:31,  1.81it/s][1,0]<stderr>:test:  29%|██▉       | 23/79 [00:37<00:27,  2.06it/s][1,1]<stderr>:test:  27%|██▋       | 21/79 [00:37<00:37,  1.53it/s][1,0]<stderr>:test:  30%|███       | 24/79 [00:37<00:24,  2.28it/s][1,1]<stderr>:test:  28%|██▊       | 22/79 [00:38<00:31,  1.80it/s][1,1]<stderr>:test:  29%|██▉       | 23/79 [00:38<00:27,  2.05it/s][1,1]<stderr>:test:  30%|███       | 24/79 [00:38<00:24,  2.27it/s][1,0]<stderr>:test:  32%|███▏      | 25/79 [00:38<00:30,  1.78it/s][1,0]<stderr>:test:  33%|███▎      | 26/79 [00:39<00:27,  1.95it/s][1,0]<stderr>:test:  34%|███▍      | 27/79 [00:39<00:23,  2.18it/s][1,1]<stderr>:test:  32%|███▏      | 25/79 [00:39<00:33,  1.60it/s][1,1]<stderr>:test:  33%|███▎      | 26/79 [00:40<00:28,  1.86it/s][1,0]<stderr>:test:  35%|███▌      | 28/79 [00:40<00:28,  1.77it/s][1,1]<stderr>:test:  34%|███▍      | 27/79 [00:40<00:24,  2.11it/s][1,1]<stderr>:test:  35%|███▌      | 28/79 [00:40<00:21,  2.32it/s][1,0]<stderr>:test:  37%|███▋      | 29/79 [00:41<00:31,  1.59it/s][1,0]<stderr>:test:  38%|███▊      | 30/79 [00:41<00:29,  1.69it/s][1,0]<stderr>:test:  39%|███▉      | 31/79 [00:41<00:24,  1.95it/s][1,1]<stderr>:test:  37%|███▋      | 29/79 [00:42<00:35,  1.42it/s][1,0]<stderr>:test:  41%|████      | 32/79 [00:42<00:21,  2.18it/s][1,1]<stderr>:test:  38%|███▊      | 30/79 [00:42<00:29,  1.69it/s][1,1]<stderr>:test:  39%|███▉      | 31/79 [00:42<00:24,  1.95it/s][1,1]<stderr>:test:  41%|████      | 32/79 [00:43<00:21,  2.18it/s][1,0]<stderr>:test:  42%|████▏     | 33/79 [00:43<00:26,  1.75it/s][1,0]<stderr>:test:  43%|████▎     | 34/79 [00:43<00:25,  1.76it/s][1,0]<stderr>:test:  44%|████▍     | 35/79 [00:43<00:21,  2.01it/s][1,0]<stderr>:test:  46%|████▌     | 36/79 [00:44<00:24,  1.73it/s][1,1]<stderr>:test:  42%|████▏     | 33/79 [00:45<00:43,  1.06it/s][1,1]<stderr>:test:  43%|████▎     | 34/79 [00:45<00:34,  1.31it/s][1,1]<stderr>:test:  44%|████▍     | 35/79 [00:45<00:27,  1.58it/s][1,0]<stderr>:test:  47%|████▋     | 37/79 [00:45<00:30,  1.39it/s][1,1]<stderr>:test:  46%|████▌     | 36/79 [00:46<00:23,  1.85it/s][1,0]<stderr>:test:  48%|████▊     | 38/79 [00:46<00:24,  1.66it/s][1,0]<stderr>:test:  49%|████▉     | 39/79 [00:46<00:20,  1.93it/s][1,0]<stderr>:test:  51%|█████     | 40/79 [00:46<00:18,  2.09it/s][1,1]<stderr>:test:  47%|████▋     | 37/79 [00:47<00:27,  1.52it/s][1,1]<stderr>:test:  48%|████▊     | 38/79 [00:47<00:22,  1.79it/s][1,1]<stderr>:test:  49%|████▉     | 39/79 [00:47<00:19,  2.04it/s][1,0]<stderr>:test:  52%|█████▏    | 41/79 [00:47<00:23,  1.63it/s][1,1]<stderr>:test:  51%|█████     | 40/79 [00:48<00:17,  2.26it/s][1,0]<stderr>:test:  53%|█████▎    | 42/79 [00:48<00:24,  1.51it/s][1,0]<stderr>:test:  54%|█████▍    | 43/79 [00:48<00:20,  1.77it/s][1,0]<stderr>:test:  56%|█████▌    | 44/79 [00:49<00:19,  1.77it/s][1,1]<stderr>:test:  52%|█████▏    | 41/79 [00:50<00:34,  1.09it/s][1,1]<stderr>:test:  53%|█████▎    | 42/79 [00:50<00:27,  1.35it/s][1,0]<stderr>:test:  57%|█████▋    | 45/79 [00:50<00:24,  1.38it/s][1,1]<stderr>:test:  54%|█████▍    | 43/79 [00:50<00:22,  1.62it/s][1,0]<stderr>:test:  58%|█████▊    | 46/79 [00:50<00:20,  1.64it/s][1,1]<stderr>:test:  56%|█████▌    | 44/79 [00:51<00:18,  1.88it/s][1,0]<stderr>:test:  59%|█████▉    | 47/79 [00:51<00:16,  1.90it/s][1,0]<stderr>:test:  61%|██████    | 48/79 [00:51<00:14,  2.14it/s][1,1]<stderr>:test:  57%|█████▋    | 45/79 [00:52<00:25,  1.34it/s][1,1]<stderr>:test:  58%|█████▊    | 46/79 [00:52<00:20,  1.61it/s][1,0]<stderr>:test:  62%|██████▏   | 49/79 [00:52<00:20,  1.45it/s][1,1]<stderr>:test:  59%|█████▉    | 47/79 [00:52<00:17,  1.88it/s][1,1]<stderr>:test:  61%|██████    | 48/79 [00:53<00:14,  2.12it/s][1,0]<stderr>:test:  63%|██████▎   | 50/79 [00:53<00:21,  1.34it/s][1,0]<stderr>:test:  65%|██████▍   | 51/79 [00:53<00:17,  1.61it/s][1,0]<stderr>:test:  66%|██████▌   | 52/79 [00:54<00:14,  1.88it/s][1,1]<stderr>:test:  62%|██████▏   | 49/79 [00:54<00:21,  1.37it/s][1,1]<stderr>:test:  63%|██████▎   | 50/79 [00:54<00:17,  1.65it/s][1,1]<stderr>:test:  65%|██████▍   | 51/79 [00:55<00:14,  1.91it/s][1,0]<stderr>:test:  67%|██████▋   | 53/79 [00:55<00:17,  1.45it/s][1,1]<stderr>:test:  66%|██████▌   | 52/79 [00:55<00:12,  2.14it/s][1,0]<stderr>:test:  68%|██████▊   | 54/79 [00:55<00:16,  1.54it/s][1,0]<stderr>:test:  70%|██████▉   | 55/79 [00:56<00:13,  1.81it/s][1,0]<stderr>:test:  71%|███████   | 56/79 [00:56<00:11,  2.06it/s][1,1]<stderr>:test:  67%|██████▋   | 53/79 [00:56<00:18,  1.44it/s][1,1]<stderr>:test:  68%|██████▊   | 54/79 [00:57<00:14,  1.71it/s][1,1]<stderr>:test:  70%|██████▉   | 55/79 [00:57<00:12,  1.97it/s][1,1]<stderr>:test:  71%|███████   | 56/79 [00:57<00:10,  2.20it/s][1,0]<stderr>:test:  72%|███████▏  | 57/79 [00:58<00:17,  1.24it/s][1,0]<stderr>:test:  73%|███████▎  | 58/79 [00:58<00:13,  1.51it/s][1,0]<stderr>:test:  75%|███████▍  | 59/79 [00:59<00:15,  1.28it/s][1,0]<stderr>:test:  76%|███████▌  | 60/79 [00:59<00:12,  1.55it/s][1,1]<stderr>:test:  72%|███████▏  | 57/79 [01:00<00:22,  1.04s/it][1,1]<stderr>:test:  73%|███████▎  | 58/79 [01:00<00:17,  1.21it/s][1,1]<stderr>:test:  75%|███████▍  | 59/79 [01:00<00:13,  1.47it/s][1,0]<stderr>:test:  77%|███████▋  | 61/79 [01:01<00:15,  1.19it/s][1,1]<stderr>:test:  76%|███████▌  | 60/79 [01:01<00:10,  1.74it/s][1,0]<stderr>:test:  78%|███████▊  | 62/79 [01:01<00:11,  1.45it/s][1,0]<stderr>:test:  80%|███████▉  | 63/79 [01:01<00:09,  1.72it/s][1,0]<stderr>:test:  81%|████████  | 64/79 [01:02<00:07,  1.98it/s][1,1]<stderr>:test:  77%|███████▋  | 61/79 [01:02<00:13,  1.36it/s][1,1]<stderr>:test:  78%|███████▊  | 62/79 [01:02<00:10,  1.63it/s][1,1]<stderr>:test:  80%|███████▉  | 63/79 [01:02<00:08,  1.89it/s][1,1]<stderr>:test:  81%|████████  | 64/79 [01:03<00:07,  2.13it/s][1,0]<stderr>:test:  82%|████████▏ | 65/79 [01:03<00:10,  1.29it/s][1,0]<stderr>:test:  84%|████████▎ | 66/79 [01:03<00:08,  1.56it/s][1,0]<stderr>:test:  85%|████████▍ | 67/79 [01:04<00:07,  1.55it/s][1,0]<stderr>:test:  86%|████████▌ | 68/79 [01:04<00:06,  1.82it/s][1,1]<stderr>:test:  82%|████████▏ | 65/79 [01:05<00:12,  1.15it/s][1,1]<stderr>:test:  84%|████████▎ | 66/79 [01:05<00:09,  1.41it/s][1,0]<stderr>:test:  87%|████████▋ | 69/79 [01:05<00:06,  1.50it/s][1,1]<stderr>:test:  85%|████████▍ | 67/79 [01:05<00:07,  1.68it/s][1,1]<stderr>:test:  86%|████████▌ | 68/79 [01:06<00:05,  1.94it/s][1,0]<stderr>:test:  89%|████████▊ | 70/79 [01:06<00:05,  1.68it/s][1,0]<stderr>:test:  90%|████████▉ | 71/79 [01:06<00:04,  1.73it/s][1,0]<stderr>:test:  91%|█████████ | 72/79 [01:07<00:03,  1.99it/s][1,1]<stderr>:test:  87%|████████▋ | 69/79 [01:07<00:06,  1.45it/s][1,1]<stderr>:test:  89%|████████▊ | 70/79 [01:07<00:05,  1.72it/s][1,1]<stderr>:test:  90%|████████▉ | 71/79 [01:07<00:04,  1.97it/s][1,1]<stderr>:test:  91%|█████████ | 72/79 [01:08<00:03,  2.20it/s][1,0]<stderr>:test:  92%|█████████▏| 73/79 [01:09<00:05,  1.05it/s][1,0]<stderr>:test:  94%|█████████▎| 74/79 [01:09<00:03,  1.30it/s][1,0]<stderr>:test:  95%|█████████▍| 75/79 [01:09<00:02,  1.57it/s][1,0]<stderr>:test:  96%|█████████▌| 76/79 [01:10<00:01,  1.84it/s][1,1]<stderr>:test:  92%|█████████▏| 73/79 [01:10<00:05,  1.04it/s][1,1]<stderr>:test:  94%|█████████▎| 74/79 [01:10<00:03,  1.30it/s][1,1]<stderr>:test:  95%|█████████▍| 75/79 [01:10<00:02,  1.57it/s][1,1]<stderr>:test:  96%|█████████▌| 76/79 [01:11<00:01,  1.83it/s][1,0]<stderr>:test:  97%|█████████▋| 77/79 [01:11<00:01,  1.28it/s][1,0]<stderr>:test:  99%|█████████▊| 78/79 [01:11<00:00,  1.55it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:11<00:00,  2.04it/s][1,0]<stderr>:test: 100%|██████████| 79/79 [01:11<00:00,  1.10it/s][1,1]<stderr>:test:  97%|█████████▋| 77/79 [01:12<00:01,  1.22it/s][1,1]<stderr>:test:  99%|█████████▊| 78/79 [01:13<00:00,  1.49it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:13<00:00,  1.96it/s][1,1]<stderr>:test: 100%|██████████| 79/79 [01:13<00:00,  1.08it/s][1,0]<stdout>:
[1,0]<stdout>:[acc/test_top1] = 0.320000
[1,0]<stdout>:[acc/test_top5] = 1.280000
[1,0]<stdout>:[acc/test_top1_best] = 0.320000
[1,1]<stdout>:spend all time:490.8108286857605s
[1,0]<stdout>:[save_path] = runs/[imagenet.vgg16_bn+methods.[wm0+fp16+int32]].np2/checkpoints
[1,0]<stdout>:spend all time:490.79300713539124s
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:  Environment Summary
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:PyTorch 1.6.0 compiled w/ CUDA 10.1
[1,1]<stdout>:Running with Python 3.8 and CUDA 10.1.105
[1,1]<stdout>:
[1,1]<stdout>:`pip3 list` truncated output:
[1,1]<stdout>:numpy==1.21.2
[1,1]<stdout>:pytorch-lightning==1.5.10
[1,1]<stdout>:torch==1.6.0
[1,1]<stdout>:torchmetrics==0.7.2
[1,1]<stdout>:torchvision==0.7.0
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:  cProfile output
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:         852832 function calls (843863 primitive calls) in 628.506 seconds
[1,1]<stdout>:
[1,1]<stdout>:   Ordered by: internal time
[1,1]<stdout>:   List reduced from 2068 to 15 due to restriction <15>
[1,1]<stdout>:
[1,1]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,1]<stdout>:        1  560.275  560.275  560.275  560.275 {method 'enable' of '_lsprof.Profiler' objects}
[1,1]<stdout>:      595   50.147    0.084   50.147    0.084 {method 'acquire' of '_thread.lock' objects}
[1,1]<stdout>:       97    3.474    0.036    3.474    0.036 {method 'cuda' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:      219    2.185    0.010    2.185    0.010 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,1]<stdout>:     3177    2.120    0.001    2.120    0.001 {built-in method posix.stat}
[1,1]<stdout>:        5    1.946    0.389    1.946    0.389 {method 'write' of '_io.BufferedWriter' objects}
[1,1]<stdout>:      245    1.797    0.007    1.797    0.007 {built-in method io.open_code}
[1,1]<stdout>:      245    1.672    0.007    1.672    0.007 {method 'read' of '_io.BufferedReader' objects}
[1,1]<stdout>:       16    1.121    0.070    1.121    0.070 {method 'normal_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:       32    0.778    0.024    0.778    0.024 {method 'uniform_' of 'torch._C._TensorBase' objects}
[1,1]<stdout>:        1    0.493    0.493    0.493    0.493 /gs/home/lwang20/anaconda3/env/lib/python3.8/site-packages/horovod/common/basics.py:48(init)
[1,1]<stdout>:     1027    0.415    0.000    0.415    0.000 {built-in method conv2d}
[1,1]<stdout>:      237    0.336    0.001    0.336    0.001 {built-in method addmm}
[1,1]<stdout>:       22    0.200    0.009    0.201    0.009 {built-in method _imp.create_dynamic}
[1,1]<stdout>:        8    0.088    0.011    0.088    0.011 {method 'dump' of '_pickle.Pickler' objects}
[1,1]<stdout>:
[1,1]<stdout>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:  Environment Summary
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:PyTorch 1.6.0 compiled w/ CUDA 10.1
[1,0]<stdout>:Running with Python 3.8 and CUDA 10.1.105
[1,0]<stdout>:
[1,0]<stdout>:`pip3 list` truncated output:
[1,0]<stdout>:numpy==1.21.2
[1,0]<stdout>:pytorch-lightning==1.5.10
[1,0]<stdout>:torch==1.6.0
[1,0]<stdout>:torchmetrics==0.7.2
[1,0]<stdout>:torchvision==0.7.0
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:  cProfile output
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:         867735 function calls (858294 primitive calls) in 628.516 seconds
[1,0]<stdout>:
[1,0]<stdout>:   Ordered by: internal time
[1,0]<stdout>:   List reduced from 2247 to 15 due to restriction <15>
[1,0]<stdout>:
[1,0]<stdout>:   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
[1,0]<stdout>:        1  559.123  559.123  559.123  559.123 {method 'enable' of '_lsprof.Profiler' objects}
[1,0]<stdout>:      595   50.647    0.085   50.647    0.085 {method 'acquire' of '_thread.lock' objects}
[1,0]<stdout>:       97    3.306    0.034    3.306    0.034 {method 'cuda' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:     3377    2.626    0.001    2.626    0.001 {built-in method posix.stat}
[1,0]<stdout>:      292    2.249    0.008    2.249    0.008 {built-in method io.open_code}
[1,0]<stdout>:        9    2.025    0.225    2.025    0.225 {method 'write' of '_io.BufferedWriter' objects}
[1,0]<stdout>:      292    1.972    0.007    1.972    0.007 {method 'read' of '_io.BufferedReader' objects}
[1,0]<stdout>:       16    1.067    0.067    1.067    0.067 {method 'normal_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:      219    0.914    0.004    0.914    0.004 {built-in method horovod.torch.mpi_lib_v2.horovod_torch_wait_and_clear}
[1,0]<stdout>:       32    0.756    0.024    0.756    0.024 {method 'uniform_' of 'torch._C._TensorBase' objects}
[1,0]<stdout>:       18    0.652    0.036    0.652    0.036 {built-in method tensor}
[1,0]<stdout>:     1027    0.497    0.000    0.497    0.000 {built-in method conv2d}
[1,0]<stdout>:        1    0.492    0.492    0.493    0.493 /gs/home/lwang20/anaconda3/env/lib/python3.8/site-packages/horovod/common/basics.py:48(init)
[1,0]<stdout>:      237    0.335    0.001    0.335    0.001 {built-in method addmm}
[1,0]<stdout>:       24    0.284    0.012    0.320    0.013 {built-in method _imp.create_dynamic}
[1,0]<stdout>:
[1,0]<stdout>:
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:  autograd profiler output (CPU mode)
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:        top 15 events sorted by cpu_time_total
[1,1]<stdout>:
[1,1]<stdout>:-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:Name                                 Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                                   
[1,1]<stdout>:-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:normal_                              7.09%            817.533ms        7.09%            817.533ms        817.533ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6.65%            766.868ms        6.65%            766.868ms        766.868ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.65%            766.863ms        6.65%            766.863ms        766.863ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6.64%            766.509ms        6.64%            766.509ms        766.509ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.64%            766.503ms        6.64%            766.503ms        766.503ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6.64%            766.499ms        6.64%            766.499ms        766.499ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.64%            766.494ms        6.64%            766.494ms        766.494ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6.64%            765.944ms        6.64%            765.944ms        765.944ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.64%            765.934ms        6.64%            765.934ms        765.934ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:torch::autograd::AccumulateGrad      6.64%            765.922ms        6.64%            765.922ms        765.922ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:add_                                 6.64%            765.916ms        6.64%            765.916ms        765.916ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6.63%            764.845ms        6.63%            764.845ms        764.845ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.63%            764.840ms        6.63%            764.840ms        764.840ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:item                                 6[1,1]<stdout>:.62%            763.536ms        6.62%            763.536ms        763.536ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:_local_scalar_dense                  6.62%            763.523ms        6.62%            763.523ms        763.523ms        NaN              0.000us          0.000us          1                []                                             
[1,1]<stdout>:-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:Self CPU time total: 11.538s
[1,1]<stdout>:CUDA time total: 0.000us
[1,1]<stdout>:
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:  autograd profiler output (CUDA mode)
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:        top 15 events sorted by cpu_time_total
[1,1]<stdout>:
[1,1]<stdout>:	Because the autograd profiler uses the CUDA event API,
[1,1]<stdout>:	the CUDA time column reports approximately max(cuda_time, cpu_time).
[1,1]<stdout>:	Please ignore this output if your code does not use CUDA.
[1,1]<stdout>:
[1,1]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:Name                                   Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                                   
[1,1]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:HorovodAllreduce                       14.77%           1.269s           14.77%           1.269s           1.269s           34.28%           1.269s           1.269s           1                []                                             
[1,1]<stdout>:normal_                                9.64%            828.816ms        9.64%            828.816ms        828.816ms        22.38%           828.824ms        828.824ms        1                []                                             
[1,1]<stdout>:uniform_                               6.60%            567.275ms        6.60%            567.275ms        567.275ms        15.32%           567.281ms        567.281ms        1                []                                             
[1,1]<stdout>:CudnnConvolutionBackward               6.49%            557.514ms        6.49%            557.514ms        557.514ms        6.52%            241.536ms        241.536ms     [1,1]<stdout>:   1                []                                             
[1,1]<stdout>:cudnn_convolution_backward             6.49%            557.485ms        6.49%            557.485ms        557.485ms        6.52%            241.536ms        241.536ms        1                []                                             
[1,1]<stdout>:CudnnConvolutionBackward               5.65%            485.286ms        5.65%            485.286ms        485.286ms        1.79%            66.416ms         66.416ms         1                []                                             
[1,1]<stdout>:cudnn_convolution_backward             5.65%            485.263ms        5.65%            485.263ms        485.263ms        1.79%            66.400ms         66.400ms         1                []                                             
[1,1]<stdout>:cudnn_convolution_backward_weight      5.65%            485.225ms        5.65%            485.225ms        485.225ms        1.79%            66.400ms         66.400ms         1                []                                             
[1,1]<stdout>:ViewBackward                           5.62%            483.037ms        5.62%            483.037ms        483.037ms        1.34%            49.712ms         49.712ms         1                []                                             
[1,1]<stdout>:reshape                                5.62%            483.022ms        5.62%            483.022ms        483.022ms        1.34%            49.680ms         49.680ms         1                []                                             
[1,1]<stdout>:view                                   5.62%            482.969ms        5.62%            482.969ms        482.969ms        1.34%            49.648ms         49.648ms         1                []                                             
[1,1]<stdout>:torch::autograd::AccumulateGrad        5.59%            480.136ms        5.59%            480.136ms        480.136ms        1.22%            45.248ms         45.248ms         1                []                                             
[1,1]<stdout>:add_                                   5.58%            479.842ms        5.58%            479.842ms        479.842ms        1.21%            44.960ms         44.960ms         1                []                                             
[1,1]<stdout>:item                                   5.53%            475.041ms        5.53%            475.041ms        475.041ms        1.56%            57.920ms         57.920ms         1                []                                             
[1,1]<stdout>:_local_scalar_dense                    5.53%            475.020ms        5.53%            475.020ms        475.020ms        1.56%            57.904ms         57.904ms         1                []                                             
[1,1]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,1]<stdout>:Self CPU time total: 8.595s
[1,1]<stdout>:CUDA time total: 3.703s
[1,1]<stdout>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:  autograd profiler output (CPU mode)
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:        top 15 events sorted by cpu_time_total
[1,0]<stdout>:
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:Name                                   Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                                   
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:normal_                                7.13%            840.405ms        7.13%            840.405ms        840.405ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               6.69%            788.283ms        6.69%            788.283ms        788.283ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             6.69%            788.268ms        6.69%            788.268ms        788.268ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:cudnn_convolution_backward_weight      6.68%            788.249ms        6.68%            788.249ms        788.249ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               6.67%            786.476ms        6.67%            786.476ms        786.476ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             6.67%            786.463ms        6.67%            786.463ms        786.463ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:cudnn_convolution_backward_weight      6.67%            786.450ms        6.67%            786.450ms        786.450ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:item                                   6.63%            781.593ms        6.63%            781.593ms        781.593ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:_local_scalar_dense                    6.63%            781.584ms        6.63%            781.584ms        781.584ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:item                                   6.61%            779.790ms        6.61%            779.790ms        779.790ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:_local_scalar_dense                    6.61%            779.782ms        6.61%            779.782ms        779.782ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:item                                   6.58%            776.154ms        6.58%            776.154ms        776.154ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:_local_scalar_dense                    6.58%            776.147ms        6.58%            776.147ms        776.147ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:item  [1,0]<stdout>:                                 6.58%            775.956ms        6.58%            775.956ms        775.956ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:_local_scalar_dense                    6.58%            775.950ms        6.58%            775.950ms        775.950ms        NaN              0.000us          0.000us          1                []                                             
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:Self CPU time total: 11.792s
[1,0]<stdout>:CUDA time total: 0.000us
[1,0]<stdout>:
[1,1]<stderr>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:  autograd profiler output (CUDA mode)
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:        top 15 events sorted by cpu_time_total
[1,0]<stdout>:
[1,0]<stdout>:	Because the autograd profiler uses the CUDA event API,
[1,0]<stdout>:	the CUDA time column reports approximately max(cuda_time, cpu_time).
[1,0]<stdout>:	Please ignore this output if your code does not use CUDA.
[1,0]<stdout>:
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:Name                                   Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                                   
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:HorovodAllreduce                       15.66%           1.389s           15.66%           1.389s           1.389s           33.66%           1.390s           1.390s           1                []                                             
[1,0]<stdout>:normal_                                9.84%            873.032ms        9.84%            873.032ms        873.032ms        21.15%           873.040ms        873.040ms        1                []                                             
[1,0]<stdout>:uniform_                               6.67%            592.028ms        6.67%            592.028ms        592.028ms        14.34%           592.034ms        592.034ms        1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               6.03%            534.758ms        6.03%            534.758ms        534.758ms        3.70%            152.656ms        152.656ms        1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             6.03%            534.729ms        6.03%            534.729ms        534.729ms        3.70%            152.624ms        152.624ms        1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               5.83%            516.829ms        5.83%            516.829ms        516.829ms        5.02%            207.104ms        207.104ms        1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             5.83%            516.811ms        5.83%            516.811ms        516.811ms        5.01%            207.040ms        207.040ms        1                []                                             
[1,0]<stdout>:cudnn_convolution_backward_weight      5.68%            503.712ms        5.68%            503.712ms        503.712ms        2.93%            120.816ms        120.816ms        1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               5.53%            490.209ms        5.53%            490.209ms        490.209ms        1.53%            63.072ms         63.072ms         1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             5.53%            490.166ms        5.53%            490.166ms        490.166ms        1.53%            63.072ms         63.072ms         1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               5.49%            486.676ms        5.49%            486.676ms        486.676ms        1.56%            64.384ms         64.384ms         1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             5.49%            486.640ms        5.49%            486.640ms        486.640ms        1.56%            64.368ms         64.368ms         1                []                                             
[1,0]<stdout>:cudnn_convolution_backward_weight      5.49%            486[1,0]<stdout>:.591ms        5.49%            486.591ms        486.591ms        1.56%            64.368ms         64.368ms         1                []                                             
[1,0]<stdout>:CudnnConvolutionBackward               5.46%            484.409ms        5.46%            484.409ms        484.409ms        1.39%            57.184ms         57.184ms         1                []                                             
[1,0]<stdout>:cudnn_convolution_backward             5.46%            484.374ms        5.46%            484.374ms        484.374ms        1.38%            57.152ms         57.152ms         1                []                                             
[1,0]<stdout>:-------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
[1,0]<stdout>:Self CPU time total: 8.870s
[1,0]<stdout>:CUDA time total: 4.128s
[1,0]<stdout>:
[1,0]<stderr>:

real	33m17.155s
user	46m30.134s
sys	33m48.929s
